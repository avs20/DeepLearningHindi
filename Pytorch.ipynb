{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6IgYGBUUzLsR"
      ],
      "authorship_tag": "ABX9TyMjTIbQVbWkzFGU+Ythzq9V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "196b7fe28125448483de37fd0204320d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_983b9e643d3442a6963bfff54b7bbd21",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1dc8c48df5884c91bd677ba6aa8d7529",
              "IPY_MODEL_a9c1bef5dc20400bb088d27a2471757d"
            ]
          }
        },
        "983b9e643d3442a6963bfff54b7bbd21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1dc8c48df5884c91bd677ba6aa8d7529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_84856d6c663e43f584fe95827f7a1b52",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21256292750d436e9de86bade77d51ca"
          }
        },
        "a9c1bef5dc20400bb088d27a2471757d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_159a217131294e3d808a4a39dd0ab0f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:02&lt;00:00, 66188802.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad7832a5d41b4549b1ae719775d69bb0"
          }
        },
        "84856d6c663e43f584fe95827f7a1b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21256292750d436e9de86bade77d51ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "159a217131294e3d808a4a39dd0ab0f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad7832a5d41b4549b1ae719775d69bb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avs20/DeepLearningHindi/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrqMcwtd6YWD"
      },
      "source": [
        "## Matrix multiplication "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noTEdMye6zKU",
        "outputId": "410f62aa-ee3c-4458-d553-c43487ab7f85"
      },
      "source": [
        "import torch\n",
        "\n",
        "# tensors \n",
        "torch.tensor([[2,3,5],[1,2,9]])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 3, 5],\n",
              "        [1, 2, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAePKWgn7VYD",
        "outputId": "5f9c5edd-f59e-44c6-87b8-f3f2c94b77f0"
      },
      "source": [
        "# random values \n",
        "\n",
        "torch.rand(2,2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6504, 0.2184],\n",
              "        [0.3873, 0.3832]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud7cyvSH7ek9",
        "outputId": "052e5087-2935-4db4-f277-f22faa7fd102"
      },
      "source": [
        "a = torch.rand((3,5))\n",
        "print(a.shape)\n",
        "print(a)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 5])\n",
            "tensor([[0.2235, 0.8796, 0.8028, 0.6795, 0.1912],\n",
            "        [0.8579, 0.0755, 0.5105, 0.2565, 0.7207],\n",
            "        [0.7925, 0.0481, 0.4363, 0.1213, 0.5391]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wZb9jcO7nnO",
        "outputId": "f1f84142-a65c-4bb9-fe15-405672eb4680"
      },
      "source": [
        "a = torch.rand((2,2))\n",
        "b = torch.rand((2,2))\n",
        "\n",
        "print(a,b)\n",
        "# np.dot \n",
        "# torch.matmul\n",
        "\n",
        "torch.matmul(a,b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8706, 0.0784],\n",
            "        [0.7571, 0.1860]]) tensor([[0.1677, 0.4804],\n",
            "        [0.4394, 0.7717]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1805, 0.4788],\n",
              "        [0.2087, 0.5072]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl79Rk0C8C9B",
        "outputId": "397d69a6-d52b-4a5b-a254-1f04a84f53e4"
      },
      "source": [
        ".87 * .16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoWUpq2K7NOW",
        "outputId": "90427b5d-80e6-491a-e871-a22006926926"
      },
      "source": [
        "a * b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1460, 0.0377],\n",
              "        [0.3327, 0.1435]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNVaChC08JAu",
        "outputId": "ce3890fa-55bd-46dc-e824-2dd49af9e2ef"
      },
      "source": [
        "torch.zeros(2,2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-sP52678Riv",
        "outputId": "94bdfcb0-ce35-42f1-b23b-d37e7f16be3e"
      },
      "source": [
        "torch.ones(2,2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFGxEObM8Uew",
        "outputId": "5310984c-615d-45b5-867e-2cbf1e1cd4eb"
      },
      "source": [
        "torch.eye(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0.],\n",
              "        [0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvWJqv-s8XJm"
      },
      "source": [
        "x = torch.rand((3,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYcD44D98iQj",
        "outputId": "2c0a3c40-aff4-4d1b-8f05-f29fe8adcda8"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2857, 0.3255, 0.7789, 0.7855, 0.1518],\n",
            "        [0.1040, 0.2476, 0.5401, 0.0728, 0.1194],\n",
            "        [0.6192, 0.8425, 0.8434, 0.9098, 0.0032]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Sy3wjDg8j0D",
        "outputId": "a59e10bf-86cf-42c6-82fb-7965631c0d81"
      },
      "source": [
        "x.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.28573233, 0.32548898, 0.77892315, 0.7854549 , 0.15182328],\n",
              "       [0.10403293, 0.24762446, 0.5400609 , 0.07283103, 0.11941135],\n",
              "       [0.6191575 , 0.84245336, 0.8433534 , 0.9097687 , 0.00318712]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv48QFHo8oa5",
        "outputId": "d2c49b90-5feb-4e47-d9b0-06b53b3826c1"
      },
      "source": [
        "torch.from_numpy(x.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2857, 0.3255, 0.7789, 0.7855, 0.1518],\n",
              "        [0.1040, 0.2476, 0.5401, 0.0728, 0.1194],\n",
              "        [0.6192, 0.8425, 0.8434, 0.9098, 0.0032]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHO5UdwY8xC6",
        "outputId": "5fe98fc3-d42c-42bd-fc30-6bc24a1cb12d"
      },
      "source": [
        "l = [1,2,3,4,5]\n",
        "torch.tensor(l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCT1R2yh6z_y"
      },
      "source": [
        "# Practice "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZBp01z2pBEQ"
      },
      "source": [
        "```\n",
        "Import PyTorch main library.\n",
        "Create the variable your_first_tensor and set it to a random torch tensor of size 3 by 3.\n",
        "Calculate its shape (dimension sizes) and set it to variable tensor_size.\n",
        "Print the values of your_first_tensor and tensor_size.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLml2-Aeo0MI"
      },
      "source": [
        "# Import torch\n",
        "____\n",
        "\n",
        "# Create random tensor of size 3 by 3\n",
        "your_first_tensor = torch.____(3, 3)\n",
        "\n",
        "# Calculate the shape of the tensor\n",
        "tensor_size = your_first_tensor.____\n",
        "\n",
        "# Print the values of the tensor and its shape\n",
        "print(____)\n",
        "print(____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJRmRNatpIuR"
      },
      "source": [
        "```\n",
        "Create a matrix of ones with shape 3 by 3, and put it on variable tensor_of_ones.\n",
        "Create an identity matrix with shape 3 by 3, and put it on variable identity_tensor.\n",
        "Do a matrix multiplication of tensor_of_ones with identity_tensor and print its value.\n",
        "Do an element-wise multiplication of tensor_of_ones with identity_tensor and print its value.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny5jtNwQpMDq"
      },
      "source": [
        "# Create a matrix of ones with shape 3 by 3\n",
        "tensor_of_ones = torch.____(3, 3)\n",
        "\n",
        "# Create an identity matrix with shape 3 by 3\n",
        "identity_tensor = torch.____(3)\n",
        "\n",
        "# Do a matrix multiplication of tensor_of_ones with identity_tensor\n",
        "matrices_multiplied = torch.____(tensor_of_ones, ____)\n",
        "print(matrices_multiplied)\n",
        "\n",
        "# Do an element-wise multiplication of tensor_of_ones with identity_tensor\n",
        "element_multiplication = ____\n",
        "print(element_multiplication)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvRtn15_pOUH"
      },
      "source": [
        "### Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KDHD_papkmj",
        "outputId": "57e1c0f9-aaf4-4827-c529-854509ff1a86"
      },
      "source": [
        "import torch \n",
        "\n",
        "a = torch.tensor([2])\n",
        "b = torch.tensor([-4])\n",
        "c = torch.tensor([-2])\n",
        "d = torch.tensor([2])\n",
        "\n",
        "e = a + b\n",
        "f = c * d \n",
        "\n",
        "g = e * f \n",
        "\n",
        "print(e, f, g)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-2]) tensor([-4]) tensor([8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkauonAKpodM"
      },
      "source": [
        "```\n",
        "Initialize random tensors x, y and z, each having shape (1000, 1000).\n",
        "Multiply x with y, putting the result in tensor q.\n",
        "Do an elementwise multiplication of tensor z with tensor q, putting the results in f\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lwPBgN9pn2F"
      },
      "source": [
        "# Initialize tensors x, y and z\n",
        "x = torch.rand(____, ____)\n",
        "y = ____\n",
        "z = ____\n",
        "\n",
        "# Multiply x with y\n",
        "q = ____\n",
        "\n",
        "# Multiply elementwise z with q\n",
        "f = ____\n",
        "\n",
        "mean_f = torch.mean(f)\n",
        "print(mean_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuuHBJzFpwga"
      },
      "source": [
        "### BackProp by auto diff "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y1FWwOE_R-O",
        "outputId": "260ca338-a17c-4ae8-8eef-2aa9f0addcb2"
      },
      "source": [
        "import torch \n",
        "\n",
        "x = torch.tensor(-3., requires_grad=True)\n",
        "y = torch.tensor(5., requires_grad= True)\n",
        "z = torch.tensor(-2., requires_grad=True)\n",
        "\n",
        "\n",
        "q = x + y \n",
        "f = q * z \n",
        "\n",
        "f.backward()\n",
        "\n",
        "print(\"gradient of z\", str(z.grad))\n",
        "print(\"gradient of y\", str(y.grad))\n",
        "print(\"gradient of x\", str(x.grad))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gradient of z tensor(2.)\n",
            "gradient of y tensor(-2.)\n",
            "gradient of x ['T', '__abs__', '__add__', '__and__', '__array__', '__array_priority__', '__array_wrap__', '__bool__', '__class__', '__complex__', '__contains__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__', '__idiv__', '__ifloordiv__', '__ilshift__', '__imod__', '__imul__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__long__', '__lshift__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pow__', '__radd__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rfloordiv__', '__rmul__', '__rpow__', '__rshift__', '__rsub__', '__rtruediv__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__torch_function__', '__truediv__', '__weakref__', '__xor__', '_backward_hooks', '_base', '_cdata', '_coalesced_', '_dimI', '_dimV', '_grad', '_grad_fn', '_indices', '_is_view', '_make_subclass', '_nnz', '_reduce_ex_internal', '_update_names', '_values', '_version', 'abs', 'abs_', 'absolute', 'absolute_', 'acos', 'acos_', 'acosh', 'acosh_', 'add', 'add_', 'addbmm', 'addbmm_', 'addcdiv', 'addcdiv_', 'addcmul', 'addcmul_', 'addmm', 'addmm_', 'addmv', 'addmv_', 'addr', 'addr_', 'align_as', 'align_to', 'all', 'allclose', 'amax', 'amin', 'angle', 'any', 'apply_', 'arccos', 'arccos_', 'arccosh', 'arccosh_', 'arcsin', 'arcsin_', 'arcsinh', 'arcsinh_', 'arctan', 'arctan_', 'arctanh', 'arctanh_', 'argmax', 'argmin', 'argsort', 'as_strided', 'as_strided_', 'as_subclass', 'asin', 'asin_', 'asinh', 'asinh_', 'atan', 'atan2', 'atan2_', 'atan_', 'atanh', 'atanh_', 'backward', 'baddbmm', 'baddbmm_', 'bernoulli', 'bernoulli_', 'bfloat16', 'bincount', 'bitwise_and', 'bitwise_and_', 'bitwise_not', 'bitwise_not_', 'bitwise_or', 'bitwise_or_', 'bitwise_xor', 'bitwise_xor_', 'bmm', 'bool', 'broadcast_to', 'byte', 'cauchy_', 'ceil', 'ceil_', 'char', 'cholesky', 'cholesky_inverse', 'cholesky_solve', 'chunk', 'clamp', 'clamp_', 'clamp_max', 'clamp_max_', 'clamp_min', 'clamp_min_', 'clip', 'clip_', 'clone', 'coalesce', 'conj', 'contiguous', 'copy_', 'copysign', 'copysign_', 'cos', 'cos_', 'cosh', 'cosh_', 'count_nonzero', 'cpu', 'cross', 'cuda', 'cummax', 'cummin', 'cumprod', 'cumprod_', 'cumsum', 'cumsum_', 'data', 'data_ptr', 'deg2rad', 'deg2rad_', 'dense_dim', 'dequantize', 'det', 'detach', 'detach_', 'device', 'diag', 'diag_embed', 'diagflat', 'diagonal', 'diff', 'digamma', 'digamma_', 'dim', 'dist', 'div', 'div_', 'divide', 'divide_', 'dot', 'double', 'dtype', 'eig', 'element_size', 'eq', 'eq_', 'equal', 'erf', 'erf_', 'erfc', 'erfc_', 'erfinv', 'erfinv_', 'exp', 'exp2', 'exp2_', 'exp_', 'expand', 'expand_as', 'expm1', 'expm1_', 'exponential_', 'fill_', 'fill_diagonal_', 'fix', 'fix_', 'flatten', 'flip', 'fliplr', 'flipud', 'float', 'float_power', 'float_power_', 'floor', 'floor_', 'floor_divide', 'floor_divide_', 'fmax', 'fmin', 'fmod', 'fmod_', 'frac', 'frac_', 'gather', 'gcd', 'gcd_', 'ge', 'ge_', 'geometric_', 'geqrf', 'ger', 'get_device', 'grad', 'grad_fn', 'greater', 'greater_', 'greater_equal', 'greater_equal_', 'gt', 'gt_', 'half', 'hardshrink', 'has_names', 'heaviside', 'heaviside_', 'histc', 'hypot', 'hypot_', 'i0', 'i0_', 'igamma', 'igamma_', 'igammac', 'igammac_', 'imag', 'index_add', 'index_add_', 'index_copy', 'index_copy_', 'index_fill', 'index_fill_', 'index_put', 'index_put_', 'index_select', 'indices', 'inner', 'int', 'int_repr', 'inverse', 'is_coalesced', 'is_complex', 'is_contiguous', 'is_cuda', 'is_distributed', 'is_floating_point', 'is_leaf', 'is_meta', 'is_mkldnn', 'is_nonzero', 'is_pinned', 'is_quantized', 'is_same_size', 'is_set_to', 'is_shared', 'is_signed', 'is_sparse', 'is_vulkan', 'is_xpu', 'isclose', 'isfinite', 'isinf', 'isnan', 'isneginf', 'isposinf', 'isreal', 'istft', 'item', 'kron', 'kthvalue', 'layout', 'lcm', 'lcm_', 'ldexp', 'ldexp_', 'le', 'le_', 'lerp', 'lerp_', 'less', 'less_', 'less_equal', 'less_equal_', 'lgamma', 'lgamma_', 'log', 'log10', 'log10_', 'log1p', 'log1p_', 'log2', 'log2_', 'log_', 'log_normal_', 'log_softmax', 'logaddexp', 'logaddexp2', 'logcumsumexp', 'logdet', 'logical_and', 'logical_and_', 'logical_not', 'logical_not_', 'logical_or', 'logical_or_', 'logical_xor', 'logical_xor_', 'logit', 'logit_', 'logsumexp', 'long', 'lstsq', 'lt', 'lt_', 'lu', 'lu_solve', 'map2_', 'map_', 'masked_fill', 'masked_fill_', 'masked_scatter', 'masked_scatter_', 'masked_select', 'matmul', 'matrix_exp', 'matrix_power', 'max', 'maximum', 'mean', 'median', 'min', 'minimum', 'mm', 'mode', 'moveaxis', 'movedim', 'msort', 'mul', 'mul_', 'multinomial', 'multiply', 'multiply_', 'mv', 'mvlgamma', 'mvlgamma_', 'name', 'names', 'nan_to_num', 'nan_to_num_', 'nanmedian', 'nanquantile', 'nansum', 'narrow', 'narrow_copy', 'ndim', 'ndimension', 'ne', 'ne_', 'neg', 'neg_', 'negative', 'negative_', 'nelement', 'new', 'new_empty', 'new_empty_strided', 'new_full', 'new_ones', 'new_tensor', 'new_zeros', 'nextafter', 'nextafter_', 'nonzero', 'norm', 'normal_', 'not_equal', 'not_equal_', 'numel', 'numpy', 'orgqr', 'ormqr', 'outer', 'output_nr', 'permute', 'pin_memory', 'pinverse', 'polygamma', 'polygamma_', 'pow', 'pow_', 'prelu', 'prod', 'put_', 'q_per_channel_axis', 'q_per_channel_scales', 'q_per_channel_zero_points', 'q_scale', 'q_zero_point', 'qr', 'qscheme', 'quantile', 'rad2deg', 'rad2deg_', 'random_', 'ravel', 'real', 'reciprocal', 'reciprocal_', 'record_stream', 'refine_names', 'register_hook', 'reinforce', 'relu', 'relu_', 'remainder', 'remainder_', 'rename', 'rename_', 'renorm', 'renorm_', 'repeat', 'repeat_interleave', 'requires_grad', 'requires_grad_', 'reshape', 'reshape_as', 'resize', 'resize_', 'resize_as', 'resize_as_', 'retain_grad', 'roll', 'rot90', 'round', 'round_', 'rsqrt', 'rsqrt_', 'scatter', 'scatter_', 'scatter_add', 'scatter_add_', 'select', 'set_', 'sgn', 'sgn_', 'shape', 'share_memory_', 'short', 'sigmoid', 'sigmoid_', 'sign', 'sign_', 'signbit', 'sin', 'sin_', 'sinc', 'sinc_', 'sinh', 'sinh_', 'size', 'slogdet', 'smm', 'softmax', 'solve', 'sort', 'sparse_dim', 'sparse_mask', 'sparse_resize_', 'sparse_resize_and_clear_', 'split', 'split_with_sizes', 'sqrt', 'sqrt_', 'square', 'square_', 'squeeze', 'squeeze_', 'sspaddmm', 'std', 'stft', 'storage', 'storage_offset', 'storage_type', 'stride', 'sub', 'sub_', 'subtract', 'subtract_', 'sum', 'sum_to_size', 'svd', 'swapaxes', 'swapaxes_', 'swapdims', 'swapdims_', 'symeig', 't', 't_', 'take', 'tan', 'tan_', 'tanh', 'tanh_', 'tensor_split', 'tile', 'to', 'to_dense', 'to_mkldnn', 'to_sparse', 'tolist', 'topk', 'trace', 'transpose', 'transpose_', 'triangular_solve', 'tril', 'tril_', 'triu', 'triu_', 'true_divide', 'true_divide_', 'trunc', 'trunc_', 'type', 'type_as', 'unbind', 'unflatten', 'unfold', 'uniform_', 'unique', 'unique_consecutive', 'unsafe_chunk', 'unsafe_split', 'unsafe_split_with_sizes', 'unsqueeze', 'unsqueeze_', 'values', 'var', 'vdot', 'view', 'view_as', 'where', 'xlogy', 'xlogy_', 'xpu', 'zero_']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlGB-BYKqUb0"
      },
      "source": [
        "```\n",
        "Initialize tensors x, y and z to values 4, -3 and 5.\n",
        "Put the sum of tensors x and y in q, put the product of q and z in f.\n",
        "Calculate the derivatives of the computational graph.\n",
        "Print the gradients of the x, y and z tensors.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jGU8ljPqVyM"
      },
      "source": [
        "# Initialize x, y and z to values 4, -3 and 5\n",
        "x = torch.tensor(4., ____)\n",
        "y = torch.tensor(____., ____)\n",
        "z = ____\n",
        "\n",
        "# Set q to sum of x and y, set f to product of q with z\n",
        "q = ____\n",
        "f = ____\n",
        "\n",
        "# Compute the derivatives\n",
        "f.____\n",
        "\n",
        "# Print the gradients\n",
        "print(\"Gradient of x is: \" + str(____))\n",
        "print(\"Gradient of y is: \" + str(____))\n",
        "print(\"Gradient of z is: \" + str(____))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GR5rPoAqk4V"
      },
      "source": [
        "```\n",
        "Multiply tensors x and y, put the product in tensor q.\n",
        "Do an elementwise multiplication of tensors z with q.\n",
        "Calculate the gradients.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQElDX28pyS4"
      },
      "source": [
        "x = torch.randn(1000,1000)\n",
        "y = torch.randn(1000,1000)\n",
        "z = torch.randn(1000,1000)\n",
        "# Multiply tensors x and y\n",
        "q = ____\n",
        "\n",
        "# Elementwise multiply tensors z with q\n",
        "f = ____\n",
        "\n",
        "mean_f = torch.mean(f)\n",
        "\n",
        "# Calculate the gradients\n",
        "____"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAt6Yu19rV1b"
      },
      "source": [
        "### Intro to Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7s4Y8hwBaEP",
        "outputId": "bb0b128b-420c-475b-b8bc-1ee03fe55bd1"
      },
      "source": [
        "import torch \n",
        "\n",
        "input_layer = torch.rand(10)\n",
        "\n",
        "w1 = torch.rand(10, 20)\n",
        "w2 = torch.rand(20,20)\n",
        "w3 = torch.rand(20, 4)\n",
        "\n",
        "h1 = torch.matmul(input_layer, w1) \n",
        "output = torch.matmul(h2, w3)\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([270.1283, 314.6077, 293.9081, 265.2788])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdaWzgUvCGxU"
      },
      "source": [
        "### Pytorch way "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqIIRTTdCGNI",
        "outputId": "718a0752-d215-4e12-97e0-04a3e8e591af"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn \n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__() # calling the super class constructor \n",
        "    self.fc1  =  nn.Linear(10,20, bias=False)\n",
        "    self.fc2  =  nn.Linear(20,20)\n",
        "    self.output = nn.Linear(20,4)\n",
        "\n",
        "  def forward(self, X):\n",
        "    x1 = self.fc1(X)\n",
        "    x2 = self.fc2(x1)\n",
        "    x3 = self.output(x2)\n",
        "    return x3\n",
        "\n",
        "input_layer = torch.rand(10)\n",
        "net = Net()\n",
        "result = net(input_layer)\n",
        "\n",
        "print(result)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.1085, -0.1558, -0.2881,  0.3149], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgWhfpxNEH01",
        "outputId": "e96620d3-8df2-4f26-8a1e-ed7e8f19bb98"
      },
      "source": [
        "print(net.fc1.bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiJ6Cjsjrcck"
      },
      "source": [
        "Your input will be images of size `(28, 28)`, so images containing 784 pixels. Your network will contain an input_layer (provided for you), a hidden layer with `200 `units, and an output layer with `10` classes. The input layer has already been created for you. You are going to create the weights, and then do matrix multiplications, getting the results from the network.\n",
        "\n",
        "```\n",
        "Initialize with random numbers two matrices of weights, called weight_1 and weight_2.\n",
        "Set the result of input_layer times weight_1 to hidden_1. Set the result of hidden_1 times weight_2 to output_layer.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pEOw1pTrXP5"
      },
      "source": [
        "# Initialize the weights of the neural network\n",
        "weight_1 = torch.rand(____, ____)\n",
        "weight_2 = ____\n",
        "\n",
        "# Multiply input_layer with weight_1\n",
        "hidden_1 = torch.matmul(____, ____)\n",
        "\n",
        "# Multiply hidden_1 with weight_2\n",
        "output_layer = ____\n",
        "print(output_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUOo6zcQrpxq"
      },
      "source": [
        "You are going to build the same neural network you built in the previous exercise, but now using the PyTorch way. As a reminder, you have 784 units in the input layer, 200 hidden units and 10 units for the output layer.\n",
        "\n",
        "```\n",
        "Instantiate two linear layers calling them self.fc1 and self.fc2. Determine their correct dimensions.\n",
        "Implement the .forward() method, using the two layers you defined and returning x.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY8hpH1frwMT"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Instantiate all 2 linear layers  \n",
        "        self.fc1 = nn.Linear(____, ____)\n",
        "        self.fc2 = ____\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "        # Use the instantiated layers and return x\n",
        "        x = self.fc1(x)\n",
        "        x = ____\n",
        "        return ____"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id8vRM02sT1b"
      },
      "source": [
        "## Activation functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1XPx-r5CpPq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU2kuCUaCprF",
        "outputId": "467a2556-fdd3-4103-8492-3d7a8c6ffbc9"
      },
      "source": [
        "import torch \n",
        "\n",
        "input_layer = torch.tensor([2., 1.])\n",
        "weight1 = torch.tensor([[0.45, 0.32], [-0.12, 0.29]])\n",
        "h1 = torch.matmul(input_layer, weight1)\n",
        "weight2 = torch.tensor([[0.48, -0.12], [0.64, 0.91]])\n",
        "output_layer = torch.matmul(h1, weight2)\n",
        "print(output_layer)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.9696, 0.7527])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJCtlnrID93m",
        "outputId": "ccbceeee-2c07-4ccd-98fb-4f1b2ff76265"
      },
      "source": [
        "weight = torch.matmul(weight1, weight2)\n",
        "output = torch.matmul(input_layer, weight)\n",
        "print(weight)\n",
        "print(output_layer)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4208, 0.2372],\n",
            "        [0.1280, 0.2783]])\n",
            "tensor([0.9696, 0.7527])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3umS_5GEkdr"
      },
      "source": [
        "ReLU in torch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOPJPxmrEma9",
        "outputId": "3d5dba11-cd2b-4120-9604-1d256c04607d"
      },
      "source": [
        "import torch.nn as nn \n",
        "\n",
        "relu = nn.ReLU()\n",
        "\n",
        "tensor1 = torch.tensor([2., -4.])\n",
        "\n",
        "print(relu(tensor1))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5HWWnQsExnT",
        "outputId": "e99f22f7-e8ad-446a-b1ee-c1ad1676dc5c"
      },
      "source": [
        "import torch.nn as nn \n",
        "\n",
        "relu = nn.ReLU()\n",
        "\n",
        "tensor2 = torch.tensor([[2., -4.], [1.2, 0]])\n",
        "\n",
        "print(relu(tensor2))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.0000, 0.0000],\n",
            "        [1.2000, 0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyG9LfHsscW8"
      },
      "source": [
        "Neural networks\n",
        "\n",
        "Let us see the differences between neural networks which apply ReLU and those which do not apply ReLU. We have already initialized the input called input_layer, and three sets of weights, called weight_1, weight_2 and weight_3.\n",
        "\n",
        "We are going to convince ourselves that networks with multiple layers which do not contain non-linearity can be expressed as neural networks with one layer.\n",
        "\n",
        "The network and the shape of layers and weights is shown below.\n",
        "\n",
        "```\n",
        "Calculate the first and second hidden layer by multiplying the appropriate inputs with the corresponding weights.\n",
        "Calculate and print the results of the output.\n",
        "Set weight_composed_1 to the product of weight_1 with weight_2, then set weight to the product of weight_composed_1 with weight_3.\n",
        "Calculate and print the output.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "424V1VCGsVqS"
      },
      "source": [
        "# Calculate the first and second hidden layer\n",
        "hidden_1 = torch.matmul(____, ____)\n",
        "hidden_2 = torch.matmul(____, ____)\n",
        "\n",
        "# Calculate the output\n",
        "print(torch.matmul(____, ____))\n",
        "\n",
        "# Calculate weight_composed_1 and weight\n",
        "weight_composed_1 = torch.matmul(____, ____)\n",
        "weight = torch.matmul(____, ____)\n",
        "\n",
        "# Multiply input_layer with weight\n",
        "print(torch.matmul(____, ____))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDv_xv__sk92"
      },
      "source": [
        "ReLU activation\n",
        "\n",
        "In this exercise, we have the same settings as the previous exercise. But now we are going to build a neural network which has non-linearity. By doing so, we are going to convince ourselves that networks with multiple layers and non-linearity functions cannot be expressed as a neural network with one layer.\n",
        "\n",
        "```\n",
        "Apply the non-linearity to the two hidden layers and print the result.\n",
        "Apply the non-linearity to the product of first two weights.\n",
        "Multiply the result of the previous step with weight_3.\n",
        "Multiply input_layer with weight and print the results\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2eJZHj1swzp"
      },
      "source": [
        "# Instantiate non-linearity\n",
        "relu = nn.ReLU()\n",
        "\n",
        "# Apply non-linearity on the hidden layers\n",
        "hidden_1_activated = ____(torch.matmul(input_layer, weight_1))\n",
        "hidden_2_activated = ____(torch.matmul(hidden_1_activated, weight_2))\n",
        "print(torch.matmul(hidden_2_activated, weight_3))\n",
        "\n",
        "# Apply non-linearity in the product of first two weights. \n",
        "weight_composed_1_activated = ____(torch.matmul(weight_1, weight_2))\n",
        "\n",
        "# Multiply `weight_composed_1_activated` with `weight_3\n",
        "weight = torch.matmul(____, ____)\n",
        "\n",
        "# Multiply input_layer with weight\n",
        "print(torch.matmul(____, ____))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bHRnj9Fsxxs"
      },
      "source": [
        "### Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x2G8uwvtLpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1df857d-11a2-4b1a-beda-be1ac851b62c"
      },
      "source": [
        "logits =  torch.tensor([[3.2, 5.1, -1.7]])\n",
        "ground_truth = torch.tensor([0])\n",
        "\n",
        "#loss function \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "loss = criterion(logits, ground_truth)\n",
        "\n",
        "print(loss)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.0404)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9UMgeoMICgF",
        "outputId": "656b63b5-a0c3-44ad-da9c-3f323b40d895"
      },
      "source": [
        "logits = torch.tensor([[10.2, 5.1, -1.7]])\n",
        "\n",
        "loss = criterion(logits, ground_truth)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0061)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2joicHA9IfB0",
        "outputId": "0d587e41-84d2-45af-f4c1-2564d78192b3"
      },
      "source": [
        "logits = torch.tensor([[-10.2, 5.1, -1.7]])\n",
        "\n",
        "loss = criterion(logits, ground_truth)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(15.3011)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CMkxbk1tWoY"
      },
      "source": [
        "```\n",
        "Initialize the tensor of scores with numbers [[-1.2, 0.12, 4.8]], and the tensor of ground truth [2].\n",
        "Instantiate the cross-entropy loss and call it criterion.\n",
        "Compute and print the loss.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB_AThjFtYXi"
      },
      "source": [
        "# Initialize the scores and ground truth\n",
        "logits = ____\n",
        "ground_truth = ____\n",
        "\n",
        "# Instantiate cross entropy loss\n",
        "criterion = nn.____\n",
        "\n",
        "# Compute and print the loss\n",
        "loss = ____\n",
        "print(____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_5ZrfgFtfXh"
      },
      "source": [
        "Loss function of random scores\n",
        "\n",
        "If the neural network predicts random scores, what would be its loss function? Let's find it out in PyTorch. The neural network is going to have 1000 classes, each having a random score. For ground truth, it will have class 111. Calculate the loss function.\n",
        "\n",
        "```\n",
        "Import torch and torch.nn as nn\n",
        "Initialize logits with a random tensor of shape (1, 1000) and ground_truth with a tensor containing the number 111.\n",
        "Instantiate the cross-entropy loss in a variable called criterion.\n",
        "Calculate and print the loss function.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrhSxS4Rx_zM"
      },
      "source": [
        "### Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "196b7fe28125448483de37fd0204320d",
            "983b9e643d3442a6963bfff54b7bbd21",
            "1dc8c48df5884c91bd677ba6aa8d7529",
            "a9c1bef5dc20400bb088d27a2471757d",
            "84856d6c663e43f584fe95827f7a1b52",
            "21256292750d436e9de86bade77d51ca",
            "159a217131294e3d808a4a39dd0ab0f8",
            "ad7832a5d41b4549b1ae719775d69bb0"
          ]
        },
        "id": "u3tvlJOTO_rr",
        "outputId": "61471bec-217e-4855-92ba-12e200012e0b"
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torch.utils.data \n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914, 0.48216, 0.44543),\n",
        "                          (0.24703, 0.24349, 0.26519))])\n",
        "\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train = True, download = True, transform = transform)\n",
        "testset = torchvision.datasets.CIFAR10(root=\"./data\", train = False, download = True, transform = transform)\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle = True, num_workers = 4)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle = False, num_workers = 4)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "196b7fe28125448483de37fd0204320d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNKbiGG-RyVv",
        "outputId": "f8678d0c-44b2-4e76-e15d-4ce1e87a9d29"
      },
      "source": [
        "# dataloader \n",
        "\n",
        "print(testloader.dataset.data.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2STd1LpuyCgV"
      },
      "source": [
        "Preparing MNIST dataset\n",
        "\n",
        "You are going to prepare dataloaders for MNIST training and testing set. As we explained in the lecture, MNIST has some differences to CIFAR-10, with the main difference being that MNIST images are grayscale (1 channel based) instead of RGB (3 channels).\n",
        "\n",
        "```\n",
        "Transform the data to torch tensors and normalize it to have mean is 0.1307 and std is 0.3081.\n",
        "Prepare the trainset and the testset.\n",
        "Prepare the dataloaders for training and testing so that only 32 pictures are processed at a time and the training data is shuffled each time.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sX2qRCKtib3"
      },
      "source": [
        "# Transform the data to torch tensors and normalize it \n",
        "transform = transforms.Compose([transforms.____,\n",
        "\t\t\t\t\t\t\t\ttransforms.____((____), ((____)))])\n",
        "\n",
        "# Prepare training set and testing set\n",
        "trainset = torchvision.datasets.MNIST('mnist', train=____, \n",
        "\t\t\t\t\t\t\t\t\t  download=____, transform=____)\n",
        "testset = ____('mnist', ____,\n",
        "\t\t\t   ____, ____)\n",
        "\n",
        "# Prepare training loader and testing loader\n",
        "trainloader = torch.utils.data.DataLoader(____, ____,\n",
        "                                          ____, num_workers=0)\n",
        "testloader = torch.utils.data.DataLoader(____, ____,\n",
        "\t\t\t\t\t\t\t\t\t\t ____, num_workers=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMW8VszxyPWX"
      },
      "source": [
        "Inspecting the dataloaders\n",
        "\n",
        "Now you are going to explore a bit the dataloaders you created in the previous exercise. In particular, you will compute the shape of the dataset in addition to the minibatch size.\n",
        "\n",
        "```\n",
        "Find the shapes of the trainset and testset.\n",
        "Print the computed values.\n",
        "Find the size of the minibatch for both trainset and testset.\n",
        "Print the minibatch size.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD5_oWoB8OhF"
      },
      "source": [
        "# Compute the shape of the training set and testing set\n",
        "trainset_shape = ____.____.____.____\n",
        "testset_shape = ____.____.____.____\n",
        "\n",
        "# Print the computed shapes\n",
        "print(____, ____)\n",
        "\n",
        "# Compute the size of the minibatch for training set and testing set\n",
        "trainset_batchsize = ____.____\n",
        "testset_batchsize = ____.____\n",
        "\n",
        "# Print sizes of the minibatch\n",
        "print(____, ____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IgYGBUUzLsR"
      },
      "source": [
        "### Training a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aWUr3myzXyc"
      },
      "source": [
        "Build a class for a neural network which will be used to train on the MNIST dataset. The dataset contains images of shape (28, 28, 1), so you should deduct the size of the input layer. For hidden layer use 200 units, while for output layer use 10 units (1 for each class). For activation function, use relu in a functional way (nn.Functional is already imported as F).\n",
        "\n",
        "For context, the same net will be trained and used to make predictions in the next two exercises.\n",
        "\n",
        "```\n",
        "Define the class called Net which inherits from nn.Module.\n",
        "In the __init__() method, define the parameters for the two fully connected layers.\n",
        "In the .forward() method, do the forward step.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou-Ii07OzNLj"
      },
      "source": [
        "# Define the class Net\n",
        "____:\n",
        "    def __init__(self):    \n",
        "    \t# Define all the parameters of the net\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(____ * ____ * ____, ____)\n",
        "        self.fc2 = ____\n",
        "\n",
        "    def forward(self, x):   \n",
        "    \t# Do the forward pass\n",
        "        x = F.relu(self.fc1(____))\n",
        "        x = self.____(____)\n",
        "        return ____"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3KhFZukzdIJ"
      },
      "source": [
        "Given the fully connected neural network (called model) which you built in the previous exercise and a train loader called train_loader containing the MNIST dataset (which we created for you), you're to train the net in order to predict the classes of digits. You will use the Adam optimizer to optimize the network, and considering that this is a classification problem you are going to use cross entropy as loss function.\n",
        "\n",
        "```\n",
        "Instantiate the Adam optimizer with learning rate 3e-4 and instantiate Cross-Entropy as loss function.\n",
        "Complete a forward pass on the neural network using the input data.\n",
        "Using backpropagation, compute the gradients of the weights, and then change the weights using the Adam optimizer.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xozTRQq60j0g"
      },
      "source": [
        "# do not change\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('./data/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/data/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_test, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1umrL1ENztm4"
      },
      "source": [
        "# Instantiate the Adam optimizer and Cross-Entropy loss function\n",
        "model = Net()   \n",
        "optimizer = optim.Adam(____.parameters(), lr=3e-4)\n",
        "criterion = nn.____\n",
        "  \n",
        "for batch_idx, data_target in enumerate(train_loader):\n",
        "    data = data_target[0]\n",
        "    target = data_target[1]\n",
        "    data = data.view(-1, 28 * 28)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Complete a forward pass\n",
        "    output = model(____)\n",
        "\n",
        "    # Compute the loss, gradients and change the weights\n",
        "    loss = ____\n",
        "    loss.____\n",
        "    optimizer.____"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKC0M1nwzvnj"
      },
      "source": [
        "Using the network to make predictions\n",
        "\n",
        "Now that you have trained the network, use it to make predictions for the data in the testing set. The network is called model (same as in the previous exercise), and the loader is called test_loader. We have already initialized variables total and correct to 0.\n",
        "\n",
        "```\n",
        "Set the network in testing (eval) mode.\n",
        "Put each image into a vector using inputs.view(-1, number_of_features) where the number of features should be deducted by multiplying spatial dimensions (shape) of the image.\n",
        "Do the forward pass and put the predictions in output variable.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytMdslMCz1iG"
      },
      "source": [
        "# Set the model in eval mode\n",
        "model.____\n",
        "\n",
        "for i, data in enumerate(test_loader, 0):\n",
        "    inputs, labels = data\n",
        "    \n",
        "    # Put each image into a vector\n",
        "    inputs = inputs.view(-1, ____)\n",
        "    \n",
        "    # Do the forward pass and get the predictions\n",
        "    outputs = ____\n",
        "    _, outputs = torch.max(____.data, ____)\n",
        "    total += labels.size(0)\n",
        "    correct += (outputs == labels).sum().item()\n",
        "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLUo1VvHIv7F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxBWU6uuIwJG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9YrPuAUIwMo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMJBk7EhIwPY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBu3OJ8GIwRy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swgXv3PlIwT4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0Ct4xVIIwWP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncUb8pqbIwYk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzS_aKWQKlLO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0olW9ChIwbJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v3Cqo9kIwdi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYJ8ro-HIwgW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "magjuSR4Iwil"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMAv4O5IIwk_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZKQESlUIwnP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoR5BVp4IwqI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvyOyoW1Iwsr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5De6qARFIwu3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vjn9PODQIwww"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2AyI893Iw0N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98UC7C7zIw3H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJc9rSRPIw6P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}