{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Networks -1 .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+xizpWnnAaMALv5mpE1XC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avs20/DeepLearningHindi/blob/main/Neural_Networks_1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e74fnyNIoYf"
      },
      "source": [
        "What basically happnes at each neuron?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvL4UIaKIGow",
        "outputId": "24e214bd-fc3c-4b4a-8b80-925ad9bf5dd4"
      },
      "source": [
        "inputs = [1, 2, 3]\n",
        "weights = [0.2, 0.8, -0.5]\n",
        "bias = 2 \n",
        "\n",
        "output = ( inputs[0]*weights[0] + \n",
        "           inputs[1]*weights[1] + \n",
        "           inputs[2]*weights[2] + bias )\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy0L4BGNIxif"
      },
      "source": [
        "What if we have 4 inputs?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxhROePckKwJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBdiGDa0Il1M",
        "outputId": "05e9737d-aa0c-4577-9c38-0bd230b97c95"
      },
      "source": [
        "inputs = [1, 2, 3, 2.5]\n",
        "weights = [0.2, 0.8, -0.5, 1.0]\n",
        "bias = 2 \n",
        "\n",
        "output = ( inputs[0]*weights[0] + \n",
        "           inputs[1]*weights[1] + \n",
        "           inputs[2]*weights[2] + \n",
        "           inputs[3]*weights[3] + bias )\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGkKBqzJJKHO"
      },
      "source": [
        "Layers have more than 1 neurons.\n",
        "Each neuron in the neuron takes the same input, input given to the layer. \n",
        "But each neuron has it's own weight and bias\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hyZssrrI8gc",
        "outputId": "ea7018f1-6fd2-4807-a161-05c6516b15c7"
      },
      "source": [
        "inputs = [1, 2, 3, 2.5]\n",
        "weights0 = [0.2, 0.8, -0.5, 1.0]\n",
        "weights1 = [0.4,0.8,-0.6,-0.7]\n",
        "weights2 = [0.9, 0.4, 0.8, 0.9]\n",
        "\n",
        "bias1 = 2.0\n",
        "bias2 = -1.0\n",
        "bias3 = 0\n",
        "\n",
        "output = [ inputs[0] * weights0[0] + inputs[1] * weights0[1] + inputs[2] * weights0[2] + inputs[3]* weights0[3] + bias1 ,\n",
        "           inputs[0] * weights1[0] + inputs[1] * weights1[1] + inputs[2] * weights1[2] + inputs[3]* weights1[3] + bias2 ,\n",
        "           inputs[0] * weights2[0] + inputs[1] * weights2[1] + inputs[2] * weights2[2] + inputs[3]* weights2[3] + bias3 ]\n",
        "    \n",
        "print(output)\n",
        "          "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.8, -2.55, 6.3500000000000005]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9oDIaLrKdRF",
        "outputId": "fef30ef8-c684-41c3-a0bf-06e0c3202587"
      },
      "source": [
        "inputs = [1, 2, 3, 2.5]\n",
        "weights = [[0.2, 0.8, -0.5, 1.0],\n",
        "           [0.4,0.8,-0.6,-0.7],\n",
        "           [0.9, 0.4, 0.8, 0.9]]\n",
        "biases = [2.0, -1.0, 0]\n",
        "\n",
        "layer_outputs = []\n",
        "\n",
        "for neuron_weights, bias in zip(weights, biases):\n",
        "  output = 0\n",
        "\n",
        "  for input, weight in zip(inputs, neuron_weights):\n",
        "    output += input * weight\n",
        "  \n",
        "  # add bias \n",
        "  output += bias\n",
        "\n",
        "  # add to final \n",
        "  layer_outputs.append(output)\n",
        "\n",
        "print(layer_outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.8, -2.55, 6.3500000000000005]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCyeFkucUsSO"
      },
      "source": [
        "Vectors and Dot product"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY6a05loLQnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2564ba1-4134-4ba2-aec8-eccb426d371a"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "inputs = [1, 2, 3]\n",
        "weights = [0.2, 0.8, -0.5]\n",
        "bias = 2 \n",
        "\n",
        "output = np.dot(inputs, weights) + bias\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrraL0QSVUQE"
      },
      "source": [
        "Layer of neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8c6IM3WU4Fl",
        "outputId": "97faf19b-2ef6-43d7-b534-805b6e03b843"
      },
      "source": [
        "inputs = [1, 2, 3, 2.5]\n",
        "weights = [[0.2, 0.8, -0.5, 1.0],\n",
        "           [0.4,0.8,-0.6,-0.7],\n",
        "           [0.9, 0.4, 0.8, 0.9]]\n",
        "biases = [2.0, -1.0, 0]\n",
        "\n",
        "layer_outputs = np.dot(weights, inputs) +biases\n",
        "\n",
        "\n",
        "\n",
        "print(layer_outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 4.8  -2.55  6.35]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "iyORlXIrVaUq",
        "outputId": "ebc8f7fe-502b-4226-873a-80fb92f28172"
      },
      "source": [
        "inputs = [1, 2, 3, 2.5]\n",
        "weights = [[0.2, 0.8, -0.5, 1.0],\n",
        "           [0.4,0.8,-0.6,-0.7],\n",
        "           [0.9, 0.4, 0.8, 0.9]]\n",
        "biases = [2.0, -1.0, 0]\n",
        "\n",
        "layer_outputs = np.dot(inputs, weights) +biases\n",
        "\n",
        "\n",
        "\n",
        "print(layer_outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-30a4b0238793>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (4,) and (3,4) not aligned: 4 (dim 0) != 3 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgZhz87FngIG",
        "outputId": "8c0e5c3c-621a-460a-fd41-d3be59fd4b11"
      },
      "source": [
        "import numpy as np \n",
        "inputs = [1, 2, 3]\n",
        "weights = [[0.2, 0.8, -0.5 ],\n",
        "           [0.4,0.8,-0.6],\n",
        "           [0.9, 0.4, 0.8]]\n",
        "biases = [2.0, -1.0, 0]\n",
        "\n",
        "layer_outputs = np.dot(inputs, weights) +biases\n",
        "\n",
        "\n",
        "\n",
        "print(layer_outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5.7 2.6 0.7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2yAVEmdXEA_"
      },
      "source": [
        "matrix multiplication is dot product of combination of rows from the first matrix and columns from the second matrix. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeCYG-z9Wr9Q"
      },
      "source": [
        "Data is often comes in input batche. \n",
        "\n",
        "What is a batch? a group of input data at a time. \n",
        "\n",
        "Now we need to multiply this group of input data with group of weights both are matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A46Sa9yrVkbz",
        "outputId": "10d64988-89fe-46cf-acdb-551ed143e026"
      },
      "source": [
        "a = np.array([1,2,3])\n",
        "b = np.array([4,5,6])\n",
        "\n",
        "output = np.dot(a,b)\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34MYLcCW9kwR"
      },
      "source": [
        "Batch of data with layer of neurons\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-fMTywLW0nd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b51d149-32ae-4664-caae-61997ae8a3da"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "inputs = [[1.0, 2.0, 3.0, 2.5],\n",
        "          [2.0,5.0,-1.0,2.0],\n",
        "          [-1/5, 2.7, 3.3, -0.8]]\n",
        "      \n",
        "weights = [[0.2, 0.8, -0.5, 1.0],\n",
        "           [0.5, -0.91, 0.26, -0.5],\n",
        "           [-0.26, -0.27, 0.17, 0.87]]\n",
        "\n",
        "biases  = [2.0, 3.0, 0.5]\n",
        "\n",
        "layer_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
        "\n",
        "print(layer_outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 4.8    1.21   2.385]\n",
            " [ 8.9   -1.81   0.2  ]\n",
            " [ 1.67   1.701 -0.312]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIp1P2tXJgu4"
      },
      "source": [
        "## More hidden layers and non-linear data\n",
        "\n",
        "A deep neural network is a neural network with 2 or more hidden layers\n",
        "\n",
        "So for each layer we will have a different set of weights\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88MZDkRZ-Pfl"
      },
      "source": [
        "import numpy as np \n",
        "inputs = [1, 2, 3]\n",
        "weights = [[0.2, 0.8, -0.5 ],\n",
        "           [0.4,0.8,-0.6],\n",
        "           [0.9, 0.4, 0.8]]\n",
        "biases = [2.0, -1.0, 0]\n",
        "\n",
        "weights2 = [[ 0.1, -0.14, 0.5],\n",
        "            [-0.5, 0.12, -0.33],\n",
        "            [-0.44, 0.73, -0.13]]\n",
        "\n",
        "biases2 = [-1,2, -0.5]\n",
        "\n",
        "layer_outputs = np.dot(inputs, weights) +biases\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWRQ-FjsKHHJ"
      },
      "source": [
        "###Q how many neurons we have in the second layer?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtAwEp2uKK-B",
        "outputId": "cdde02f8-6a59-4447-cf73-fa0bb0b34630"
      },
      "source": [
        "import numpy as np \n",
        "inputs = [[1.0, 2.0, 3.0, 2.5],\n",
        "          [2.0,5.0,-1.0,2.0],\n",
        "          [-1/5, 2.7, 3.3, -0.8]]\n",
        "weights = [[0.2, 0.8, -0.5, 1.0],\n",
        "           [0.5, -0.91, 0.26, -0.5],\n",
        "           [-0.26, -0.27, 0.17, 0.87]]\n",
        "biases = [2.0, -1.0, 0]\n",
        "\n",
        "weights2 = [[ 0.1, -0.14, 0.5],\n",
        "            [-0.5, 0.12, -0.33],\n",
        "            [-0.44, 0.73, -0.13]]\n",
        "\n",
        "biases2 = [-1, 2, -0.5]\n",
        "\n",
        "layer1_outputs = np.dot(inputs, np.array(weights).T) +biases\n",
        "\n",
        "\n",
        "layer2_outputs = np.dot(layer1_outputs, np.array(weights2).T) + biases2\n",
        "\n",
        "print(layer2_outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.8131  -1.35685 -4.89375]\n",
            " [ 0.5534  -3.0482  -8.6183 ]\n",
            " [-0.91714  1.15708 -2.80751]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZrI_VM7KYHk",
        "outputId": "8f9b114e-5cc6-4d3a-9ea0-ca51127dc367"
      },
      "source": [
        "!pip install nnfs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nnfs\n",
            "  Downloading https://files.pythonhosted.org/packages/06/8c/3003a41d5229e65da792331b060dcad8100a0a5b9760f8c2074cde864148/nnfs-0.5.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nnfs) (1.19.5)\n",
            "Installing collected packages: nnfs\n",
            "Successfully installed nnfs-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9zr04ZsLDj5"
      },
      "source": [
        "import nnfs\n",
        "nnfs.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "6_5HFYddLK3U",
        "outputId": "e6514424-73c4-4baa-e16a-6fb97cf4e168"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from nnfs.datasets import spiral_data\n",
        "X,y = spiral_data(samples=100, classes=3)\n",
        "plt.scatter(X[:,0], X[:,1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "lnO35ahILaUB",
        "outputId": "250817a6-c3df-4bbd-bb29-1314919e75b1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from nnfs.datasets import spiral_data\n",
        "X,y = spiral_data(samples=100, classes=3)\n",
        "plt.scatter(X[:,0], X[:,1], c = y, cmap='brg')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocLIqmziL4VI"
      },
      "source": [
        "## Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65n7_RRpLw0S",
        "outputId": "4631f07e-a622-4d1c-f568-f64ba09fe00c"
      },
      "source": [
        "import numpy as np \n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "#Dense Layer\n",
        "class Layer_Dense:\n",
        "\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    #initialize weight and biases\n",
        "    self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "    self.biases = np.zeros((1,n_neurons))\n",
        "\n",
        "  # forwards pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "# test class\n",
        "\n",
        "X,y = spiral_data(samples = 100, classes=3)\n",
        "\n",
        "#create the layer\n",
        "dense1 = Layer_Dense(2, 3)\n",
        "\n",
        "#perform a forward pass\n",
        "dense1.forward(X)\n",
        "\n",
        "# see output\n",
        "print(dense1.output[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [-1.0475188e-04  1.1395361e-04 -4.7983500e-05]\n",
            " [-2.7414842e-04  3.1729150e-04 -8.6921798e-05]\n",
            " [-4.2188365e-04  5.2666257e-04 -5.5912682e-05]\n",
            " [-5.7707680e-04  7.1401405e-04 -8.9430439e-05]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4ElCfFS-o3U"
      },
      "source": [
        "### Activation Functions\n",
        "\n",
        "Activation function is applied to the output of a neuron, which modifies outputs.\n",
        "\n",
        "We use activation function because is activation function is non-linear, it allows for neural networks with 2 or more layers to map non-linear functions.\n",
        "\n",
        "There are generally 2 types of activation functions used in NN. \n",
        "One in the hidden layers and 1 in the final output layer. \n",
        "\n",
        "How non-linearity comes will see later. Generally there are following types \n",
        "\n",
        "1. Step activation function \n",
        "2. Linear activation function (Last Layer for regression)\n",
        "3. Sigmoid activation function\n",
        "4. Rectified Linear Units \n",
        "\n",
        "\n",
        "Refs\n",
        "----\n",
        "1. https://towardsdatascience.com/if-rectified-linear-units-are-linear-how-do-they-add-nonlinearity-40247d3e4792\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrHcBtZAZ20y"
      },
      "source": [
        "ReLU Activation : simple code \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GDM6Zz4altw",
        "outputId": "f39c801e-7386-40c0-cb1a-82178b390a0e"
      },
      "source": [
        "!pip install nnfs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nnfs\n",
            "  Downloading https://files.pythonhosted.org/packages/06/8c/3003a41d5229e65da792331b060dcad8100a0a5b9760f8c2074cde864148/nnfs-0.5.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nnfs) (1.19.5)\n",
            "Installing collected packages: nnfs\n",
            "Successfully installed nnfs-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqMQ5-2NMyGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d151818-4b86-4a6d-c26e-b0711134fe0e"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "inputs = [0, 2, -1, 3.3, -2.7, 1.1, 2.2, -100]\n",
        "output = np.maximum(0, inputs)\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.  2.  0.  3.3 0.  1.1 2.2 0. ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tk8KBVaaCyW"
      },
      "source": [
        "# Relu Activation Class \n",
        "class Activation_Relu:\n",
        "\n",
        "  #forward pass \n",
        "  def forward(self, inputs):\n",
        "    # calculate max of 0, input values\n",
        "    self.output = np.maximum(0, inputs)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d394Le7caPPW",
        "outputId": "7e8ea4e6-fbe5-4d89-a99c-adce87656ccd"
      },
      "source": [
        "#example \n",
        "import numpy as np \n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "#Dense Layer\n",
        "class Layer_Dense:\n",
        "\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    #initialize weight and biases\n",
        "    self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "    self.biases = np.zeros((1,n_neurons))\n",
        "\n",
        "  # forwards pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "# test class\n",
        "\n",
        "X,y = spiral_data(samples = 100, classes=3)\n",
        "\n",
        "#create the layer\n",
        "dense1 = Layer_Dense(2, 3)\n",
        "activation1 = Activation_Relu()\n",
        "\n",
        "#perform a forward pass\n",
        "dense1.forward(X)\n",
        "\n",
        "#perform activation of Relu\n",
        "activation1.forward(dense1.output)\n",
        "\n",
        "\n",
        "# see output\n",
        "print(activation1.output[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.        ]\n",
            " [0.         0.00011395 0.        ]\n",
            " [0.         0.00031729 0.        ]\n",
            " [0.         0.00052666 0.        ]\n",
            " [0.         0.00071401 0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btpa74zdasnS"
      },
      "source": [
        "We can see the values have been clipped to 0. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xFMcq_OcId2"
      },
      "source": [
        "### Softmax Activation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bPWQbQmaTg3",
        "outputId": "2ce77170-e208-4f67-c938-1ef00e70a5d8"
      },
      "source": [
        "layer_outputs = [4.8, 1.21, 2.385]\n",
        "\n",
        "# need to do e^x\n",
        "# e = 2.71828182846\n",
        "\n",
        "exp_values = np.exp(layer_outputs)\n",
        "print(exp_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[121.51041752   3.35348465  10.85906266]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgIvJ3nKcpp6"
      },
      "source": [
        "Full softmax "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XHV_VVmcmHN",
        "outputId": "c317597e-db2b-4726-9916-ae358e6a1087"
      },
      "source": [
        "layer_outputs = [4.8, 1.21, 2.385]\n",
        "\n",
        "# need to do e^x\n",
        "# e = 2.71828182846\n",
        "\n",
        "exp_values = np.exp(layer_outputs)\n",
        "print(exp_values)\n",
        "\n",
        "# now normalize them \n",
        "norm_values = exp_values / np.sum(exp_values)\n",
        "print(norm_values)\n",
        "\n",
        "print(\"sum of normalized values: \", np.sum(norm_values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[121.51041752   3.35348465  10.85906266]\n",
            "[0.89528266 0.02470831 0.08000903]\n",
            "sum of normalized values:  0.9999999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxpCWfxCdpmk"
      },
      "source": [
        "For batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgb8mqBxdlkg",
        "outputId": "06543410-60d0-4197-d825-8c35f39f3999"
      },
      "source": [
        "layer_outputs = np.array([[4.8, 1.21, 2.385],\n",
        "                          [8.9, -1.81, 0.2],\n",
        "                          [1.41, 1.051, 0.026]])\n",
        "\n",
        "print(\"sum without axis\", np.sum(layer_outputs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sum without axis 18.172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKk-RKUWee9p",
        "outputId": "2a2819f5-a8fd-4b65-e069-46627df7903c"
      },
      "source": [
        "print(\"sum with axis = 0 \", np.sum(layer_outputs, axis = 0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sum with axis = 0  [15.11   0.451  2.611]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF_6qDQ3ekrP",
        "outputId": "880ca3a1-5839-433a-d139-75445f678349"
      },
      "source": [
        "print(\"sum with axis = 1 \", np.sum(layer_outputs, axis = 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sum with axis = 1  [8.395 7.29  2.487]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "465dw3D4enpZ",
        "outputId": "304c5967-534a-45f4-9ec3-9788116623ff"
      },
      "source": [
        "# to simplify to single value per sample, use keep_dims\n",
        "print(\"sum with axis = 1 \", np.sum(layer_outputs, axis = 1, keepdims=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sum with axis = 1  [[8.395]\n",
            " [7.29 ]\n",
            " [2.487]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYpW-1vffGAC"
      },
      "source": [
        "\n",
        "\n",
        "Softmax Activation Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2mchQCQfCcQ"
      },
      "source": [
        "#Softmax Activation\n",
        "class Activation_Softmax:\n",
        "\n",
        "  # forward pass \n",
        "  def forward(self, inputs):\n",
        "\n",
        "    exp_values = np.exp(inputs - np.max(inputs, axis = 1, keepdims=True))\n",
        "\n",
        "    #normalize\n",
        "    probs = exp_values / np.sum(exp_values, axis = 1, keepdims=True)\n",
        "\n",
        "    self.output = probs\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QblO6R7EfjC_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aAE0BP-fxrP"
      },
      "source": [
        "Exponent\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4khkxb3Hfy44",
        "outputId": "2dbde7e9-057c-46de-db48-252f86df8467"
      },
      "source": [
        "np.exp(-100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.720075976020836e-44"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leILyMxqf0Lq",
        "outputId": "cfdc566f-425f-4e0e-b02b-8e17fefd1ad5"
      },
      "source": [
        "np.exp(-10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.5399929762484854e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzFmyWO9f1T1",
        "outputId": "14a98d10-daa3-46ed-cbc3-51e9fa0b53c1"
      },
      "source": [
        "np.exp(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ic3tchhf2Mc",
        "outputId": "50580099-14d7-42bd-f62a-911c730e9ece"
      },
      "source": [
        "np.exp(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22026.465794806718"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuWQqSmDf6Sh",
        "outputId": "57927eb2-76bb-48ad-a0d1-d2e273d854b9"
      },
      "source": [
        "np.exp(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.6881171418161356e+43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD9GrnCJf9np",
        "outputId": "98ef0188-e014-43e4-cf35-fba4511ef37e"
      },
      "source": [
        "np.exp(1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: overflow encountered in exp\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "inf"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hPSob2mf-l4",
        "outputId": "65afaede-773e-4915-ec14-80f714be2313"
      },
      "source": [
        "softmax = Activation_Softmax()\n",
        "\n",
        "input = [[1,2,3]]\n",
        "\n",
        "softmax.forward(input)\n",
        "print(softmax.output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.09003057 0.24472847 0.66524096]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veP3ehuhggKP",
        "outputId": "c73b67b5-6584-44e8-b75f-bf72ada139e7"
      },
      "source": [
        "input = [[-2,-1,0]]\n",
        "\n",
        "softmax.forward(input)\n",
        "print(softmax.output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.09003057 0.24472847 0.66524096]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygnayfuHgzKY"
      },
      "source": [
        "Final Code "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mn-Quxqgryh",
        "outputId": "7aac4615-f633-4525-91d1-ebfd704489cb"
      },
      "source": [
        "#example \n",
        "import numpy as np \n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "#Dense Layer\n",
        "class Layer_Dense:\n",
        "\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    #initialize weight and biases\n",
        "    self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "    self.biases = np.zeros((1,n_neurons))\n",
        "\n",
        "  # forwards pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "# test class\n",
        "\n",
        "X,y = spiral_data(samples = 100, classes=3)\n",
        "\n",
        "#create the layer\n",
        "dense1 = Layer_Dense(2, 3)\n",
        "activation1 = Activation_Relu()\n",
        "activation2 = Activation_Softmax()\n",
        "\n",
        "#perform a forward pass\n",
        "dense1.forward(X)\n",
        "\n",
        "#perform activation of Relu\n",
        "activation1.forward(dense1.output)\n",
        "\n",
        "#perform softmax\n",
        "activation2.forward(activation1.output)\n",
        "\n",
        "# see output\n",
        "print(activation2.output[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.33333334 0.33333334 0.33333334]\n",
            " [0.33332068 0.33335868 0.33332068]\n",
            " [0.3332981  0.33340386 0.3332981 ]\n",
            " [0.3332748  0.3334504  0.3332748 ]\n",
            " [0.33325398 0.33349204 0.33325398]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJoRO_LRiBk0"
      },
      "source": [
        "# assignment \n",
        "Think about how to model sine wave using neural networks?\n",
        "\n",
        "Can a neural network do this? We have not learned about training but think about the first steps. \n",
        "\n",
        "You need a dataset to train upon. How can you create that dataset?\n",
        "\n",
        "Try to create a sine wave dataset. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8ibRs5fytDO"
      },
      "source": [
        "Categorical Cross Entropy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_41MFWHqhGWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f1164f1-5398-41ce-efe3-1d1c66dd687e"
      },
      "source": [
        "import math\n",
        "output = [0.7, 0.1 , 0.2]\n",
        "\n",
        "target = [1, 0, 0 ]\n",
        "\n",
        "\n",
        "loss = -(math.log(output[0]) * target[0] + \n",
        "                 math.log(output[1]) * target[1]+\n",
        "                 math.log(output[2]) * target[2])\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.35667494393873245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eks2bKtdy9t2",
        "outputId": "1517063f-3974-4faf-9334-8ecd14a194c1"
      },
      "source": [
        "# our numpy solution \n",
        "import numpy as np \n",
        "np.sum(-1*np.log(np.asarray(output)) * np.asarray(target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35667494393873245"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WxtkqzOzPfg",
        "outputId": "42ee921d-f837-4c40-c9fc-a8f988f37ee6"
      },
      "source": [
        "print(math.log(1))\n",
        "print(math.log(0.95))\n",
        "print(math.log(0.9))\n",
        "print(math.log(0.8))\n",
        "print(math.log(0.2))\n",
        "print(math.log(0.1))\n",
        "print(math.log(0.05))\n",
        "print(math.log(0.01))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "-0.05129329438755058\n",
            "-0.10536051565782628\n",
            "-0.2231435513142097\n",
            "-1.6094379124341003\n",
            "-2.3025850929940455\n",
            "-2.995732273553991\n",
            "-4.605170185988091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez9A2iiq0Rc5"
      },
      "source": [
        "Calcualting loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VqGAkbyzfhn",
        "outputId": "34cadc1c-6c92-4c6a-92c8-df00fae1ccd8"
      },
      "source": [
        "softmax_outputs = np.array([[0.7, 0.1, 0.2],\n",
        "                   [0.1, 0.5, 0.4],\n",
        "                   [0.02, 0.9, 0.08]])\n",
        "\n",
        "class_targets = [0, 1, 1]\n",
        "\n",
        "#use numpy indexing to get the correct confidence scores \n",
        "print(softmax_outputs[range(len(softmax_outputs)), class_targets])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.7 0.5 0.9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ijj8XFQq03CA",
        "outputId": "8b7587ba-0e6d-404c-986b-e1957e6f0804"
      },
      "source": [
        "negLog = -np.log(softmax_outputs[range(len(softmax_outputs)), class_targets])\n",
        "\n",
        "avg_loss = np.mean(negLog)\n",
        "\n",
        "print(avg_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.38506088005216804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3shsHer21e5d"
      },
      "source": [
        "## One hot encoded values. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X85R8wQM1Zqf",
        "outputId": "170b2f83-951f-4c03-f491-033aa78c26ce"
      },
      "source": [
        "softmax_outputs = np.array([[0.7, 0.1, 0.2],\n",
        "                   [0.1, 0.5, 0.4],\n",
        "                   [0.02, 0.9, 0.08]])\n",
        "\n",
        "class_targets = np.array([[1, 0, 0],\n",
        "                          [0,1,0],\n",
        "                         [0,1,0]])\n",
        "\n",
        "print(np.sum(softmax_outputs * class_targets, axis = 1))\n",
        "negLog = -1 * np.log(np.sum(softmax_outputs * class_targets, axis = 1))\n",
        "avg_loss = np.mean(negLog)\n",
        "print(avg_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.7 0.5 0.9]\n",
            "0.38506088005216804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN-P7pwk4bP-"
      },
      "source": [
        "Problems with log "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1pS8Nqf37Pt",
        "outputId": "fd56f29c-6f7c-4413-a515-ce8e8f14f364"
      },
      "source": [
        "np.log(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-inf"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLJERz_B4dvH",
        "outputId": "33b8541f-1b0b-422e-dadf-ce06b1ee0514"
      },
      "source": [
        "-np.log(1.0000001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-9.999999505838704e-08"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efdQ4NEu4pBR"
      },
      "source": [
        "add a very small value to the actual values like 1e-7\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zYItRv54gEO"
      },
      "source": [
        "softmax_outputs = np.array([[0.7, 0.1, 0.2],\n",
        "                   [0.1, 0.5, 0.4],\n",
        "                   [0.02, 0.9, 0.08]])\n",
        "\n",
        "class_targets = np.array([[1, 0, 0],\n",
        "                          [1,0,0],\n",
        "                         [0,1,0]])\n",
        "\n",
        "actual_scores = np.sum(softmax_outputs * class_targets, axis = 1)\n",
        "\n",
        "actual_scores += 1e-7\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yVGvz2X48Kw",
        "outputId": "4f6fe102-6b6a-4c39-f309-53547789d97f"
      },
      "source": [
        "print(actual_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.7000001 0.5000001 0.9000001]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n9T9WUi4-Ww",
        "outputId": "1df98f6f-c040-4adf-9379-cd92fbe1df74"
      },
      "source": [
        "preds = np.array([0, 1, 0.5])\n",
        "preds += 1e-7\n",
        "\n",
        "preds = np.clip(preds, 1e-7, 1-1e-7)\n",
        "np.clip()\n",
        "print(preds)\n",
        "\n",
        "-np.log(preds)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.000000e-07 9.999999e-01 5.000001e-01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.61180957e+01, 1.00000005e-07, 6.93146981e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTnSPanL5zeN"
      },
      "source": [
        "Final Code "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWvL0gd75b8I"
      },
      "source": [
        "# Common loss class \n",
        "\n",
        "class Loss : \n",
        "\n",
        "  #calculates data and reg loss given model output and truth values \n",
        "  def calculate(self, output, y):\n",
        "\n",
        "    #calculate sample losses \n",
        "\n",
        "    sample_losses = self.forward(output, y )\n",
        "\n",
        "    #mean loss \n",
        "    data_loss = np.mean(sample_losses)\n",
        "\n",
        "    #return \n",
        "    return data_loss \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEAeMjaU6MCo"
      },
      "source": [
        "# Categorical Cross Entropy Loss \n",
        "\n",
        "class Loss_CategoricalCrossEntropy(Loss):\n",
        "\n",
        "  #forward pass \n",
        "  def forward(self, y_pred, y_true):\n",
        "\n",
        "    #number of samples in a batch \n",
        "    samples = len(y_pred)\n",
        "\n",
        "    #clip data to remove log 0 and negative loss \n",
        "    y_pred_clipped = np.clip(y_pred, 1e-7, 1-1e-7)\n",
        "\n",
        "    #probs for target values \n",
        "\n",
        "    #if categorical labels \n",
        "    if len(y_true.shape) == 1:\n",
        "      confidences = y_pred_clipped[range(samples), y_true]\n",
        "    \n",
        "    elif len(y_true.shape) == 2:\n",
        "      confidences = np.sum(y_pred_clipped * y_true, axis = 1)\n",
        "\n",
        "    #Losses\n",
        "    negLog = -np.log(confidences)\n",
        "\n",
        "    return negLog\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr2L3C1z6bHC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqzbqw6l6SQv",
        "outputId": "ac11ca76-9f56-45a9-f36b-6099ce8ec822"
      },
      "source": [
        "loss_fucntion = Loss_CategoricalCrossEntropy()\n",
        "loss = loss_fucntion.calculate(softmax_outputs, class_targets)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.38506088005216804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAVuiWKd7Tsk"
      },
      "source": [
        "Calculating Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM7ySp-57MYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58dd27a2-a1cc-4636-b2c2-c64bf5ad07b4"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "#probabilities of 3 samples \n",
        "softmax_outputs = np.array([[0.7, 0.2, 0.1],\n",
        "                            [0.5, 0.1, 0.4],\n",
        "                            [0.02, 0.9, 0.08]])\n",
        "\n",
        "#target \n",
        "class_targets = np.array([0, 1, 1])\n",
        "\n",
        "\n",
        "predictions = np.argmax(softmax_outputs, axis = 1)\n",
        "\n",
        "accuracy = np.mean(predictions == class_targets)\n",
        "\n",
        "print(accuracy)\n",
        "\n",
        "#"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FChidiTQFcK5"
      },
      "source": [
        "Back Propagation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7MBENBb_pEE",
        "outputId": "d7a1901b-c885-4b21-d666-9acb45f5d397"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "# Suppose gradient is coming from the end. \n",
        "dvalues = np.array([[1., 1., 1.],\n",
        "                    [2., 2., 2.],\n",
        "                    3., 3., 3.])\n",
        "\n",
        "\n",
        "# set of inputs \n",
        "inputs = np.array([[1, 2, 3, 2.5],\n",
        "                   [2., 5., -1,  2],\n",
        "                   [-1.5, 2.7, 3.3, -0.8]])\n",
        "\n",
        "#weights \n",
        "\n",
        "weights = np.array( [[ 0.2, 0.8, -0.5, 1],\n",
        "                     [0.5, -0.91, 0.26, -0.5],\n",
        "                     [-0.26, -0.27, 0.17, 0.87]]).T\n",
        "\n",
        "biases = np.array([[2, 3, 0.5]])\n",
        "\n",
        "#forward pass \n",
        "layer_outputs = np.dot(inputs, weights) + biases \n",
        "relu_outputs = np.maximum(0, layer_outputs)\n",
        "\n",
        "#backward pass \n",
        "#relu layer\n",
        "drelu = relu_outputs.copy()\n",
        "drelu[layer_outputs <= 0] = 0\n",
        "\n",
        "#dense layer\n",
        "dinputs = np.dot(drelu, weights.T)\n",
        "dweights = np.dot(inputs.T, drelu)\n",
        "dbiases = np.sum(drelu, axis = 0, keepdims = True)\n",
        "\n",
        "weights += -0.001 * dweights \n",
        "biases += -0.001 * dbiases \n",
        "\n",
        "print(weights)\n",
        "print(biases )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.179515   0.5003665 -0.262746 ]\n",
            " [ 0.742093  -0.9152577 -0.2758402]\n",
            " [-0.510153   0.2529017  0.1629592]\n",
            " [ 0.971328  -0.5021842  0.8636583]]\n",
            "[[1.98489  2.997739 0.497389]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFH0YjCMcArU"
      },
      "source": [
        "## Full NN code without Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39QnLCvUcLm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa3653f-9f5c-41d3-978f-c9242080a56a"
      },
      "source": [
        "!pip install nnfs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nnfs\n",
            "  Downloading https://files.pythonhosted.org/packages/06/8c/3003a41d5229e65da792331b060dcad8100a0a5b9760f8c2074cde864148/nnfs-0.5.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nnfs) (1.19.5)\n",
            "Installing collected packages: nnfs\n",
            "Successfully installed nnfs-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQgUKbExHAbD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7509ed1-274e-421e-fc1f-9bc3c9efcba0"
      },
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "\n",
        "# Dense layer\n",
        "class Layer_Dense:\n",
        "\n",
        "    # Layer initialization\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "        # Initialize weights and biases\n",
        "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "        self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Calculate output values from inputs, weights and biases\n",
        "        self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Gradients on parameters\n",
        "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
        "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
        "        # Gradient on values\n",
        "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
        "\n",
        "\n",
        "# ReLU activation\n",
        "class Activation_ReLU:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Calculate output values from inputs\n",
        "        self.output = np.maximum(0, inputs)\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Since we need to modify original variable,\n",
        "        # let's make a copy of values first\n",
        "        self.dinputs = dvalues.copy()\n",
        "\n",
        "        # Zero gradient where input values were negative\n",
        "        self.dinputs[self.inputs <= 0] = 0\n",
        "\n",
        "\n",
        "# Softmax activation\n",
        "class Activation_Softmax:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "\n",
        "        # Get unnormalized probabilities\n",
        "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
        "                                            keepdims=True))\n",
        "        # Normalize them for each sample\n",
        "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
        "                                            keepdims=True)\n",
        "\n",
        "        self.output = probabilities\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "\n",
        "        # Create uninitialized array\n",
        "        self.dinputs = np.empty_like(dvalues)\n",
        "\n",
        "        # Enumerate outputs and gradients\n",
        "        for index, (single_output, single_dvalues) in \\\n",
        "                enumerate(zip(self.output, dvalues)):\n",
        "            # Flatten output array\n",
        "            single_output = single_output.reshape(-1, 1)\n",
        "            # Calculate Jacobian matrix of the output\n",
        "            jacobian_matrix = np.diagflat(single_output) - \\\n",
        "                              np.dot(single_output, single_output.T)\n",
        "\n",
        "            # Calculate sample-wise gradient\n",
        "            # and add it to the array of sample gradients\n",
        "            self.dinputs[index] = np.dot(jacobian_matrix,\n",
        "                                         single_dvalues)\n",
        "\n",
        "\n",
        "# Common loss class\n",
        "class Loss:\n",
        "\n",
        "    # Calculates the data and regularization losses\n",
        "    # given model output and ground truth values\n",
        "    def calculate(self, output, y):\n",
        "\n",
        "        # Calculate sample losses\n",
        "        sample_losses = self.forward(output, y)\n",
        "\n",
        "        # Calculate mean loss\n",
        "        data_loss = np.mean(sample_losses)\n",
        "\n",
        "        # Return loss\n",
        "        return data_loss\n",
        "\n",
        "\n",
        "# Cross-entropy loss\n",
        "class Loss_CategoricalCrossentropy(Loss):\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, y_pred, y_true):\n",
        "\n",
        "        # Number of samples in a batch\n",
        "        samples = len(y_pred)\n",
        "\n",
        "        # Clip data to prevent division by 0\n",
        "        # Clip both sides to not drag mean towards any value\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        # Probabilities for target values -\n",
        "        # only if categorical labels\n",
        "        if len(y_true.shape) == 1:\n",
        "            correct_confidences = y_pred_clipped[\n",
        "                range(samples),\n",
        "                y_true\n",
        "            ]\n",
        "\n",
        "\n",
        "        # Mask values - only for one-hot encoded labels\n",
        "        elif len(y_true.shape) == 2:\n",
        "            correct_confidences = np.sum(\n",
        "                y_pred_clipped * y_true,\n",
        "                axis=1\n",
        "            )\n",
        "\n",
        "        # Losses\n",
        "        negative_log_likelihoods = -np.log(correct_confidences)\n",
        "        return negative_log_likelihoods\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "        # Number of labels in every sample\n",
        "        # We'll use the first sample to count them\n",
        "        labels = len(dvalues[0])\n",
        "\n",
        "        # If labels are sparse, turn them into one-hot vector\n",
        "        if len(y_true.shape) == 1:\n",
        "            y_true = np.eye(labels)[y_true]\n",
        "\n",
        "        # Calculate gradient\n",
        "        self.dinputs = -y_true / dvalues\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "\n",
        "# Softmax classifier - combined Softmax activation\n",
        "# and cross-entropy loss for faster backward step\n",
        "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
        "\n",
        "    # Creates activation and loss function objects\n",
        "    def __init__(self):\n",
        "        self.activation = Activation_Softmax()\n",
        "        self.loss = Loss_CategoricalCrossentropy()\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs, y_true):\n",
        "        # Output layer's activation function\n",
        "        self.activation.forward(inputs)\n",
        "        # Set the output\n",
        "        self.output = self.activation.output\n",
        "        # Calculate and return loss value\n",
        "        return self.loss.calculate(self.output, y_true)\n",
        "\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "\n",
        "        # If labels are one-hot encoded,\n",
        "        # turn them into discrete values\n",
        "        if len(y_true.shape) == 2:\n",
        "            y_true = np.argmax(y_true, axis=1)\n",
        "\n",
        "        # Copy so we can safely modify\n",
        "        self.dinputs = dvalues.copy()\n",
        "        # Calculate gradient\n",
        "        self.dinputs[range(samples), y_true] -= 1\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "\n",
        "# Create dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n",
        "\n",
        "# Create Dense layer with 2 input features and 3 output values\n",
        "dense1 = Layer_Dense(2, 3)\n",
        "\n",
        "# Create ReLU activation (to be used with Dense layer):\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "# Create second Dense layer with 3 input features (as we take output\n",
        "# of previous layer here) and 3 output values (output values)\n",
        "dense2 = Layer_Dense(3, 3)\n",
        "\n",
        "# Create Softmax classifier's combined loss and activation\n",
        "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
        "\n",
        "# Perform a forward pass of our training data through this layer\n",
        "dense1.forward(X)\n",
        "\n",
        "# Perform a forward pass through activation function\n",
        "# takes the output of first dense layer here\n",
        "activation1.forward(dense1.output)\n",
        "\n",
        "# Perform a forward pass through second Dense layer\n",
        "# takes outputs of activation function of first layer as inputs\n",
        "dense2.forward(activation1.output)\n",
        "\n",
        "# Perform a forward pass through the activation/loss function\n",
        "# takes the output of second dense layer here and returns loss\n",
        "loss = loss_activation.forward(dense2.output, y)\n",
        "# Let's see output of the first few samples:\n",
        "print(loss_activation.output[:5])\n",
        "\n",
        "# Print loss value\n",
        "print('loss:', loss)\n",
        "\n",
        "# Calculate accuracy from output of activation2 and targets\n",
        "# calculate values along first axis\n",
        "predictions = np.argmax(loss_activation.output, axis=1)\n",
        "if len(y.shape) == 2:\n",
        "    y = np.argmax(y, axis=1)\n",
        "accuracy = np.mean(predictions==y)\n",
        "\n",
        "# Print accuracy\n",
        "print('acc:', accuracy)\n",
        "\n",
        "# Backward pass\n",
        "loss_activation.backward(loss_activation.output, y)\n",
        "dense2.backward(loss_activation.dinputs)\n",
        "activation1.backward(dense2.dinputs)\n",
        "dense1.backward(activation1.dinputs)\n",
        "\n",
        "# Print gradients\n",
        "print(dense1.dweights)\n",
        "print(dense1.dbiases)\n",
        "print(dense2.dweights)\n",
        "print(dense2.dbiases)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.33333334 0.33333334 0.33333334]\n",
            " [0.3333332  0.3333332  0.33333364]\n",
            " [0.3333329  0.33333293 0.3333342 ]\n",
            " [0.3333326  0.33333263 0.33333477]\n",
            " [0.33333233 0.3333324  0.33333528]]\n",
            "loss: 1.0986104\n",
            "acc: 0.34\n",
            "[[ 1.5766357e-04  7.8368583e-05  4.7324400e-05]\n",
            " [ 1.8161038e-04  1.1045573e-05 -3.3096312e-05]]\n",
            "[[-3.60553473e-04  9.66117223e-05 -1.03671395e-04]]\n",
            "[[ 5.44109462e-05  1.07411419e-04 -1.61822361e-04]\n",
            " [-4.07913431e-05 -7.16780924e-05  1.12469446e-04]\n",
            " [-5.30112993e-05  8.58172934e-05 -3.28059905e-05]]\n",
            "[[-1.0729185e-05 -9.4610732e-06  2.0027859e-05]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oQgRSO0Gf5F"
      },
      "source": [
        "## Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPDdjKMA_cib"
      },
      "source": [
        "!pip install nnfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OERkShhI_o8p"
      },
      "source": [
        "class Optimizer_SGD:\n",
        "\n",
        "  def __init__(self, learning_rate = 1.0):\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "  def update_params(self, layer):\n",
        "    layer.weights += -self.learning_rate * layer.dweights\n",
        "    layer.biases += -self.learning_rate * layer.dbiases\n",
        "    "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY_yXGMc_XfW",
        "outputId": "2499c84f-ebd9-4269-ae11-33ed33ef5fe4"
      },
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "\n",
        "# Create dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n",
        "\n",
        "# Create Dense layer with 2 input features and 3 output values\n",
        "dense1 = Layer_Dense(2, 64)\n",
        "\n",
        "# Create ReLU activation (to be used with Dense layer):\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "# Create second Dense layer with 3 input features (as we take output\n",
        "# of previous layer here) and 3 output values (output values)\n",
        "dense2 = Layer_Dense(64, 3)\n",
        "\n",
        "# Create Softmax classifier's combined loss and activation\n",
        "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
        "\n",
        "optimizer = Optimizer_SGD()\n",
        "\n",
        "#train in loop \n",
        "losses = []\n",
        "for epoch in range(10001):\n",
        "\n",
        "  #forward passes \n",
        "  dense1.forward(X)\n",
        "  activation1.forward(dense1.output)\n",
        "  dense2.forward(activation1.output)\n",
        "  loss = loss_activation.forward(dense2.output, y)\n",
        "  losses.append(loss)\n",
        "  # calcualte accuracy \n",
        "  predictions = np.argmax(loss_activation.output, axis = 1)\n",
        "  if len(y.shape) == 2:\n",
        "    y = np.argmax(y, axis = 1)\n",
        "  \n",
        "  accuracy = np.mean(predictions == y)\n",
        "\n",
        "  if not epoch % 100:\n",
        "    print(f'epoch: {epoch}, acc: {accuracy}, loss:{loss}' )\n",
        "\n",
        "  # backward pass \n",
        "  loss_activation.backward(loss_activation.output, y)\n",
        "  dense2.backward(loss_activation.dinputs)\n",
        "  activation1.backward(dense2.dinputs)\n",
        "  dense1.backward(activation1.dinputs)\n",
        "\n",
        "  #update params \n",
        "  optimizer.update_params(dense1)\n",
        "  optimizer.update_params(dense2)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, acc: 0.36, loss:1.098594307899475\n",
            "epoch: 100, acc: 0.4, loss:1.0869206190109253\n",
            "epoch: 200, acc: 0.4166666666666667, loss:1.0773380994796753\n",
            "epoch: 300, acc: 0.42, loss:1.0760209560394287\n",
            "epoch: 400, acc: 0.4, loss:1.074236273765564\n",
            "epoch: 500, acc: 0.4, loss:1.0713080167770386\n",
            "epoch: 600, acc: 0.4166666666666667, loss:1.0673632621765137\n",
            "epoch: 700, acc: 0.43666666666666665, loss:1.0623551607131958\n",
            "epoch: 800, acc: 0.43, loss:1.0550928115844727\n",
            "epoch: 900, acc: 0.39, loss:1.0638744831085205\n",
            "epoch: 1000, acc: 0.4, loss:1.0622682571411133\n",
            "epoch: 1100, acc: 0.44333333333333336, loss:1.061262607574463\n",
            "epoch: 1200, acc: 0.4033333333333333, loss:1.0605604648590088\n",
            "epoch: 1300, acc: 0.38666666666666666, loss:1.0517452955245972\n",
            "epoch: 1400, acc: 0.38666666666666666, loss:1.105523943901062\n",
            "epoch: 1500, acc: 0.43, loss:1.0429925918579102\n",
            "epoch: 1600, acc: 0.41, loss:1.0630847215652466\n",
            "epoch: 1700, acc: 0.39666666666666667, loss:1.0433818101882935\n",
            "epoch: 1800, acc: 0.45, loss:1.0381176471710205\n",
            "epoch: 1900, acc: 0.48333333333333334, loss:1.0248881578445435\n",
            "epoch: 2000, acc: 0.4033333333333333, loss:1.0371609926223755\n",
            "epoch: 2100, acc: 0.45666666666666667, loss:1.0216883420944214\n",
            "epoch: 2200, acc: 0.49333333333333335, loss:1.0195891857147217\n",
            "epoch: 2300, acc: 0.44333333333333336, loss:1.0016921758651733\n",
            "epoch: 2400, acc: 0.48, loss:0.9941015839576721\n",
            "epoch: 2500, acc: 0.49, loss:1.008725643157959\n",
            "epoch: 2600, acc: 0.48, loss:0.9909303784370422\n",
            "epoch: 2700, acc: 0.54, loss:0.9724604487419128\n",
            "epoch: 2800, acc: 0.47333333333333333, loss:0.9976078271865845\n",
            "epoch: 2900, acc: 0.5266666666666666, loss:0.963260293006897\n",
            "epoch: 3000, acc: 0.5433333333333333, loss:0.9854065179824829\n",
            "epoch: 3100, acc: 0.5233333333333333, loss:0.9876247048377991\n",
            "epoch: 3200, acc: 0.4866666666666667, loss:0.9763368964195251\n",
            "epoch: 3300, acc: 0.49333333333333335, loss:0.9725401997566223\n",
            "epoch: 3400, acc: 0.4766666666666667, loss:0.9842291474342346\n",
            "epoch: 3500, acc: 0.52, loss:0.992677628993988\n",
            "epoch: 3600, acc: 0.5366666666666666, loss:0.9652496576309204\n",
            "epoch: 3700, acc: 0.55, loss:0.9966951608657837\n",
            "epoch: 3800, acc: 0.48333333333333334, loss:0.9633467793464661\n",
            "epoch: 3900, acc: 0.49333333333333335, loss:0.9697713255882263\n",
            "epoch: 4000, acc: 0.52, loss:0.9706616401672363\n",
            "epoch: 4100, acc: 0.54, loss:0.989279568195343\n",
            "epoch: 4200, acc: 0.5466666666666666, loss:0.9564687013626099\n",
            "epoch: 4300, acc: 0.5733333333333334, loss:0.9951723217964172\n",
            "epoch: 4400, acc: 0.48333333333333334, loss:0.9586665034294128\n",
            "epoch: 4500, acc: 0.49333333333333335, loss:0.9687966704368591\n",
            "epoch: 4600, acc: 0.52, loss:0.9737345576286316\n",
            "epoch: 4700, acc: 0.5433333333333333, loss:0.9868637323379517\n",
            "epoch: 4800, acc: 0.5466666666666666, loss:0.9624319672584534\n",
            "epoch: 4900, acc: 0.5533333333333333, loss:1.0066593885421753\n",
            "epoch: 5000, acc: 0.51, loss:0.9731101393699646\n",
            "epoch: 5100, acc: 0.53, loss:0.9664764404296875\n",
            "epoch: 5200, acc: 0.5466666666666666, loss:0.9857028126716614\n",
            "epoch: 5300, acc: 0.55, loss:0.9605168700218201\n",
            "epoch: 5400, acc: 0.5566666666666666, loss:1.0007402896881104\n",
            "epoch: 5500, acc: 0.52, loss:0.9658766388893127\n",
            "epoch: 5600, acc: 0.5133333333333333, loss:0.9555531740188599\n",
            "epoch: 5700, acc: 0.57, loss:0.9754876494407654\n",
            "epoch: 5800, acc: 0.5533333333333333, loss:0.9360553026199341\n",
            "epoch: 5900, acc: 0.5766666666666667, loss:0.971545398235321\n",
            "epoch: 6000, acc: 0.49, loss:0.9397631883621216\n",
            "epoch: 6100, acc: 0.5566666666666666, loss:0.9508057832717896\n",
            "epoch: 6200, acc: 0.5333333333333333, loss:0.9367452263832092\n",
            "epoch: 6300, acc: 0.59, loss:0.9558148384094238\n",
            "epoch: 6400, acc: 0.5633333333333334, loss:0.928519606590271\n",
            "epoch: 6500, acc: 0.5933333333333334, loss:0.9553053975105286\n",
            "epoch: 6600, acc: 0.5233333333333333, loss:0.9191462993621826\n",
            "epoch: 6700, acc: 0.5666666666666667, loss:0.928459882736206\n",
            "epoch: 6800, acc: 0.56, loss:0.8899131417274475\n",
            "epoch: 6900, acc: 0.5866666666666667, loss:0.8712476491928101\n",
            "epoch: 7000, acc: 0.5933333333333334, loss:0.9049868583679199\n",
            "epoch: 7100, acc: 0.6233333333333333, loss:0.859682023525238\n",
            "epoch: 7200, acc: 0.5833333333333334, loss:0.867811918258667\n",
            "epoch: 7300, acc: 0.6, loss:0.8740476369857788\n",
            "epoch: 7400, acc: 0.5966666666666667, loss:0.8488327860832214\n",
            "epoch: 7500, acc: 0.6066666666666667, loss:0.91400146484375\n",
            "epoch: 7600, acc: 0.6566666666666666, loss:0.8581396341323853\n",
            "epoch: 7700, acc: 0.62, loss:0.8528146743774414\n",
            "epoch: 7800, acc: 0.63, loss:0.8621673583984375\n",
            "epoch: 7900, acc: 0.58, loss:0.8781864643096924\n",
            "epoch: 8000, acc: 0.6166666666666667, loss:0.8736241459846497\n",
            "epoch: 8100, acc: 0.5966666666666667, loss:0.8394070267677307\n",
            "epoch: 8200, acc: 0.5933333333333334, loss:0.8517529964447021\n",
            "epoch: 8300, acc: 0.58, loss:0.9232891798019409\n",
            "epoch: 8400, acc: 0.6466666666666666, loss:0.8787612915039062\n",
            "epoch: 8500, acc: 0.63, loss:0.8380792140960693\n",
            "epoch: 8600, acc: 0.63, loss:0.8532760739326477\n",
            "epoch: 8700, acc: 0.6266666666666667, loss:0.8633965253829956\n",
            "epoch: 8800, acc: 0.6, loss:0.8790981769561768\n",
            "epoch: 8900, acc: 0.5966666666666667, loss:0.8709477782249451\n",
            "epoch: 9000, acc: 0.57, loss:0.8717381954193115\n",
            "epoch: 9100, acc: 0.63, loss:0.8798957467079163\n",
            "epoch: 9200, acc: 0.6266666666666667, loss:0.8619816303253174\n",
            "epoch: 9300, acc: 0.6133333333333333, loss:0.8477188348770142\n",
            "epoch: 9400, acc: 0.5966666666666667, loss:0.8380523920059204\n",
            "epoch: 9500, acc: 0.6066666666666667, loss:0.8435631394386292\n",
            "epoch: 9600, acc: 0.6066666666666667, loss:0.8644261956214905\n",
            "epoch: 9700, acc: 0.6066666666666667, loss:0.8806635737419128\n",
            "epoch: 9800, acc: 0.6, loss:0.9264081716537476\n",
            "epoch: 9900, acc: 0.61, loss:0.9145286083221436\n",
            "epoch: 10000, acc: 0.6466666666666666, loss:0.8737250566482544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "Xvgha_rMBr-y",
        "outputId": "97d7c736-9070-46e8-983a-d31109047ca4"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline \n",
        "\n",
        "plt.plot(range(len(losses)), losses)\n",
        "plt.title('Loss vs steps')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUW8MMB5CHDf"
      },
      "source": [
        "Low learning rate \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1KSlZfJxCGoW",
        "outputId": "7f83173e-152b-422c-c72d-344ea440539e"
      },
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "\n",
        "# Create dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n",
        "\n",
        "# Create Dense layer with 2 input features and 3 output values\n",
        "dense1 = Layer_Dense(2, 64)\n",
        "\n",
        "# Create ReLU activation (to be used with Dense layer):\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "# Create second Dense layer with 3 input features (as we take output\n",
        "# of previous layer here) and 3 output values (output values)\n",
        "dense2 = Layer_Dense(64, 3)\n",
        "\n",
        "# Create Softmax classifier's combined loss and activation\n",
        "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
        "\n",
        "optimizer = Optimizer_SGD(0.001)\n",
        "\n",
        "#train in loop \n",
        "losses = []\n",
        "for epoch in range(10001):\n",
        "\n",
        "  #forward passes \n",
        "  dense1.forward(X)\n",
        "  activation1.forward(dense1.output)\n",
        "  dense2.forward(activation1.output)\n",
        "  loss = loss_activation.forward(dense2.output, y)\n",
        "  losses.append(loss)\n",
        "  # calcualte accuracy \n",
        "  predictions = np.argmax(loss_activation.output, axis = 1)\n",
        "  if len(y.shape) == 2:\n",
        "    y = np.argmax(y, axis = 1)\n",
        "  \n",
        "  accuracy = np.mean(predictions == y)\n",
        "\n",
        "  if not epoch % 100:\n",
        "    print(f'epoch: {epoch}, acc: {accuracy}, loss:{loss}' )\n",
        "\n",
        "  # backward pass \n",
        "  loss_activation.backward(loss_activation.output, y)\n",
        "  dense2.backward(loss_activation.dinputs)\n",
        "  activation1.backward(dense2.dinputs)\n",
        "  dense1.backward(activation1.dinputs)\n",
        "\n",
        "  #update params \n",
        "  optimizer.update_params(dense1)\n",
        "  optimizer.update_params(dense2)\n",
        "\n",
        "plt.plot(range(len(losses)), losses)\n",
        "plt.title('Loss vs steps')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, acc: 0.36, loss:1.098594307899475\n",
            "epoch: 100, acc: 0.36, loss:1.0985922813415527\n",
            "epoch: 200, acc: 0.36666666666666664, loss:1.0985902547836304\n",
            "epoch: 300, acc: 0.37, loss:1.0985881090164185\n",
            "epoch: 400, acc: 0.4, loss:1.098586082458496\n",
            "epoch: 500, acc: 0.4066666666666667, loss:1.0985839366912842\n",
            "epoch: 600, acc: 0.4033333333333333, loss:1.0985819101333618\n",
            "epoch: 700, acc: 0.4033333333333333, loss:1.0985798835754395\n",
            "epoch: 800, acc: 0.39666666666666667, loss:1.0985779762268066\n",
            "epoch: 900, acc: 0.4033333333333333, loss:1.0985760688781738\n",
            "epoch: 1000, acc: 0.4066666666666667, loss:1.0985740423202515\n",
            "epoch: 1100, acc: 0.4033333333333333, loss:1.0985721349716187\n",
            "epoch: 1200, acc: 0.4066666666666667, loss:1.0985701084136963\n",
            "epoch: 1300, acc: 0.4033333333333333, loss:1.098568320274353\n",
            "epoch: 1400, acc: 0.39666666666666667, loss:1.0985665321350098\n",
            "epoch: 1500, acc: 0.3933333333333333, loss:1.0985647439956665\n",
            "epoch: 1600, acc: 0.39, loss:1.0985629558563232\n",
            "epoch: 1700, acc: 0.39, loss:1.0985610485076904\n",
            "epoch: 1800, acc: 0.38666666666666666, loss:1.0985593795776367\n",
            "epoch: 1900, acc: 0.38666666666666666, loss:1.0985575914382935\n",
            "epoch: 2000, acc: 0.39, loss:1.0985559225082397\n",
            "epoch: 2100, acc: 0.38666666666666666, loss:1.098554253578186\n",
            "epoch: 2200, acc: 0.39, loss:1.0985527038574219\n",
            "epoch: 2300, acc: 0.39, loss:1.0985511541366577\n",
            "epoch: 2400, acc: 0.39, loss:1.098549485206604\n",
            "epoch: 2500, acc: 0.3933333333333333, loss:1.0985479354858398\n",
            "epoch: 2600, acc: 0.3933333333333333, loss:1.0985465049743652\n",
            "epoch: 2700, acc: 0.39666666666666667, loss:1.098544955253601\n",
            "epoch: 2800, acc: 0.4, loss:1.0985435247421265\n",
            "epoch: 2900, acc: 0.4, loss:1.0985420942306519\n",
            "epoch: 3000, acc: 0.4, loss:1.0985406637191772\n",
            "epoch: 3100, acc: 0.4, loss:1.0985392332077026\n",
            "epoch: 3200, acc: 0.4033333333333333, loss:1.098537802696228\n",
            "epoch: 3300, acc: 0.4, loss:1.098536491394043\n",
            "epoch: 3400, acc: 0.4033333333333333, loss:1.0985350608825684\n",
            "epoch: 3500, acc: 0.4066666666666667, loss:1.0985337495803833\n",
            "epoch: 3600, acc: 0.41, loss:1.0985324382781982\n",
            "epoch: 3700, acc: 0.41333333333333333, loss:1.0985311269760132\n",
            "epoch: 3800, acc: 0.41333333333333333, loss:1.0985296964645386\n",
            "epoch: 3900, acc: 0.41333333333333333, loss:1.0985283851623535\n",
            "epoch: 4000, acc: 0.4166666666666667, loss:1.0985270738601685\n",
            "epoch: 4100, acc: 0.4166666666666667, loss:1.0985256433486938\n",
            "epoch: 4200, acc: 0.4166666666666667, loss:1.0985243320465088\n",
            "epoch: 4300, acc: 0.4166666666666667, loss:1.0985230207443237\n",
            "epoch: 4400, acc: 0.4166666666666667, loss:1.0985217094421387\n",
            "epoch: 4500, acc: 0.4166666666666667, loss:1.0985205173492432\n",
            "epoch: 4600, acc: 0.4166666666666667, loss:1.0985193252563477\n",
            "epoch: 4700, acc: 0.4166666666666667, loss:1.0985180139541626\n",
            "epoch: 4800, acc: 0.4166666666666667, loss:1.0985167026519775\n",
            "epoch: 4900, acc: 0.4166666666666667, loss:1.0985153913497925\n",
            "epoch: 5000, acc: 0.4166666666666667, loss:1.098514199256897\n",
            "epoch: 5100, acc: 0.4166666666666667, loss:1.0985130071640015\n",
            "epoch: 5200, acc: 0.4166666666666667, loss:1.098511815071106\n",
            "epoch: 5300, acc: 0.4166666666666667, loss:1.0985103845596313\n",
            "epoch: 5400, acc: 0.4166666666666667, loss:1.0985091924667358\n",
            "epoch: 5500, acc: 0.4166666666666667, loss:1.0985080003738403\n",
            "epoch: 5600, acc: 0.41333333333333333, loss:1.0985068082809448\n",
            "epoch: 5700, acc: 0.41333333333333333, loss:1.0985054969787598\n",
            "epoch: 5800, acc: 0.41333333333333333, loss:1.0985041856765747\n",
            "epoch: 5900, acc: 0.41333333333333333, loss:1.0985028743743896\n",
            "epoch: 6000, acc: 0.41, loss:1.0985018014907837\n",
            "epoch: 6100, acc: 0.41, loss:1.0985004901885986\n",
            "epoch: 6200, acc: 0.4066666666666667, loss:1.0984992980957031\n",
            "epoch: 6300, acc: 0.4066666666666667, loss:1.0984981060028076\n",
            "epoch: 6400, acc: 0.4066666666666667, loss:1.098496675491333\n",
            "epoch: 6500, acc: 0.41, loss:1.0984957218170166\n",
            "epoch: 6600, acc: 0.41, loss:1.0984944105148315\n",
            "epoch: 6700, acc: 0.41, loss:1.0984930992126465\n",
            "epoch: 6800, acc: 0.41, loss:1.098491907119751\n",
            "epoch: 6900, acc: 0.41, loss:1.098490595817566\n",
            "epoch: 7000, acc: 0.41, loss:1.0984896421432495\n",
            "epoch: 7100, acc: 0.41, loss:1.098488211631775\n",
            "epoch: 7200, acc: 0.41333333333333333, loss:1.0984869003295898\n",
            "epoch: 7300, acc: 0.41, loss:1.0984857082366943\n",
            "epoch: 7400, acc: 0.41, loss:1.0984845161437988\n",
            "epoch: 7500, acc: 0.41, loss:1.0984833240509033\n",
            "epoch: 7600, acc: 0.41, loss:1.0984820127487183\n",
            "epoch: 7700, acc: 0.41, loss:1.0984808206558228\n",
            "epoch: 7800, acc: 0.41, loss:1.0984796285629272\n",
            "epoch: 7900, acc: 0.41, loss:1.0984784364700317\n",
            "epoch: 8000, acc: 0.41, loss:1.0984771251678467\n",
            "epoch: 8100, acc: 0.41, loss:1.0984759330749512\n",
            "epoch: 8200, acc: 0.41, loss:1.0984746217727661\n",
            "epoch: 8300, acc: 0.41333333333333333, loss:1.0984734296798706\n",
            "epoch: 8400, acc: 0.41333333333333333, loss:1.0984721183776855\n",
            "epoch: 8500, acc: 0.41333333333333333, loss:1.09847092628479\n",
            "epoch: 8600, acc: 0.41333333333333333, loss:1.098469614982605\n",
            "epoch: 8700, acc: 0.41333333333333333, loss:1.0984684228897095\n",
            "epoch: 8800, acc: 0.41333333333333333, loss:1.098467230796814\n",
            "epoch: 8900, acc: 0.41333333333333333, loss:1.0984660387039185\n",
            "epoch: 9000, acc: 0.41333333333333333, loss:1.0984646081924438\n",
            "epoch: 9100, acc: 0.4166666666666667, loss:1.0984632968902588\n",
            "epoch: 9200, acc: 0.42, loss:1.0984621047973633\n",
            "epoch: 9300, acc: 0.42, loss:1.0984609127044678\n",
            "epoch: 9400, acc: 0.42, loss:1.0984594821929932\n",
            "epoch: 9500, acc: 0.42, loss:1.0984582901000977\n",
            "epoch: 9600, acc: 0.42, loss:1.0984569787979126\n",
            "epoch: 9700, acc: 0.42, loss:1.098455548286438\n",
            "epoch: 9800, acc: 0.42, loss:1.098454236984253\n",
            "epoch: 9900, acc: 0.42, loss:1.0984528064727783\n",
            "epoch: 10000, acc: 0.42333333333333334, loss:1.0984514951705933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "93K8PgMVDEN0",
        "outputId": "6330d76b-00d1-4b5d-d2cd-d879ad55c3fe"
      },
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "\n",
        "# Create dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n",
        "\n",
        "# Create Dense layer with 2 input features and 3 output values\n",
        "dense1 = Layer_Dense(2, 64)\n",
        "\n",
        "# Create ReLU activation (to be used with Dense layer):\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "# Create second Dense layer with 3 input features (as we take output\n",
        "# of previous layer here) and 3 output values (output values)\n",
        "dense2 = Layer_Dense(64, 3)\n",
        "\n",
        "# Create Softmax classifier's combined loss and activation\n",
        "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
        "\n",
        "optimizer = Optimizer_SGD(0.85)\n",
        "\n",
        "#train in loop \n",
        "losses = []\n",
        "for epoch in range(10001):\n",
        "\n",
        "  #forward passes \n",
        "  dense1.forward(X)\n",
        "  activation1.forward(dense1.output)\n",
        "  dense2.forward(activation1.output)\n",
        "  loss = loss_activation.forward(dense2.output, y)\n",
        "  losses.append(loss)\n",
        "  # calcualte accuracy \n",
        "  predictions = np.argmax(loss_activation.output, axis = 1)\n",
        "  if len(y.shape) == 2:\n",
        "    y = np.argmax(y, axis = 1)\n",
        "  \n",
        "  accuracy = np.mean(predictions == y)\n",
        "\n",
        "  if not epoch % 100:\n",
        "    print(f'epoch: {epoch}, acc: {accuracy}, loss:{loss}' )\n",
        "\n",
        "  # backward pass \n",
        "  loss_activation.backward(loss_activation.output, y)\n",
        "  dense2.backward(loss_activation.dinputs)\n",
        "  activation1.backward(dense2.dinputs)\n",
        "  dense1.backward(activation1.dinputs)\n",
        "\n",
        "  #update params \n",
        "  optimizer.update_params(dense1)\n",
        "  optimizer.update_params(dense2)\n",
        "\n",
        "plt.plot(range(len(losses)), losses)\n",
        "plt.title('Loss vs steps')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, acc: 0.36, loss:1.098594307899475\n",
            "epoch: 100, acc: 0.4033333333333333, loss:1.09110426902771\n",
            "epoch: 200, acc: 0.41, loss:1.0781528949737549\n",
            "epoch: 300, acc: 0.42333333333333334, loss:1.0765252113342285\n",
            "epoch: 400, acc: 0.41333333333333333, loss:1.0754460096359253\n",
            "epoch: 500, acc: 0.4, loss:1.0735853910446167\n",
            "epoch: 600, acc: 0.4033333333333333, loss:1.0708863735198975\n",
            "epoch: 700, acc: 0.4166666666666667, loss:1.0674803256988525\n",
            "epoch: 800, acc: 0.43333333333333335, loss:1.0634346008300781\n",
            "epoch: 900, acc: 0.44666666666666666, loss:1.0567983388900757\n",
            "epoch: 1000, acc: 0.4533333333333333, loss:1.0497252941131592\n",
            "epoch: 1100, acc: 0.42, loss:1.0586049556732178\n",
            "epoch: 1200, acc: 0.4, loss:1.0575016736984253\n",
            "epoch: 1300, acc: 0.39666666666666667, loss:1.0537679195404053\n",
            "epoch: 1400, acc: 0.39666666666666667, loss:1.0539730787277222\n",
            "epoch: 1500, acc: 0.43666666666666665, loss:1.065623164176941\n",
            "epoch: 1600, acc: 0.45, loss:1.0771702527999878\n",
            "epoch: 1700, acc: 0.4, loss:1.04583740234375\n",
            "epoch: 1800, acc: 0.42333333333333334, loss:1.0394339561462402\n",
            "epoch: 1900, acc: 0.4066666666666667, loss:1.067804217338562\n",
            "epoch: 2000, acc: 0.4066666666666667, loss:1.037172794342041\n",
            "epoch: 2100, acc: 0.44, loss:1.027287244796753\n",
            "epoch: 2200, acc: 0.45666666666666667, loss:1.038488507270813\n",
            "epoch: 2300, acc: 0.44666666666666666, loss:1.0423778295516968\n",
            "epoch: 2400, acc: 0.5366666666666666, loss:0.986311137676239\n",
            "epoch: 2500, acc: 0.4266666666666667, loss:1.0092506408691406\n",
            "epoch: 2600, acc: 0.4866666666666667, loss:1.0293062925338745\n",
            "epoch: 2700, acc: 0.53, loss:0.9862475395202637\n",
            "epoch: 2800, acc: 0.5166666666666667, loss:0.9918524026870728\n",
            "epoch: 2900, acc: 0.51, loss:0.9729094505310059\n",
            "epoch: 3000, acc: 0.51, loss:1.001628041267395\n",
            "epoch: 3100, acc: 0.5266666666666666, loss:1.0008291006088257\n",
            "epoch: 3200, acc: 0.4866666666666667, loss:0.9676011204719543\n",
            "epoch: 3300, acc: 0.47333333333333333, loss:0.9715688228607178\n",
            "epoch: 3400, acc: 0.52, loss:0.9716684222221375\n",
            "epoch: 3500, acc: 0.5233333333333333, loss:0.9593930840492249\n",
            "epoch: 3600, acc: 0.49333333333333335, loss:0.9660150408744812\n",
            "epoch: 3700, acc: 0.48333333333333334, loss:0.9624878764152527\n",
            "epoch: 3800, acc: 0.52, loss:0.9563201665878296\n",
            "epoch: 3900, acc: 0.5333333333333333, loss:0.9560033082962036\n",
            "epoch: 4000, acc: 0.54, loss:0.9641157984733582\n",
            "epoch: 4100, acc: 0.5033333333333333, loss:0.958552360534668\n",
            "epoch: 4200, acc: 0.5033333333333333, loss:0.9458459615707397\n",
            "epoch: 4300, acc: 0.5533333333333333, loss:0.9592179656028748\n",
            "epoch: 4400, acc: 0.55, loss:0.964046835899353\n",
            "epoch: 4500, acc: 0.51, loss:0.9617825150489807\n",
            "epoch: 4600, acc: 0.5066666666666667, loss:0.9450520873069763\n",
            "epoch: 4700, acc: 0.5566666666666666, loss:0.9568802714347839\n",
            "epoch: 4800, acc: 0.53, loss:0.9601391553878784\n",
            "epoch: 4900, acc: 0.49666666666666665, loss:0.9631547331809998\n",
            "epoch: 5000, acc: 0.5666666666666667, loss:0.9608914256095886\n",
            "epoch: 5100, acc: 0.5333333333333333, loss:0.9470316767692566\n",
            "epoch: 5200, acc: 0.51, loss:0.9663339257240295\n",
            "epoch: 5300, acc: 0.51, loss:0.9856399297714233\n",
            "epoch: 5400, acc: 0.5633333333333334, loss:1.002647876739502\n",
            "epoch: 5500, acc: 0.5733333333333334, loss:0.9685387015342712\n",
            "epoch: 5600, acc: 0.51, loss:0.9592396020889282\n",
            "epoch: 5700, acc: 0.58, loss:0.964918851852417\n",
            "epoch: 5800, acc: 0.5466666666666666, loss:0.9419671893119812\n",
            "epoch: 5900, acc: 0.54, loss:0.9621848464012146\n",
            "epoch: 6000, acc: 0.5233333333333333, loss:0.9861330389976501\n",
            "epoch: 6100, acc: 0.5866666666666667, loss:0.9836980104446411\n",
            "epoch: 6200, acc: 0.5533333333333333, loss:0.9403071999549866\n",
            "epoch: 6300, acc: 0.5366666666666666, loss:0.9414297342300415\n",
            "epoch: 6400, acc: 0.53, loss:0.9618615508079529\n",
            "epoch: 6500, acc: 0.5733333333333334, loss:0.9253088235855103\n",
            "epoch: 6600, acc: 0.58, loss:0.9747936725616455\n",
            "epoch: 6700, acc: 0.5533333333333333, loss:0.9310923218727112\n",
            "epoch: 6800, acc: 0.59, loss:0.9525468945503235\n",
            "epoch: 6900, acc: 0.5233333333333333, loss:0.9310550689697266\n",
            "epoch: 7000, acc: 0.55, loss:0.9755570292472839\n",
            "epoch: 7100, acc: 0.5666666666666667, loss:0.9172365069389343\n",
            "epoch: 7200, acc: 0.5866666666666667, loss:0.9689092040061951\n",
            "epoch: 7300, acc: 0.5533333333333333, loss:0.9468705058097839\n",
            "epoch: 7400, acc: 0.61, loss:0.9534051418304443\n",
            "epoch: 7500, acc: 0.5733333333333334, loss:0.9526743292808533\n",
            "epoch: 7600, acc: 0.5366666666666666, loss:0.9354404807090759\n",
            "epoch: 7700, acc: 0.5466666666666666, loss:0.9785068035125732\n",
            "epoch: 7800, acc: 0.5666666666666667, loss:0.9160088300704956\n",
            "epoch: 7900, acc: 0.59, loss:0.9704978466033936\n",
            "epoch: 8000, acc: 0.6033333333333334, loss:0.9497460722923279\n",
            "epoch: 8100, acc: 0.55, loss:0.9204681515693665\n",
            "epoch: 8200, acc: 0.5866666666666667, loss:0.9228540062904358\n",
            "epoch: 8300, acc: 0.5966666666666667, loss:0.9309743046760559\n",
            "epoch: 8400, acc: 0.59, loss:0.9302946925163269\n",
            "epoch: 8500, acc: 0.5766666666666667, loss:0.9379971027374268\n",
            "epoch: 8600, acc: 0.5666666666666667, loss:0.9221791625022888\n",
            "epoch: 8700, acc: 0.5866666666666667, loss:0.9238671660423279\n",
            "epoch: 8800, acc: 0.59, loss:0.9269946217536926\n",
            "epoch: 8900, acc: 0.59, loss:0.9285272359848022\n",
            "epoch: 9000, acc: 0.5833333333333334, loss:0.9278387427330017\n",
            "epoch: 9100, acc: 0.5833333333333334, loss:0.9291917085647583\n",
            "epoch: 9200, acc: 0.5833333333333334, loss:0.9291853904724121\n",
            "epoch: 9300, acc: 0.5833333333333334, loss:0.9295763373374939\n",
            "epoch: 9400, acc: 0.5766666666666667, loss:0.9290005564689636\n",
            "epoch: 9500, acc: 0.58, loss:0.9279197454452515\n",
            "epoch: 9600, acc: 0.5766666666666667, loss:0.9260796308517456\n",
            "epoch: 9700, acc: 0.5533333333333333, loss:0.9231849908828735\n",
            "epoch: 9800, acc: 0.5433333333333333, loss:0.9456762671470642\n",
            "epoch: 9900, acc: 0.58, loss:0.9455422163009644\n",
            "epoch: 10000, acc: 0.6033333333333334, loss:0.9419823288917542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3wUdf748dc7nYROQhGQ0IsVRLoIKE082xXbWc5TT0/P7gn2evL1vLPXU3+WU+xnA0RQEFBEAtJ7iYTQEiChBdI+vz9mNmzCbrJJdna2vJ+Pxz4y+5nZmc9ky3s+ZT4fMcaglFJKVRXndgaUUkqFJw0QSimlfNIAoZRSyicNEEoppXzSAKGUUsonDRBKKaV80gChlFLKJw0QKmqISLaInOl2PoItWs9LhT8NEEoppXzSAKGinogki8jTIrLVfjwtIsn2unQR+UpECkRkt4jMEZE4e91dIpIrIvtEZI2InOFj3/1FZLuIxHulnS8iS+3lfiKSJSJ7RWSHiPzbTx595kNE3gGOBb4Ukf0i8nd7+wEi8qO9/RIRGea1r1ki8riI/Gwf93MRaW6vSxGR/4rILvu1C0SkVdD+2SqqaIBQseAeYABwMnAS0A+41153O7AFyABaAXcDRkS6AzcCpxpjGgGjgeyqOzbGzAcOACO8ki8B3rOXnwGeMcY0BjoDH/rJo898GGMuAzYDvzHGNDTGPCEibYHJwKNAc+AO4BMRyfDa3+XAVUAboBR41k6/AmgCtAdaANcBRX7ypGKcBggVCy4FHjbG7DTG5AEPAZfZ60qwfkQ7GGNKjDFzjDVAWRmQDPQSkURjTLYxZoOf/U8CLgYQkUbAWXaaZ/9dRCTdGLPfGPOTn334y4cvfwSmGGOmGGPKjTHTgSz7uB7vGGOWG2MOAPcBf7BLOSVYgaGLMabMGLPQGLPX3z9OxTYNECoWHAP86vX8VzsN4J/AeuAbEdkoIuMBjDHrgVuAB4GdIvK+iByDb+8BF9jVVhcAi4wxnuP9GegGrLarc872sw+f+fCjA/B7u4qoQEQKgCFYAcYjp8r5JgLpwDvANOB9u7rtCRFJrOZYKoZpgFCxYCvWj6rHsXYaxph9xpjbjTGdgHOA2zxtDcaY94wxQ+zXGuD/fO3cGLMS60d4LJWrlzDGrDPGXAy0tF//sYik+diH33zYx/aWg1VCaOr1SDPGTPTapn2V8y0B8u3SyUPGmF7AIOBsrOoopY6iAUJFm0S7IdbzSMCq7rlXRDJEJB24H/gvgIicLSJdRESAQqyqpXIR6S4iI+xSwSGsevryao77HnAzMBT4yJMoIn8UkQxjTDlQYCcftR9/+bBX7wA6eW3+X+A3IjJaROLt8xwmIu28tvmjiPQSkVTgYeBjY0yZiAwXkRPs6qa9WIGjuvNSMUwDhIo2U7B+zD2PB7Eac7OApcAyYJGdBtAVmAHsB+YBLxpjZmK1P0wE8oHtWCWACdUcdxJwOvCdMSbfK30MsEJE9mM1WF9kjPHVKOwvHwCPYwW4AhG5wxiTA5yL1ZCdh1WiuJPK3+d3gDftvKcAN9nprYGPsYLDKuB7e1uljiI6YZBS0UVEZgH/Nca85nZeVGTTEoRSSimfNEAopZTySauYlFJK+aQlCKWUUj4luJ2BYElPTzeZmZluZ0MppSLKwoUL840xGb7WRU2AyMzMJCsry+1sKKVURBGRX/2t0yompZRSPmmAUEop5ZMGCKWUUj5pgFBKKeWTBgillFI+aYBQSinlkwYIpZRSPmmAiHC79h9m6rJtbmdDKRWFNEBEuGvezuL6dxex+0Cx21lRSkUZDRARLmePNfdMaZlOCqaUCi4NEEoppXzSABGBjDH8c9pq1u3Yh47WrpRyStQM1hdLCotKeGHmBt7/OQdrjntA3M2TUir6aAkigpWWa/FBKeUcDRARzJoNUIOEUsoZGiAikGh9klIqBDRARDwNFkrFqm9X7eDV2Rsc2782UkciOyZo5ZJSse3Pb1mzaF47tLMj+9cSRATydFyyIoSGCaWUMzRARCBf9z5ou4RSKtg0QEQiU+mPUko5QgNEBDIaGpRSIeBYgBCRN0Rkp4gs97O+h4jME5HDInJHlXVjRGSNiKwXkfFO5TFSeVcx6VAbSimnOFmCeBMYU8363cBNwJPeiSISD7wAjAV6AReLSC+H8hjRjFd00FKFUirYHAsQxpjZWEHA3/qdxpgFQEmVVf2A9caYjcaYYuB94Fyn8hmJTJW/Rz9RSqn6C8c2iLZAjtfzLXbaUUTkWhHJEpGsvLy8Oh2stKycv767kLnr8uv0ejcYrVdSSoVAOAaIgBljXjXG9DXG9M3IyKjTPnILilieu5c/vj6fuz5eGhE/vhUlCHN0mlJKBUs4BohcoL3X83Z2miM6tEjjm1uH8qfBmXyQlcO8DbucOlTQ+IphERDXlFIRJhwDxAKgq4h0FJEk4CLgCycPmJIYz11jetAoOYHPFjsWi4LG0yDt3TCtjdRKqWBzbCwmEZkEDAPSRWQL8ACQCGCMeVlEWgNZQGOgXERuAXoZY/aKyI3ANCAeeMMYs8KpfHqkJMYzsHMLft7kt1097BijVUtKBcPUZdto07QBJ7dv6nZWwopjAcIYc3EN67djVR/5WjcFmOJEvqrT+9hmfLNyB3sOFNMsLSnUhw+cVjEpFVTXv7sIgOyJ41zOSXgJxyom1/Q6pjEAa3bsczkn1fPVzVXjg1Iq2DRAeOmUngbApvwDLueker4bqTVEKKWCSwOEl7ZNG5CUEMfGvP1uZ6Va2iCtlAoFDRBe4uKEji3S2JgXISUIrzhRUma4/cMl5Ow+6EqelFLRRwNEFZ0y0tgQ5iUID++SxA/r8/lk0Rbu/t8yF3OklIomGiCq6NKyIZt3H+RQSZnbWfGrUuO0XZzw/BXRiYOUUsGhAaKKLi0bUm4ge1f4VjMdCQpeafZfDQ9KqWDRAFFF54yGAKzfGb7VTL46LJWXe0oQsK2wKKxLQEqpyKABoorOGQ0RCe8A4cuaHVZ+Z63JY+Dj33H1W1ku50gpFek0QFTRICmejulpLM4pcDsrfnlKEIYjVUuTft5caZu56/NZs30fy3MLQ5o3pVT00ADhw5Au6czfuJvDpeFdTVPTzXGjn57N2c/NDVFulIocBw6X8sLM9ZSV6z1F1dEA4cOZPVtRVFLG18u3u50Vn46M5qqUqosnv1nDP6et4cslW93OSljTAOHDkC7pdMpI49/T17L3UNUZUd3nXXDQXktK1d6Bw6UAYV9L4DYNED7ExQn/OP8EcvcUcd4LPzB12TaKS8vdzlaFUA3S993qHRQcLHbwCEqpcKYBwo8BnVrw9lX9KC83XP/uIk59bAZ//3gJM1bucL0Lqa/7IIJtz4Firnozi2vfXujcQZRyiY5tGRjH5oOIBoO6pDP9ttOZsy6PzxdvZeqy7XyYtYXUpHgu6NOWvwztTPvmqSHPVzA/25vyD/DTxl1c3O/YSuklZVaJaVMY3zCoVCxas30fnTLSSIx3/vpeA0QNEuPjGNGjFSN6tKK4tJyfNu7iiyVb+TBrCx9lbeH6YZ257vTOpCTGu53VOvnNc3PZf7j0qAChF1gqmkXqiDQ5uw8y+unZXDkokwfPOc7x42kVUy0kJcQxtFsGT/7+JL6/cxgje7Xi6RnrGPfsHFZt2xuyfFQaYqOev+T77cY6nU9CxZJI/bjvPmC1CS7avCckx9MAUUdtmjTg+Uv68M6f+7H3UCnnvfADX4Soy9zM1TuDvs9I/cIopZyjAaKeTuuawdSbT+Ok9k25adIvvDZno6PHm7dhF49NWRX0/fqLDxFaEleqWpFaxRTq6zgNEEGQ3jCZt6/qx9jjW/Po5FW8/P0Gx461LDc4Q4C8PS+7UrWYvyomLVioaKQl5sBoI3WQpCTG89zFvbn1wyVMnLqaeBGuGdop6MdZubVubR3GGLbsKarodXX/5ysqr693zpSKPKJl5GppCSKIEuLjeOoPJzHuxDY8NmVVQNVNpWXltbpbe9bavErPC4tqfm1JWTmPfLWK056YyccLt/jcptwY3v9581H3eOjXR0WzSJ3fPVTfSy1BBFlCfBxPX3gyxhgenbyKOBGuGtLR7/ZnPTuHtTv2s/6xsSQE0K+5Lh+MrvdMrVh+7rt1nHfyMUdt8/Xy7Yz/dBmb8g8w4ayedTiKUiraaIBwQGJ8HM9c1Jvy8l94+KuVNE9L4rzebX1uu9aex+FgSRmN4+MoL7euaeLjfIeC+k4p+uuug3TxChgeew9Z3V13HdChNVTs0Cqm6mkVk0MS4+N49uLe9Mtszj3/W0ZuQVG12/+wLh+ATndPofPdU7jwlXk+tyt3qnXNM6e1M3tXSkUgDRAOSkqI419/OIlyAw98vrzam9GqzmA3f9Nun9uVOzR+vWe3ngKK9vJQKvyE+oZWDRAOa988lVtHdmXGqp1MW+F/fol/TV9L5vjJldKy848eB8m5AoS1408W5bJ6+5GeUpHaX1wpVX8aIELgqsEd6dmmMY98tapiELxADHtyFpnjJ9P1nikAbN51kH320BjB5ok7ZeWGMU/PqUjfsfewI8dTStVefdsga0sDRAgkxMfx99HdyS0o4vPFlYfjaJxScz+BkjJD5vjJDP3nTKeyqFVKKqZE6sddq5ii1LDuGfRs05gXZ1WeB7d760Yu5uoIxxq/bdsKi7j0tZ8Cum9DKVWDEJUkNECEiIhww/DObMw7wDdebRGl5YZTOjRzMWeWnN0HKz0P9g1Ez3+3nh/W7wrZgIZKVSeSmtY27zrIPf9bVunCMlQ0QITQ2OPb0DE9jRdmra8oKpaWGZo0SCR74jgauDinRG7BoWrXL91SwOtzN4UoN0o5K5KqmP42aRHvzt/MstzCkB9bA0QIxccJ15/emeW5e5lt3/dQUlZOgn1T3Jd/G+xi7ip/ZareQHTO8z/wyFcrg7R3pcJEBBQlDpdaHVsS40OfWQ0QIXZe77Yc0ySFF2euB6wAkZhgvQ1dWjbitpHdXMnXoZLKvaucGqMmAr6PKpaE6ZXLWz9mM+5Zqzehp+djYnxcyLOrQ22EWFJCHFcN6cijk1exdEsBh0vLSfYag+mmM7qSmZ7G8O4ZnPDgNyHL19z1+ZWee7dZFxWXESxh+n1UKqw88MWKo9L8jL7jKMdKECLyhojsFJHlftaLiDwrIutFZKmI9PFaVyYii+3HF07l0S0XntqeRskJ/GfOJvYfLqVhla6u55x0DI1SrHaJcNDz/q/dzoJSzvDzo5s5fjJPTltT690t/HV30Ec78N5bqGOEk1VMbwJjqlk/FuhqP64FXvJaV2SMOdl+nONcFt3RKCWRi/sfy5Rl2yg4WEJygv+3IXviOO4d15PRx7UKYQ6du9LXKiYVKZ63q4EDNW/DLn770jxecmzCMImeGeWMMbMB3wMKWc4F3jaWn4CmItLGqfyEmysGZVZ0W6tpIL+rT+vEMxf1DkW2KoT6hhylIt22Qut7XHVcNYDi0vKgfqdCdaHlZiN1WyDH6/kWOw0gRUSyROQnETnP3w5E5Fp7u6y8vDx/m4Wltk0bcOWgTAD+OqxLjdunhLgLrMYHpYLjcGkZ3e6dysSpq+u2Axe/i+Hai6mDMaYvcAnwtIh09rWRMeZVY0xfY0zfjIyM0OYwCB485zhWPjya49s2CWj7eRNG8Mt9Ix3OlWXGqh0hOY5S0e5QsdULadLPm+u1HzcGznQzQOQC7b2et7PTMMZ4/m4EZgGhrV8JodSkwDuStWnSgGZpSQ7m5oiDQey5BFoiUeHFzc/j0i0F5O2LjEEw3QwQXwCX272ZBgCFxphtItJMRJIBRCQdGAzU/Q6tKDZhbI+QHzOYXV6VikXnPP8Do5+eXafXhjqwOdnNdRIwD+guIltE5M8icp2IXGdvMgXYCKwH/gP81U7vCWSJyBJgJjDRGKMBwofz+/iextRJ2/dWPySHUpHA7XlOdkfI1L6O3ShnjLm4hvUGuMFH+o/ACU7lKxqIWFcS3g3XPVo3YvX2fUE7hlO9mNz+YioFkVXl6WZWw7WRWgUgyb4De0SPlnx9y1CW3D8qaPv+dvXOoO1LqWiyc+8hnpmxrsaLqDnr8tgfxAm+vK+tQnWhpQEiAg3v3hKwxmbJnjiON648FYAmqYlBO8YvmwuCti+lQq283PDktDXs3HekSnR5biGfL84F6vcDe/P7i3lqxlqW5RZSVm6YumzbUcFiW2ERl73+MzdP+qXuBwoDGiAi0AuX9GHmHcOI9zE4yze3DnUhR0qFlwXZu3l+5nru/GhpRdrZz83l5vcXA0eqmIpLA5sCeFP+AZ74ejXGGA6WWB01ysoNr87eyPXvLuLLpdsqbe+5wApGSdzNm1Y1QESgBknxdExP87muWytnZ6jTO6xVJPCMUnC41Hevu+krrUm7npq+NqD9XfXmAl6ctYEteyqPerDD7rSRX6Xb6k6vzhyekZEP+OgBWFJWHvBEQKGejxo0QESlabc4V4rIyt5Tx1dqYFGhV3VeE4+9h6y2gV0B9ibyDLkNUFp2dKnDAPM3WiML/e+XXOJ8lO59BYKu90yl891TAPgwK4e3fsw+ahsXJpKroAEiCnVv3SioDdbeDhZXbnRbu2MfB4LYEKdUMNTnN7WmUvKKrXsBmLdxF3H2Vb0xhg+yjowcVJdr/b9/vNTnMN+b7emAl+SEvl1QA0SUapKayNy7hvP1LacFdb9lXt+dsnLDqKdm85d3Fgb1GErVl+c33slamfx9xRX7PyqmeB3YXykmEN7Basueg9Vs6QydMCiKtWuWGvR9en9gy+3leRt3Bfz6+nxZlKotfwHCcy+RL4E2sxkM8Z4SxFFT9gbH0XkJbX2TliBiQDAnHvLUo5aUlfPE16srpSkVLuozZW6grzTGam8AyN5V+ere6fbkUF1maQlC1UpRSRn/mLKKFmlJ/GfOJrezo5RPFVVMDv+U5u+3GrnXVhnFwOnjhuqSTANEjPjdKe34eOGWeu/n7Xm/svtAMUnVzIKnVLjwW8WE/x/ZQLtye29XTRNEvbhdNtdveYx48vcn8f/+dGq99+MZZCzQG4w89PYJFU5q+3H03P9QVHLkXgbvfVQNKt7xYX1ecMZIk0oN36GhASKGeIbocNr8jbvoOGEyu/YfPea9DtanQqFe3VyrWbfYawga75hQ3WsOl9TuYqpSXqoEnqgZ7luFp1cvOwUf9/AE1SOTV2IMLPIxnpOWJFQ4qOtXwF/jd9V+Gt4XQpH8kdc2iBgz6rjWbHzc6tVUcLCYkx+eHvRjLM+1biRau2MfI3u1Cvr+lapJfYaEqe6lpXUYFqNSSaOeV0ihLoFrCSKGJcbX/u1vmBz4NUW5jy+TVjGpUPB88uoyflGgXWSr2y5o90FUfa5VTCpU6tITqVXj5IC3zfG689PzwV6waTfLcwtrfVyl6sLJ6xFj/D1xhnesC9XAfRogYlhCHRojurRs6DPdGMOhksqjVX7nY6jjT3/J5ezn5tb6uErVSg2/19X9wFb3Wx9ow3Rd9l27/YSmKKEBIobV5SqkSQPfkxJN+jmHHvd9Tc7uI6UG7xomrVpSoeSp/nHyc1fpN9qhA3kfo7qb75wKGBogYtyM24ay+P6RAW/v73M4dbk1YcpHfm7G095Lyg3+flLr+oNqqnkWSqGqYtJeTDGuS8vaTTDkLwB4PPvtuoplnVxIuSWYH73TnviuxmNU/bn29wNe32yF+hulJQgFwPrHxgZ9nwbI2X2QpVsKtIpJuUJEKCkrZ+LU1XXeR85ur1nkvIfXCLA9on4DBwY67EedD1EtLUEoABLq0OXVm78P6GlPzATgwr7t67V/pepq+sodvPz9hjq9NnP85ErPZ63Jq1gO9KInqPdB2H93BzgTXn0F9KsgImkiEmcvdxORc0TEd2ulikm+rnS0hkm5xfuzV+JjitC69mL61qtn3v5qZlL0NS1pXVTNi+fppvwDQdl/TQK9bJwNpIhIW+Ab4DLgTacypaKDtkEot3gms8rOP+DYhUqlqXarHMQzTwQE1m7wmdf2783fXOu8OPVNCzRAiDHmIHAB8KIx5vfAcQ7lSUUgX1/CQIclUCrYcuzRVzfW4Uq7Lm0GS7ZUvvnT3yRa/vZ8yweLK5bv/t+yWh/fKQEHCBEZCFwKeCrl4p3JkopEvupEDxaX+dhSKedVnquh8s/yl0u2Oj4LYtaveyqWvSuzFnqlR4JAA8QtwATgf8aYFSLSCZjpXLaUG5Y/NLrOr129vfox7+vTk0OpYPrbpF+Csp+ZXg3W1bn8jZ8rli969aeK5aoN4DVxoydgQL2YjDHfA98D2I3V+caYm5zMmAq9hskJnNmzFTNW7Qj6vrcWHAr6PpXypz7tDuHUdLbUq+qq+iFADE6MPBVoL6b3RKSxiKQBy4GVInJn0HOjXHfV4ExH9ru1sOiotJe/38CP6/MdOZ5SHuH0g19bf3hlnqvHD7SKqZcxZi9wHjAV6IjVk0lFmSapoeu9PHHqai55bX7IjheJ9h4qYUH2brezocKAG9W0gQaIRPu+h/OAL4wxJUT2REnKj9Qkh+6d1E9LnVzzVha/f3keB4v997lXwRXOH1V/pSG3u7m+AmQDacBsEekA7HUoT8pFmS1SGdS5hdvZiFnbCovI23dkLu+VW62vmXYZrh3tFBEcgTZSPws865X0q4gMdyZLyk0iwjVDO/Hjhl1B3nFwdxcpjDFs3n2QhPg4xjw9m89uGEznjCNzapSUlfPv6Wv5evl2rj6tI/f8bzkA/Ts2Z/4mrVqqq8rDW7iXj0gXUIAQkSbAA8BQO+l74GFApwaLQnWZSKhGUf4l3V54iD0Hi+mYnsbeohIS4+OYsz6f3fsP8+CXKxl3Qhv2HSrlhncXcX7vtlzQpx03TfqFeRuPBGJPcACOCg7FpeXc+N4ihnRJ56wT29A4RUe6qY53l9DbP1pSq9eG6wgAK3L30rdDc5/r3B6s7w2s3kt/sJ9fBvw/rDurVZSJd6DDdXWf3wte/IFnL+5Nu2apQT9ufa3bsY+mqUlkNLKmWl346x7SkuPp0bpxpe0GPP4tAKd1TWfOunwGdW5RqRQ2xZ4vY/X2fTw+dTXvzt/MZq/JlWrS99EZAHy1dBtv/pjN17cMreEVsS1Mf+PrZfKybSwL8XS9gbZBdDbGPGCM2Wg/HgI6VfcCEXlDRHaKyHI/60VEnhWR9SKyVET6eK27QkTW2Y8rAj8dFQx9OjQL+j4PVBnYzPsmoUWbC3jl+41BP2YwjHxqNkP+78h8AL996UfGPD2Hjxdu4fW5m9iYt58lOQUV6+ess7rtbi2o3K236g/WNh/dfgO1evs+PliwmQ15++u8DxWZanNREQyBliCKRGSIMWYugIgMBmr6hL8JPA+87Wf9WKCr/egPvAT0F5HmWNVZfbEuPBeKyBfGmMi6Rz2CJdZz6G9fDpcGZ3RLpxwqKSMxPo54u3rtmRnr6JSRBlh5X7djHw1Tjnxd7rCrLR75qm7HKymr3yXuXZ9Y4/V8cv1AOmc0pGlqUr32F21q898d8eSsOr82XDjVKB9ogLgOeNtuiwDYA1R7ZW+MmS0imdVsci7wtrEq/H4SkaYi0gYYBkw3xuwGEJHpwBhgUoB5VfXkSBNEmJf5e9z3NaOPa8X2vYcZ1asVT81YW2n9yKdmu5Sz6v32JetGqm9vP71S43esK6/F560uA/rFioAuFY0xS4wxJwEnAicaY3oDI+p57LZAjtfzLXaav/SjiMi1IpIlIll5eYGNi6Jq5sR8tzX10vQ+ZHb+AQZP/I6Cg7WfFOX9nzezfmf140KVlxv6PjqDTxZu4fYPl/D9WuuzM23FDpbkFPDPaWtqfdyqsneFtirgjH99zwcLaj9MdLSKlqE23FarugRjzF77jmqA2xzIT60YY141xvQ1xvTNyMhwOztR6XentAvKfqqbXKWqC1+dR25BEfd8dqT5as+BYp8Tv1Q1/tNljHl6Diu2FlJ4sISTHvqGDxfkcM3bWUxbsZ1Hv1rJT5t2kb//MPd+tpxPFm3hCq/B1CKZp9pJxYY7a9k7qy7qc9tsfS8zcwHveSjb2Wm5WNVM3umz6nksVUePX3ACHy/c4vhxvD9MO/ZaN4pNXbatIq33I9MZe3xrXvrjKTXuq7TcMO7ZufRo3YjCohLu+3w5h0vLmb7SGoTwtbmbrGNG4b0Zh0rKSEnUkfhjwUde30unSj31aY2sb5a+AC63ezMNAAqNMduAacAoEWkmIs2AUXaackFifByNU0IzdXnevsOM+NesiudVq6WmLt9OcWl5wO0ZNQ1BHo163Pe121mIfFrFVKHab76I7MP3v0uABjW8dhJWSSBdRLZg9UxKBDDGvAxMAc4C1gMHgT/Z63aLyCPAAntXD3sarFXo/OX0ThXDPFx4anv+M2eTo8cTEaat2M7GvOobDLvdO5UrB2UysHMLerVpTPvmqRhj6DhhCueefIzP1/j7vkfrhEanPDKdHyeMIDlBSxKqfqoNEMaYRnXdsTHm4hrWG+AGP+vewLo5T7lkwtieFcvHtkhz/Hi7DhTTI8DuU//96Vfe/DGbxikJdG7ZkDHHtQbg88VbncxixNh1oJju935N9sRxbmdFRbjQ1B2oiNaztXWd0KZJCtsKnZn458slW2nmY6jxX3cdoFXjlEppnhLB3kOl/LK5gF82Fxz1Om/FYX4PhlOKS8tJSgj+PS2RoD7dqnWgvyM0QKgaeaoqAulFVB8fZR3dGH76P2cdleb0fMLRotu9U2O2FKFdVYMjNi8vVK14rkLz99f+voTaiMZeRcodsRYf3B6sT8WwPXW4Ya0uanP3qwrM1oIijmlabX8S5eU3z83lxHZNat4wRmgJQtXIu2pp7l3Dee/q/o4c51BJbLYVOGnQxO94Zsa6sB/qJJhmr81j1pqddXrtstxC3p2vd6R7aIBQNerZ5sjQ1u2apTJQZ5yLKE/NWEvBwRK3s+GoKcu2kTl+MuXlhsvf+JlFNXRcUIHRAKFq1LzKSKFOjNWknLU4J7Q/mOt27KM8hJ0J/vruIgB+CfF5hgunel5pgFA1iosTJt80hCUPjKpIu3dcz2peocLNn7/yPSkAABawSURBVN5cwDVvZ5E5fjLTVmznolfnBf0H3BjD1W8t4KVZGxj51GxemLkegPfmb+aEB6dVquYqKSvn0a9WsueA7/at8nJTp2qxWO3S7BRtpFYBOe6Yyg13V5/WiUcnr3IpN6ouPGNR/eWdhQAs3lLAgk27+cvpnQPex8HiUr5bvZPRx7Xm4OEymnjdu1JuYMaqncxYZdX/v78gh+YNkyqmUi0tN4Ch6z1TK16TvesgQ7q04IpBmRUl06LiMnre/zWX9j+W0ce1JikhjiU5BZXyuXPfIUb+ezbvXzugUhWo3sMQXBoglIpRF7z4IwBXDenoc5Ko7YWHSEuOp5HX/Nf3fracTxfl0r55A3J2F/Hu1f3ZXniI3/oY9Te3oKjSPNvegcFjxqodzFi1g39MXU1xaTkfXDuAJVusaqJ352+u1GDcoUUqLRun0OfYZkyan0NhUQlnPTuHTY8fuddD6j2GaGTSbq4qbF0xsANvzfvV7WyoOsrff5h1O/bTo00j8vYdrigtDnj8W9o0SWHehDMoKi5j/KdLK+5az9ltTSh56WvzAbi9nkNPe6qGLnz1J7/bXPdfq50he+K4iulWq/4wTluxvV75UJVpgFD1psNLR7aBj1tzbqclxXOguIwrB2VW/ABvKzzEXR8vJSkhLiLGunrzx2y3sxBVNECoegv3+aZVYA7Yo9tW/ZH9ICvHx9buWZ5byN5D0d1tt7aW5xbSv1Pwu59rgFBKRZSzn5vrdhbCziGHLtK0m6uqt97HNnU7CyqGZY6f7HYWopYGCFVvOjGNUu5yaigVDRCq3g4Wl7qdBaWUAzRAqDpb/cgY5t41vNLc0V/9bYh7GVIqRjl1e6AGCFVnKYnxtGuWWql4uyBbpw9XKlpogFD11q9j84rlYd1bupgTpWKUQ0UIDRCq3to1SwXgxUv7kJqkDdZKhZpTY1DpfRCq3uLjpGLu48Ion3dAqViiJQgVVMmJ+pFSKtScGqxPv80qqHRcJqWihwYIpZSKcFqCUBHl2OapFcuX9j/WxZwoFf30PggVMbInjmP234fTrlkDAP40OLPG13gHFKVUeNAAoRwz845hzLhtKF1aNqpx2xm3nR6CHCkVnXQsJhVxEuPjfAaHi/u1PyotLjZnilQqrGmAUCEXHydktqhcpRQnwhk99C5spepC2yBURLv5jK4Vy6lJCQztllFpvQi8fuWpoc6WUlFBezGpiHbryG68dnlfAP42ogv3juvF5JuOjPwqonVMSoUbDRAqZM7s1YrsieNolJJIUkIcxx3ThH6ZzWt+oVKqBtpIraLQG3861WcPphZpSQCc2VPbJZSqyWe/bHVkvzpYn3JVw+QEurRsWPH8utM78/L3G/jHBScwqlcrRIS56/J5f8Fmvlq6zcWcKhW+thYWObJfDRAqrNwxqhunZjZjRI+WFe0SQ7qmM2PVDpdzplT4Ko/E+yBEZIyIrBGR9SIy3sf6DiLyrYgsFZFZItLOa12ZiCy2H184mU8VPhLi4zijZ6ujGq0vG9gBgCsHZXL3WT2YN2EEl/Y/lh6ta74JT6lo51QvJsdKECISD7wAjAS2AAtE5AtjzEqvzZ4E3jbGvCUiI4DHgcvsdUXGmJOdyp+KLJ0zGjLtlqF0bdmQOPuuusfOP4HCohJOeugbl3OnlLuKissc2a+TJYh+wHpjzEZjTDHwPnBulW16Ad/ZyzN9rFeqQvfWjSqCg0eTBolkTxzHA7/p5VKulHLfxvwDjuzXyQDRFsjxer7FTvO2BLjAXj4faCQiLeznKSKSJSI/ich5vg4gItfa22Tl5eUFM+8qwlx06rF6J7ZSQeZ2N9c7gNNF5BfgdCAX8JSVOhhj+gKXAE+LSOeqLzbGvGqM6WuM6ZuRkVF1tYohDZLief3KU3nitydWSh99XCuXcqRU5HMyQOQC3qOytbPTKhhjthpjLjDG9AbusdMK7L+59t+NwCygt4N5VVHid6e048Hf9GLWHcPomJ7G3Wf1JHviOM456Ri3s6ZUxHEyQCwAuopIRxFJAi4CKvVGEpF0EfHkYQLwhp3eTESSPdsAgwHvxm2lfIqLE64c3JHM9DRm3jGMDi3SAHjy9ydx15ge/HLfSJdzqFTkcCxAGGNKgRuBacAq4ENjzAoReVhEzrE3GwasEZG1QCvgMTu9J5AlIkuwGq8nVun9pFStJCXEcf2wzjRLSyJ74jim3TIUgMfOPx6AAZ2qH/Kj6nDkSQlu184q5TxHP+XGmCnGmG7GmM7GmMfstPuNMV/Yyx8bY7ra21xtjDlsp/9ojDnBGHOS/fd1J/OpYk/31o3InjiOS/t3IHviOF75ozWQ4MfXDaRTRhqf3TAYgFG9WtEsNZGnLjyZ9IZJPHOR1fO6YbLVQ7xTulVCqTo6bXWaNEgE4LhjGgftfJRygt5JrRTQJNXqLgvw3e3DAJjz9+G0bpJCYrx1HXXuyVYnvLx9hxnRoyUFRSVktkijuT1uVOb4ybRr1oAte6of9sBzD6AOYKvCnQYIpfxo72ee7KtP6+QzfcVDo4mPE+Zt2EVpuWH6yu1sKzzEnHX5lba7fVR37vtsOe2aprI8d2/Q861UsGiAUCpI0uxqp+H2/Rgje1ldbPccKGb3wWJSEuPJyt7NuSe35bIBHViSU8DXK7Zzw/DOvDBzA4M6t+DHDbuYMLYHa3bs44werbjhvUUApDdMJn//Yb68cQi/eX6uOyeoYo44Ndl1qPXt29dkZWW5nQ2lam319r2MeXoOr13elyFd00lOiKsYi2rH3kOUlJWTFB/Hr7sPcmpmc4wxrNy2l3HPzqVZaiJ7Dpa4fAYqHHiqSGtLRBba95wdvU4DhFLuKys3xFftKhWgwoMlPPvdOl6fuynIuVKRxIkAoX31lAoDdQ0OYDWw33e2jkWlgk8DhFJRRIcWUcGkAUKpKLH0wVE8f0kfADplpNH72KYu50hFOu3FpFSUaJxi3YC3+P6RJCfE0yApHrDuz1CqLrQEoVSUaZqaVBEcAJqnJdG+eQMXc6QilZYglIpyi+wBCrUkoWpLSxBKxYiUxDhSEvUrrwKnJQilYsSSB0YBcMa/vqdRSiKrtukwH6p6GiCUihHJCVa7xNy7RgBa5aRqpuVNpWKYzmuhqqOfDqVi1JIHRlU0YCvliwYIpWJUkwaJNExO4J0/92PGbUPdzo4KQ9oGoVSMO62rNRvee1f3p3GDRM5+TocTjzTXnNbRkf1qCUIpBcCgLun0aN2IzBap3HpmN7ezo2rhnnHODNaoAUIpVSEhPo5Zdw7n5jO7sunxs7hqsDNXpioyaIBQSvkkItw1tjvPXHSy21mplTtHd3c7C1FDA4RSyq/khHjOPbktGY2SAZh1xzC++tsQAFo3TnEza341Tjm6abVLy4YVy418rK9OnxgeFVcDhFKqRl/eOIR3/tyPzPQ0jm/bhNl3DueTvw4CoGFyePV1aegjALRvdmSwwmUPjq5Y7uoVOPz59K+Dg5OxCKQBQilVo9ZNUip6OwEc2yKVtk0bsPyh0Sy870xuG9ktbMZ5ats0lVcuO6VS2uAu6T63nX7b6Uel3TuuZ0yXGryFxzuqlIpIDZMTSE6I56YzuvLzPWfyj/NPYPH9I/n4uoG0bVp5iPHfndKuYrlfx+ZMuem0Suv7d2zOD+NHcEn/Y486TocWqT6P/8WNg/nk+oGVnvfr2JzRx7Vm3IltABh3QhsyW6QFfE4dWqTx1lX9fK67cXiXiuWbz+haseyv3eO3fdr5TK/Ou1f3r/VrnBJeZUOlVMRqnJJY8ePeN7M5391xOsbAmu37aN0khVaNU7j7rJ5c8OIPvHd1fxLi4/jk+kGkJsVjjFUqaZicwCPnHs9do3uQlmyNHZUQH0d5ueG9nzczrHsG01bs4JGvVgJw/DFNiPOaz/vEdkeu/F+4pA+/67OT07tlsLWwKKBz+OT6QZzSoRmHSsp8rr9jdHeen7kegFtHduOZb9cBcMPwLvxz2hrAmtnvxAe/AeD+3/Tik0VbADitazpz1uX73O9lAzrwzk+/ApDsNfxJ9sRxro6ZpSUIpZQjkhPiSUmM56T2TWllN2g3T0ti1p3DSYi3fnpO6dCMnm0a0+uYxhVtGfFxQpPURBLi4yq2i4sT/jigA+2apfLnIUe63noHB1+G92hJXJxUHN8X75LOKR2aAZCSGO9v8xo1TkkkzZ6wSbyyd0GftpW2824sT00+cryO6YGXdpymAUIpFXH+99dB3DuuZ1D2NaBTC5/pS+4fxdpHx9Zpn2JHBmNgVK9WAKQkVA463iUF4UgkadEw2ec+65qX+tAAoZSKOL2PbcbVp3WqeD7pmgF8c6v/8aTi7B9sz5X9mT1b1XiMJqmJlUa7bWl39X3x0j68dGmfo7Y/7pjGFcvn9T4GgIQ44bKBHSryPKy71dB/5aBM+ne0AlPrxikkxldfEgJ3Rt7VNgilVMQb2Nl3KcAjPk64d1zPitLCa1f0rdX+Vz8ypiLInHVCm4r0WXcMo6CoBIAP/jKQXfsPA/DQOcdz8xndSEtO4LSuGWRPHAfA0xeezP99vYbxY3uw52Axk5dt4+XLTmF5bmGt8jN+bA92Hyjm1dkba/W62tIAoZSKCd4lDm9S88W73zaJTK/2gobJCZXaUTw3F3prmprE4xecAECbJg0qAsdJ7Zrw7vzNvHBJ75ozA5x9Yhu+WrotoG3rQwOEUiqmhcOkSSLC1JtPq3lDW1pSAp0zar7Jr77c/88opZSLMv3cY+G2S33cD+Lt1MxmjudBSxBKqZh27dDO/LxpN49fcKLbWangqXqqqkmDRAqLShCp3PPJKRoglFIx77UrTnU7C351TE8jKd6dyh4NEEopFcZm3jGsYtkYc2SF8wUIZ9sgRGSMiKwRkfUiMt7H+g4i8q2ILBWRWSLSzmvdFSKyzn5c4WQ+lVIqkggS0L0T9eVYgBCReOAFYCzQC7hYRKrOi/ck8LYx5kTgYeBx+7XNgQeA/kA/4AERcb5FRimlwth/Lu/L6ONa0SglISTVTk4eoR+w3hiz0RhTDLwPnFtlm17Ad/byTK/1o4Hpxpjdxpg9wHRgjIN5VUqpsNe/UwteuawvcXFSMU6Vk5w8Qlsgx+v5FjvN2xLgAnv5fKCRiLQI8LWIyLUikiUiWXl5eUHLuFJKKffvg7gDOF1EfgFOB3IB3+Ps+mCMedUY09cY0zcjI6PmFyilVBR55Nzj+PLGIY7t38leTLlAe6/n7ey0CsaYrdglCBFpCPzWGFMgIrnAsCqvneVgXpVSKuJcNjDT0f07WYJYAHQVkY4ikgRcBHzhvYGIpIuIJw8TgDfs5WnAKBFpZjdOj7LTlFJKhYhjAcIYUwrciPXDvgr40BizQkQeFpFz7M2GAWtEZC3QCnjMfu1u4BGsILMAeNhOU0opFSJS6caLCNa3b1+TlZXldjaUUiqiiMhCY4zP8c/dbqRWSikVpjRAKKWU8kkDhFJKKZ80QCillPJJA4RSSimfoqYXk4jkAb/WYxfpQH6QshMpYu2cY+18Qc85VtTnnDsYY3wORRE1AaK+RCTLX1evaBVr5xxr5wt6zrHCqXPWKiallFI+aYBQSinlkwaII151OwMuiLVzjrXzBT3nWOHIOWsbhFJKKZ+0BKGUUsonDRBKKaV8ivkAISJjRGSNiKwXkfFu56c+RKS9iMwUkZUiskJEbrbTm4vIdBFZZ/9tZqeLiDxrn/tSEenjta8r7O3XicgVbp1TIEQkXkR+EZGv7OcdRWS+fV4f2PORICLJ9vP19vpMr31MsNPXiMhod84kMCLSVEQ+FpHVIrJKRAbGwHt8q/2ZXi4ik0QkJdreZxF5Q0R2ishyr7Sgva8icoqILLNf86yISI2ZMsbE7AOIBzYAnYAkrDmye7mdr3qcTxugj73cCFgL9AKeAMbb6eOB/7OXzwKmAgIMAObb6c2BjfbfZvZyM7fPr5rzvg14D/jKfv4hcJG9/DJwvb38V+Ble/ki4AN7uZf93icDHe3PRLzb51XN+b4FXG0vJwFNo/k9xpqPfhPQwOv9vTLa3mdgKNAHWO6VFrT3FfjZ3lbs146tMU9u/1NcfkMGAtO8nk8AJridryCe3+fASGAN0MZOawOssZdfAS722n6Nvf5i4BWv9ErbhdMDazrab4ERwFf2hz8fSKj6HmNNXjXQXk6wt5Oq77v3duH2AJrYP5ZSJT2a3+O2QI79o5dgv8+jo/F9BjKrBIigvK/2utVe6ZW28/eI9SomzwfPY4udFvHsYnVvYD7QyhizzV61HWv2PvB//pH0f3ka+DtQbj9vARQYa0ZDqJz3ivOy1xfa20fS+XYE8oD/Z1ervSYiaUTxe2yMyQWeBDYD27Det4VE9/vsEaz3ta29XDW9WrEeIKKSiDQEPgFuMcbs9V5nrMuHqOjbLCJnAzuNMQvdzksIJWBVQ7xkjOkNHMCqeqgQTe8xgF3vfi5WcDwGSAPGuJopF7jxvsZ6gMgF2ns9b2enRSwRScQKDu8aYz61k3eISBt7fRtgp53u7/wj5f8yGDhHRLKB97GqmZ4BmopIgr2Nd94rzste3wTYReScL1hXfluMMfPt5x9jBYxofY8BzgQ2GWPyjDElwKdY7300v88ewXpfc+3lqunVivUAsQDoaveGSMJq0PrC5TzVmd0r4XVglTHm316rvgA8vRmuwGqb8KRfbveIGAAU2sXZacAoEWlmX72NstPCijFmgjGmnTEmE+u9+84YcykwE/idvVnV8/X8H35nb2/s9Ivs3i8dga5YDXphxxizHcgRke520hnASqL0PbZtBgaISKr9Gfecc9S+z16C8r7a6/aKyAD7f3i51778c7tRxu0HVm+AtVg9Gu5xOz/1PJchWEXQpcBi+3EWVv3rt8A6YAbQ3N5egBfsc18G9PXa11XAevvxJ7fPLYBzH8aRXkydsL7464GPgGQ7PcV+vt5e38nr9ffY/4c1BNC7w+VzPRnIst/nz7B6q0T1eww8BKwGlgPvYPVEiqr3GZiE1cZSglVS/HMw31egr/3/2wA8T5WODr4eOtSGUkopn2K9ikkppZQfGiCUUkr5pAFCKaWUTxoglFJK+aQBQimllE8aIJSqAxG5xx5ddKmILBaR/iJyi4ikup03pYJFu7kqVUsiMhD4NzDMGHNYRNKxRlX9Eas/er6rGVQqSLQEoVTttQHyjTGHAeyA8DuscYJmishMABEZJSLzRGSRiHxkj5GFiGSLyBP22Pw/i0gXO/339nwHS0RktjunptQRWoJQqpbsH/q5QCrW3a0fGGO+t8eE6muMybdLFZ9i3a17QETuwrrT92F7u/8YYx4TkcuBPxhjzhaRZcAYY0yuiDQ1xhS4coJK2bQEoVQtGWP2A6cA12INvf2BiFxZZbMBWBPU/CAii7HG0engtX6S19+B9vIPwJsicg3WZFZKuSqh5k2UUlUZY8qAWcAs+8q/6pSdAkw3xlzsbxdVl40x14lIf2AcsFBETjHG7ApuzpUKnJYglKolEekuIl29kk4GfgX2YU31CvATMNirfSFNRLp5veZCr7/z7G06G2PmG2PuxyqZeA/brFTIaQlCqdprCDwnIk2BUqxRM6/FmsbxaxHZaowZblc7TRKRZPt192KNHAzQTESWAoft1wH80w48gjWC55KQnI1SfmgjtVIh5t2Y7XZelKqOVjEppZTySUsQSimlfNIShFJKKZ80QCillPJJA4RSSimfNEAopZTySQOEUkopn/4/19K2a9uIZg4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luAkdVEc8Yy1"
      },
      "source": [
        "### SGD Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SilHYmJpDWc6"
      },
      "source": [
        "# SGD optimizer\n",
        "class Optimizer_SGD:\n",
        "\n",
        "    # Initialize optimizer - set settings,\n",
        "    # learning rate of 1. is default for this optimizer\n",
        "    def __init__(self, learning_rate=1., decay=0.):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "        # Vanilla SGD updates \n",
        "        weight_updates = -self.current_learning_rate * \\\n",
        "                          layer.dweights\n",
        "        bias_updates = -self.current_learning_rate * \\\n",
        "                        layer.dbiases\n",
        "\n",
        "        # Update weights and biases using either\n",
        "        # vanilla or momentum updates\n",
        "        layer.weights += weight_updates\n",
        "        layer.biases += bias_updates\n",
        "\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z6aA7A1cDmd2",
        "outputId": "c40d12c6-45f2-43ba-c3c5-07a1f0e9f44c"
      },
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "\n",
        "# Create dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n",
        "\n",
        "# Create Dense layer with 2 input features and 3 output values\n",
        "dense1 = Layer_Dense(2, 64)\n",
        "\n",
        "# Create ReLU activation (to be used with Dense layer):\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "# Create second Dense layer with 3 input features (as we take output\n",
        "# of previous layer here) and 3 output values (output values)\n",
        "dense2 = Layer_Dense(64, 3)\n",
        "\n",
        "# Create Softmax classifier's combined loss and activation\n",
        "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
        "\n",
        "optimizer = Optimizer_SGD(decay = 1e-2)\n",
        "\n",
        "#train in loop \n",
        "losses = []\n",
        "for epoch in range(10001):\n",
        "\n",
        "  #forward passes \n",
        "  dense1.forward(X)\n",
        "  activation1.forward(dense1.output)\n",
        "  dense2.forward(activation1.output)\n",
        "  loss = loss_activation.forward(dense2.output, y)\n",
        "  losses.append(loss)\n",
        "  # calcualte accuracy \n",
        "  predictions = np.argmax(loss_activation.output, axis = 1)\n",
        "  if len(y.shape) == 2:\n",
        "    y = np.argmax(y, axis = 1)\n",
        "  \n",
        "  accuracy = np.mean(predictions == y)\n",
        "\n",
        "  if not epoch % 100:\n",
        "    print(f'epoch: {epoch}, acc: {accuracy}, loss:{loss}, lr:{optimizer.current_learning_rate}' )\n",
        "\n",
        "  # backward pass \n",
        "  loss_activation.backward(loss_activation.output, y)\n",
        "  dense2.backward(loss_activation.dinputs)\n",
        "  activation1.backward(dense2.dinputs)\n",
        "  dense1.backward(activation1.dinputs)\n",
        "\n",
        "  #update params \n",
        "  optimizer.pre_update_params()\n",
        "  optimizer.update_params(dense1)\n",
        "  optimizer.update_params(dense2)\n",
        "  optimizer.post_update_params()\n",
        "\n",
        "plt.plot(range(len(losses)), losses)\n",
        "plt.title('Loss vs steps')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, acc: 0.36, loss:1.098594307899475, lr:1.0\n",
            "epoch: 100, acc: 0.4033333333333333, loss:1.094583511352539, lr:0.5025125628140703\n",
            "epoch: 200, acc: 0.39666666666666667, loss:1.0842682123184204, lr:0.33444816053511706\n",
            "epoch: 300, acc: 0.4, loss:1.0800079107284546, lr:0.2506265664160401\n",
            "epoch: 400, acc: 0.4066666666666667, loss:1.078490138053894, lr:0.2004008016032064\n",
            "epoch: 500, acc: 0.42, loss:1.077833652496338, lr:0.1669449081803005\n",
            "epoch: 600, acc: 0.42, loss:1.0774352550506592, lr:0.14306151645207438\n",
            "epoch: 700, acc: 0.4166666666666667, loss:1.0771820545196533, lr:0.1251564455569462\n",
            "epoch: 800, acc: 0.41333333333333333, loss:1.0769789218902588, lr:0.11123470522803114\n",
            "epoch: 900, acc: 0.41, loss:1.076817274093628, lr:0.10010010010010009\n",
            "epoch: 1000, acc: 0.4166666666666667, loss:1.0766910314559937, lr:0.09099181073703366\n",
            "epoch: 1100, acc: 0.42333333333333334, loss:1.0765801668167114, lr:0.08340283569641367\n",
            "epoch: 1200, acc: 0.42333333333333334, loss:1.0764901638031006, lr:0.07698229407236336\n",
            "epoch: 1300, acc: 0.4266666666666667, loss:1.0764083862304688, lr:0.07147962830593281\n",
            "epoch: 1400, acc: 0.4266666666666667, loss:1.0763334035873413, lr:0.066711140760507\n",
            "epoch: 1500, acc: 0.4266666666666667, loss:1.076262354850769, lr:0.06253908692933083\n",
            "epoch: 1600, acc: 0.4266666666666667, loss:1.076193928718567, lr:0.05885815185403177\n",
            "epoch: 1700, acc: 0.42, loss:1.0761269330978394, lr:0.055586436909394105\n",
            "epoch: 1800, acc: 0.42, loss:1.07606041431427, lr:0.052659294365455495\n",
            "epoch: 1900, acc: 0.42, loss:1.0759949684143066, lr:0.05002501250625312\n",
            "epoch: 2000, acc: 0.42, loss:1.0759315490722656, lr:0.047641734159123386\n",
            "epoch: 2100, acc: 0.42333333333333334, loss:1.0758695602416992, lr:0.04547521600727603\n",
            "epoch: 2200, acc: 0.4266666666666667, loss:1.0758087635040283, lr:0.04349717268377555\n",
            "epoch: 2300, acc: 0.4266666666666667, loss:1.075749158859253, lr:0.04168403501458941\n",
            "epoch: 2400, acc: 0.4166666666666667, loss:1.0756906270980835, lr:0.04001600640256102\n",
            "epoch: 2500, acc: 0.4166666666666667, loss:1.0756319761276245, lr:0.03847633705271258\n",
            "epoch: 2600, acc: 0.4166666666666667, loss:1.0755743980407715, lr:0.03705075954057058\n",
            "epoch: 2700, acc: 0.4166666666666667, loss:1.0755178928375244, lr:0.03572704537334762\n",
            "epoch: 2800, acc: 0.41333333333333333, loss:1.075461983680725, lr:0.03449465332873405\n",
            "epoch: 2900, acc: 0.41333333333333333, loss:1.075406551361084, lr:0.03334444814938312\n",
            "epoch: 3000, acc: 0.41333333333333333, loss:1.0753517150878906, lr:0.03226847370119393\n",
            "epoch: 3100, acc: 0.41333333333333333, loss:1.0752969980239868, lr:0.03125976867771178\n",
            "epoch: 3200, acc: 0.41333333333333333, loss:1.075243353843689, lr:0.03031221582297666\n",
            "epoch: 3300, acc: 0.41333333333333333, loss:1.0751901865005493, lr:0.02942041776993233\n",
            "epoch: 3400, acc: 0.41, loss:1.0751373767852783, lr:0.028579594169762787\n",
            "epoch: 3500, acc: 0.41, loss:1.0750848054885864, lr:0.027785495971103084\n",
            "epoch: 3600, acc: 0.4066666666666667, loss:1.075033187866211, lr:0.02703433360367667\n",
            "epoch: 3700, acc: 0.4066666666666667, loss:1.0749820470809937, lr:0.026322716504343247\n",
            "epoch: 3800, acc: 0.4066666666666667, loss:1.0749313831329346, lr:0.025647601949217745\n",
            "epoch: 3900, acc: 0.4066666666666667, loss:1.0748807191848755, lr:0.02500625156289072\n",
            "epoch: 4000, acc: 0.4066666666666667, loss:1.0748282670974731, lr:0.02439619419370578\n",
            "epoch: 4100, acc: 0.4066666666666667, loss:1.0747779607772827, lr:0.023815194093831864\n",
            "epoch: 4200, acc: 0.4066666666666667, loss:1.0747281312942505, lr:0.02326122354035822\n",
            "epoch: 4300, acc: 0.4033333333333333, loss:1.0746769905090332, lr:0.022732439190725165\n",
            "epoch: 4400, acc: 0.4033333333333333, loss:1.0746269226074219, lr:0.02222716159146477\n",
            "epoch: 4500, acc: 0.4033333333333333, loss:1.0745782852172852, lr:0.021743857360295715\n",
            "epoch: 4600, acc: 0.4033333333333333, loss:1.0745298862457275, lr:0.021281123643328365\n",
            "epoch: 4700, acc: 0.4033333333333333, loss:1.074480414390564, lr:0.02083767451552407\n",
            "epoch: 4800, acc: 0.4033333333333333, loss:1.074431300163269, lr:0.020412329046744233\n",
            "epoch: 4900, acc: 0.4033333333333333, loss:1.0743829011917114, lr:0.020004000800160033\n",
            "epoch: 5000, acc: 0.4033333333333333, loss:1.0743353366851807, lr:0.019611688566385566\n",
            "epoch: 5100, acc: 0.4033333333333333, loss:1.0742881298065186, lr:0.019234468166955183\n",
            "epoch: 5200, acc: 0.4, loss:1.0742411613464355, lr:0.018871485185884128\n",
            "epoch: 5300, acc: 0.4, loss:1.0741947889328003, lr:0.018521948508983144\n",
            "epoch: 5400, acc: 0.4, loss:1.0741490125656128, lr:0.01818512456810329\n",
            "epoch: 5500, acc: 0.4, loss:1.074103593826294, lr:0.01786033220217896\n",
            "epoch: 5600, acc: 0.4, loss:1.0740586519241333, lr:0.01754693805930865\n",
            "epoch: 5700, acc: 0.4, loss:1.0740149021148682, lr:0.01724435247456458\n",
            "epoch: 5800, acc: 0.4, loss:1.0739717483520508, lr:0.016952025767079167\n",
            "epoch: 5900, acc: 0.4, loss:1.0739294290542603, lr:0.01666944490748458\n",
            "epoch: 6000, acc: 0.4, loss:1.0738879442214966, lr:0.016396130513198885\n",
            "epoch: 6100, acc: 0.4, loss:1.073846697807312, lr:0.016131634134537828\n",
            "epoch: 6200, acc: 0.4, loss:1.0738059282302856, lr:0.015875535799333228\n",
            "epoch: 6300, acc: 0.4, loss:1.073765754699707, lr:0.01562744178777934\n",
            "epoch: 6400, acc: 0.4, loss:1.073725938796997, lr:0.015386982612709646\n",
            "epoch: 6500, acc: 0.4, loss:1.0736864805221558, lr:0.015153811183512654\n",
            "epoch: 6600, acc: 0.4, loss:1.0736474990844727, lr:0.014927601134497688\n",
            "epoch: 6700, acc: 0.4033333333333333, loss:1.0736087560653687, lr:0.014708045300779527\n",
            "epoch: 6800, acc: 0.4033333333333333, loss:1.0735702514648438, lr:0.014494854326714018\n",
            "epoch: 6900, acc: 0.4, loss:1.073532223701477, lr:0.014287755393627663\n",
            "epoch: 7000, acc: 0.4, loss:1.0734946727752686, lr:0.014086491055078181\n",
            "epoch: 7100, acc: 0.4, loss:1.0734572410583496, lr:0.013890818169190166\n",
            "epoch: 7200, acc: 0.39666666666666667, loss:1.0734200477600098, lr:0.013700506918755994\n",
            "epoch: 7300, acc: 0.39666666666666667, loss:1.0733833312988281, lr:0.013515339910798757\n",
            "epoch: 7400, acc: 0.39666666666666667, loss:1.0733470916748047, lr:0.013335111348179758\n",
            "epoch: 7500, acc: 0.39666666666666667, loss:1.0733108520507812, lr:0.013159626266614028\n",
            "epoch: 7600, acc: 0.39666666666666667, loss:1.073275089263916, lr:0.012988699831146902\n",
            "epoch: 7700, acc: 0.39666666666666667, loss:1.073239803314209, lr:0.012822156686754713\n",
            "epoch: 7800, acc: 0.39666666666666667, loss:1.073204755783081, lr:0.0126598303582732\n",
            "epoch: 7900, acc: 0.39666666666666667, loss:1.073169469833374, lr:0.012501562695336917\n",
            "epoch: 8000, acc: 0.39666666666666667, loss:1.0731343030929565, lr:0.012347203358439314\n",
            "epoch: 8100, acc: 0.39666666666666667, loss:1.0730993747711182, lr:0.012196609342602758\n",
            "epoch: 8200, acc: 0.39666666666666667, loss:1.0730648040771484, lr:0.012049644535486204\n",
            "epoch: 8300, acc: 0.39666666666666667, loss:1.073030710220337, lr:0.011906179307060364\n",
            "epoch: 8400, acc: 0.39666666666666667, loss:1.072996735572815, lr:0.011766090128250382\n",
            "epoch: 8500, acc: 0.39666666666666667, loss:1.0729631185531616, lr:0.01162925921618793\n",
            "epoch: 8600, acc: 0.39666666666666667, loss:1.0729297399520874, lr:0.011495574203931488\n",
            "epoch: 8700, acc: 0.39666666666666667, loss:1.0728964805603027, lr:0.011364927832708264\n",
            "epoch: 8800, acc: 0.39666666666666667, loss:1.0728635787963867, lr:0.011237217664906169\n",
            "epoch: 8900, acc: 0.39666666666666667, loss:1.0728307962417603, lr:0.011112345816201801\n",
            "epoch: 9000, acc: 0.39666666666666667, loss:1.072798252105713, lr:0.010990218705352238\n",
            "epoch: 9100, acc: 0.39666666666666667, loss:1.0727659463882446, lr:0.010870746820306556\n",
            "epoch: 9200, acc: 0.39666666666666667, loss:1.0727338790893555, lr:0.010753844499408539\n",
            "epoch: 9300, acc: 0.39666666666666667, loss:1.0727018117904663, lr:0.010639429726566656\n",
            "epoch: 9400, acc: 0.39666666666666667, loss:1.0726702213287354, lr:0.010527423939362039\n",
            "epoch: 9500, acc: 0.39666666666666667, loss:1.0726385116577148, lr:0.010417751849150954\n",
            "epoch: 9600, acc: 0.39666666666666667, loss:1.072607159614563, lr:0.010310341272296112\n",
            "epoch: 9700, acc: 0.39666666666666667, loss:1.0725762844085693, lr:0.010205122971731808\n",
            "epoch: 9800, acc: 0.39666666666666667, loss:1.0725454092025757, lr:0.010102030508132133\n",
            "epoch: 9900, acc: 0.39666666666666667, loss:1.0725147724151611, lr:0.01000100010001\n",
            "epoch: 10000, acc: 0.39666666666666667, loss:1.0724841356277466, lr:0.009901970492127933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHnoAADQEWCI"
      },
      "source": [
        "Less decay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UVttgor2EXqy",
        "outputId": "569131c2-5e8b-4b2c-9c87-40100f4dff74"
      },
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "\n",
        "# Create dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n",
        "\n",
        "# Create Dense layer with 2 input features and 3 output values\n",
        "dense1 = Layer_Dense(2, 64)\n",
        "\n",
        "# Create ReLU activation (to be used with Dense layer):\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "# Create second Dense layer with 3 input features (as we take output\n",
        "# of previous layer here) and 3 output values (output values)\n",
        "dense2 = Layer_Dense(64, 3)\n",
        "\n",
        "# Create Softmax classifier's combined loss and activation\n",
        "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
        "\n",
        "optimizer = Optimizer_SGD(decay = 1e-3)\n",
        "\n",
        "#train in loop \n",
        "losses = []\n",
        "for epoch in range(10001):\n",
        "\n",
        "  #forward passes \n",
        "  dense1.forward(X)\n",
        "  activation1.forward(dense1.output)\n",
        "  dense2.forward(activation1.output)\n",
        "  loss = loss_activation.forward(dense2.output, y)\n",
        "  losses.append(loss)\n",
        "  # calcualte accuracy \n",
        "  predictions = np.argmax(loss_activation.output, axis = 1)\n",
        "  if len(y.shape) == 2:\n",
        "    y = np.argmax(y, axis = 1)\n",
        "  \n",
        "  accuracy = np.mean(predictions == y)\n",
        "\n",
        "  if not epoch % 100:\n",
        "    print(f'epoch: {epoch}, acc: {accuracy}, loss:{loss}, lr:{optimizer.current_learning_rate}' )\n",
        "\n",
        "  # backward pass \n",
        "  loss_activation.backward(loss_activation.output, y)\n",
        "  dense2.backward(loss_activation.dinputs)\n",
        "  activation1.backward(dense2.dinputs)\n",
        "  dense1.backward(activation1.dinputs)\n",
        "\n",
        "  #update params \n",
        "  optimizer.pre_update_params()\n",
        "  optimizer.update_params(dense1)\n",
        "  optimizer.update_params(dense2)\n",
        "  optimizer.post_update_params()\n",
        "\n",
        "plt.plot(range(len(losses)), losses)\n",
        "plt.title('Loss vs steps')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, acc: 0.36, loss:1.098594307899475, lr:1.0\n",
            "epoch: 100, acc: 0.4, loss:1.088205099105835, lr:0.9099181073703367\n",
            "epoch: 200, acc: 0.42333333333333334, loss:1.0777205228805542, lr:0.8340283569641367\n",
            "epoch: 300, acc: 0.42333333333333334, loss:1.0764548778533936, lr:0.7698229407236336\n",
            "epoch: 400, acc: 0.42, loss:1.0755491256713867, lr:0.7147962830593281\n",
            "epoch: 500, acc: 0.4033333333333333, loss:1.0741554498672485, lr:0.66711140760507\n",
            "epoch: 600, acc: 0.4033333333333333, loss:1.0723166465759277, lr:0.6253908692933083\n",
            "epoch: 700, acc: 0.41, loss:1.0703470706939697, lr:0.5885815185403178\n",
            "epoch: 800, acc: 0.4066666666666667, loss:1.0682345628738403, lr:0.5558643690939411\n",
            "epoch: 900, acc: 0.4266666666666667, loss:1.0658538341522217, lr:0.526592943654555\n",
            "epoch: 1000, acc: 0.44333333333333336, loss:1.0631405115127563, lr:0.5002501250625312\n",
            "epoch: 1100, acc: 0.43666666666666665, loss:1.059455156326294, lr:0.4764173415912339\n",
            "epoch: 1200, acc: 0.44666666666666666, loss:1.0557358264923096, lr:0.45475216007276037\n",
            "epoch: 1300, acc: 0.44, loss:1.051923394203186, lr:0.43497172683775553\n",
            "epoch: 1400, acc: 0.43, loss:1.0476053953170776, lr:0.4168403501458941\n",
            "epoch: 1500, acc: 0.41333333333333333, loss:1.040504813194275, lr:0.4001600640256102\n",
            "epoch: 1600, acc: 0.42, loss:1.032575249671936, lr:0.3847633705271258\n",
            "epoch: 1700, acc: 0.43666666666666665, loss:1.0250996351242065, lr:0.3705075954057058\n",
            "epoch: 1800, acc: 0.44666666666666666, loss:1.017133355140686, lr:0.35727045373347627\n",
            "epoch: 1900, acc: 0.44666666666666666, loss:1.008447289466858, lr:0.3449465332873405\n",
            "epoch: 2000, acc: 0.49, loss:0.999559760093689, lr:0.33344448149383127\n",
            "epoch: 2100, acc: 0.45, loss:1.0048989057540894, lr:0.32268473701193934\n",
            "epoch: 2200, acc: 0.42333333333333334, loss:1.0087372064590454, lr:0.31259768677711786\n",
            "epoch: 2300, acc: 0.43333333333333335, loss:1.0062755346298218, lr:0.3031221582297666\n",
            "epoch: 2400, acc: 0.43333333333333335, loss:1.0024940967559814, lr:0.29420417769932333\n",
            "epoch: 2500, acc: 0.44, loss:0.9987099170684814, lr:0.2857959416976279\n",
            "epoch: 2600, acc: 0.44333333333333336, loss:0.9944607615470886, lr:0.2778549597110308\n",
            "epoch: 2700, acc: 0.46, loss:0.9896107912063599, lr:0.2703433360367667\n",
            "epoch: 2800, acc: 0.4633333333333333, loss:0.9859461188316345, lr:0.26322716504343247\n",
            "epoch: 2900, acc: 0.48, loss:0.9811713695526123, lr:0.25647601949217746\n",
            "epoch: 3000, acc: 0.4866666666666667, loss:0.977130115032196, lr:0.25006251562890724\n",
            "epoch: 3100, acc: 0.4866666666666667, loss:0.9723496437072754, lr:0.2439619419370578\n",
            "epoch: 3200, acc: 0.5033333333333333, loss:0.9681275486946106, lr:0.23815194093831865\n",
            "epoch: 3300, acc: 0.5066666666666667, loss:0.9633573293685913, lr:0.23261223540358225\n",
            "epoch: 3400, acc: 0.51, loss:0.9590501189231873, lr:0.22732439190725165\n",
            "epoch: 3500, acc: 0.5166666666666667, loss:0.9550294876098633, lr:0.22227161591464767\n",
            "epoch: 3600, acc: 0.5233333333333333, loss:0.9505584836006165, lr:0.21743857360295715\n",
            "epoch: 3700, acc: 0.5266666666666666, loss:0.9462372064590454, lr:0.21281123643328367\n",
            "epoch: 3800, acc: 0.53, loss:0.9415592551231384, lr:0.20837674515524068\n",
            "epoch: 3900, acc: 0.53, loss:0.9366893768310547, lr:0.20412329046744235\n",
            "epoch: 4000, acc: 0.5366666666666666, loss:0.9319341778755188, lr:0.2000400080016003\n",
            "epoch: 4100, acc: 0.5466666666666666, loss:0.9286285638809204, lr:0.19611688566385566\n",
            "epoch: 4200, acc: 0.5466666666666666, loss:0.9241488575935364, lr:0.19234468166955185\n",
            "epoch: 4300, acc: 0.5466666666666666, loss:0.920760989189148, lr:0.18871485185884126\n",
            "epoch: 4400, acc: 0.5466666666666666, loss:0.9167051315307617, lr:0.18521948508983144\n",
            "epoch: 4500, acc: 0.56, loss:0.912702739238739, lr:0.18185124568103292\n",
            "epoch: 4600, acc: 0.55, loss:0.9091458916664124, lr:0.1786033220217896\n",
            "epoch: 4700, acc: 0.56, loss:0.9052979350090027, lr:0.1754693805930865\n",
            "epoch: 4800, acc: 0.56, loss:0.900590181350708, lr:0.17244352474564578\n",
            "epoch: 4900, acc: 0.5566666666666666, loss:0.8969241380691528, lr:0.16952025767079165\n",
            "epoch: 5000, acc: 0.5633333333333334, loss:0.8934779763221741, lr:0.16669444907484582\n",
            "epoch: 5100, acc: 0.5666666666666667, loss:0.8902596235275269, lr:0.16396130513198884\n",
            "epoch: 5200, acc: 0.57, loss:0.887595534324646, lr:0.16131634134537828\n",
            "epoch: 5300, acc: 0.57, loss:0.8825060129165649, lr:0.15875535799333226\n",
            "epoch: 5400, acc: 0.58, loss:0.8798065185546875, lr:0.1562744178777934\n",
            "epoch: 5500, acc: 0.5866666666666667, loss:0.876708984375, lr:0.15386982612709646\n",
            "epoch: 5600, acc: 0.59, loss:0.8754709959030151, lr:0.15153811183512653\n",
            "epoch: 5700, acc: 0.5933333333333334, loss:0.8722601532936096, lr:0.14927601134497687\n",
            "epoch: 5800, acc: 0.59, loss:0.8692604303359985, lr:0.14708045300779526\n",
            "epoch: 5900, acc: 0.59, loss:0.8657904267311096, lr:0.14494854326714016\n",
            "epoch: 6000, acc: 0.5866666666666667, loss:0.8626292943954468, lr:0.1428775539362766\n",
            "epoch: 6100, acc: 0.5833333333333334, loss:0.8590361475944519, lr:0.1408649105507818\n",
            "epoch: 6200, acc: 0.5833333333333334, loss:0.8560277223587036, lr:0.13890818169190167\n",
            "epoch: 6300, acc: 0.58, loss:0.852372944355011, lr:0.13700506918755992\n",
            "epoch: 6400, acc: 0.5766666666666667, loss:0.8499178290367126, lr:0.13515339910798757\n",
            "epoch: 6500, acc: 0.5833333333333334, loss:0.8468402028083801, lr:0.13335111348179757\n",
            "epoch: 6600, acc: 0.59, loss:0.843994140625, lr:0.13159626266614027\n",
            "epoch: 6700, acc: 0.59, loss:0.8438836932182312, lr:0.12988699831146902\n",
            "epoch: 6800, acc: 0.59, loss:0.8419830799102783, lr:0.12822156686754713\n",
            "epoch: 6900, acc: 0.5933333333333334, loss:0.838492751121521, lr:0.126598303582732\n",
            "epoch: 7000, acc: 0.5933333333333334, loss:0.8356691598892212, lr:0.12501562695336915\n",
            "epoch: 7100, acc: 0.5966666666666667, loss:0.8317149877548218, lr:0.12347203358439313\n",
            "epoch: 7200, acc: 0.6, loss:0.829009473323822, lr:0.12196609342602757\n",
            "epoch: 7300, acc: 0.6, loss:0.825796902179718, lr:0.12049644535486204\n",
            "epoch: 7400, acc: 0.6033333333333334, loss:0.8230707049369812, lr:0.11906179307060363\n",
            "epoch: 7500, acc: 0.6066666666666667, loss:0.8197982311248779, lr:0.11766090128250381\n",
            "epoch: 7600, acc: 0.6033333333333334, loss:0.8173811435699463, lr:0.11629259216187929\n",
            "epoch: 7700, acc: 0.6, loss:0.8143560290336609, lr:0.11495574203931487\n",
            "epoch: 7800, acc: 0.5933333333333334, loss:0.8116163611412048, lr:0.11364927832708263\n",
            "epoch: 7900, acc: 0.5933333333333334, loss:0.8091781139373779, lr:0.11237217664906168\n",
            "epoch: 8000, acc: 0.5933333333333334, loss:0.8062868118286133, lr:0.11112345816201799\n",
            "epoch: 8100, acc: 0.6, loss:0.8034483790397644, lr:0.10990218705352237\n",
            "epoch: 8200, acc: 0.6, loss:0.8003649115562439, lr:0.10870746820306555\n",
            "epoch: 8300, acc: 0.6066666666666667, loss:0.7973328232765198, lr:0.1075384449940854\n",
            "epoch: 8400, acc: 0.6033333333333334, loss:0.7952946424484253, lr:0.10639429726566654\n",
            "epoch: 8500, acc: 0.5966666666666667, loss:0.7927553653717041, lr:0.10527423939362038\n",
            "epoch: 8600, acc: 0.6066666666666667, loss:0.7902684211730957, lr:0.10417751849150952\n",
            "epoch: 8700, acc: 0.62, loss:0.7878957986831665, lr:0.10310341272296113\n",
            "epoch: 8800, acc: 0.6233333333333333, loss:0.7859294414520264, lr:0.1020512297173181\n",
            "epoch: 8900, acc: 0.62, loss:0.7845796942710876, lr:0.10102030508132134\n",
            "epoch: 9000, acc: 0.6333333333333333, loss:0.7820120453834534, lr:0.1000100010001\n",
            "epoch: 9100, acc: 0.6333333333333333, loss:0.7794587016105652, lr:0.09901970492127933\n",
            "epoch: 9200, acc: 0.63, loss:0.777688205242157, lr:0.09804882831650162\n",
            "epoch: 9300, acc: 0.6366666666666667, loss:0.7751132249832153, lr:0.09709680551509856\n",
            "epoch: 9400, acc: 0.64, loss:0.772569477558136, lr:0.09616309260505818\n",
            "epoch: 9500, acc: 0.6366666666666667, loss:0.7725750803947449, lr:0.09524716639679968\n",
            "epoch: 9600, acc: 0.6366666666666667, loss:0.7712997198104858, lr:0.09434852344560807\n",
            "epoch: 9700, acc: 0.6433333333333333, loss:0.7677462100982666, lr:0.09346667912889055\n",
            "epoch: 9800, acc: 0.6433333333333333, loss:0.7657479047775269, lr:0.09260116677470137\n",
            "epoch: 9900, acc: 0.6466666666666666, loss:0.7632008194923401, lr:0.09175153683824203\n",
            "epoch: 10000, acc: 0.6466666666666666, loss:0.7612416744232178, lr:0.09091735612328393\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Uw9UwNdMN8Il",
        "outputId": "4ff65f06-a614-45a6-db36-620c1a1c5428"
      },
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "\n",
        "# Create dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n",
        "\n",
        "# Create Dense layer with 2 input features and 3 output values\n",
        "dense1 = Layer_Dense(2, 64)\n",
        "\n",
        "# Create ReLU activation (to be used with Dense layer):\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "# Create second Dense layer with 3 input features (as we take output\n",
        "# of previous layer here) and 3 output values (output values)\n",
        "dense2 = Layer_Dense(64, 3)\n",
        "\n",
        "# Create Softmax classifier's combined loss and activation\n",
        "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
        "\n",
        "optimizer = Optimizer_SGD(learning_rate = 0.9, decay = 1e-3)\n",
        "\n",
        "#train in loop \n",
        "losses = []\n",
        "for epoch in range(10001):\n",
        "\n",
        "  #forward passes \n",
        "  dense1.forward(X)\n",
        "  activation1.forward(dense1.output)\n",
        "  dense2.forward(activation1.output)\n",
        "  loss = loss_activation.forward(dense2.output, y)\n",
        "  losses.append(loss)\n",
        "  # calcualte accuracy \n",
        "  predictions = np.argmax(loss_activation.output, axis = 1)\n",
        "  if len(y.shape) == 2:\n",
        "    y = np.argmax(y, axis = 1)\n",
        "  \n",
        "  accuracy = np.mean(predictions == y)\n",
        "\n",
        "  if not epoch % 100:\n",
        "    print(f'epoch: {epoch}, acc: {accuracy}, loss:{loss}, lr:{optimizer.current_learning_rate}' )\n",
        "\n",
        "  # backward pass \n",
        "  loss_activation.backward(loss_activation.output, y)\n",
        "  dense2.backward(loss_activation.dinputs)\n",
        "  activation1.backward(dense2.dinputs)\n",
        "  dense1.backward(activation1.dinputs)\n",
        "\n",
        "  #update params \n",
        "  optimizer.pre_update_params()\n",
        "  optimizer.update_params(dense1)\n",
        "  optimizer.update_params(dense2)\n",
        "  optimizer.post_update_params()\n",
        "\n",
        "plt.plot(range(len(losses)), losses)\n",
        "plt.title('Loss vs steps')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, acc: 0.36, loss:1.098594307899475, lr:0.9\n",
            "epoch: 100, acc: 0.4033333333333333, loss:1.0908864736557007, lr:0.8189262966333031\n",
            "epoch: 200, acc: 0.41, loss:1.0783594846725464, lr:0.7506255212677231\n",
            "epoch: 300, acc: 0.42, loss:1.0767338275909424, lr:0.6928406466512702\n",
            "epoch: 400, acc: 0.42, loss:1.0759800672531128, lr:0.6433166547533953\n",
            "epoch: 500, acc: 0.4066666666666667, loss:1.0750079154968262, lr:0.600400266844563\n",
            "epoch: 600, acc: 0.4, loss:1.0736521482467651, lr:0.5628517823639775\n",
            "epoch: 700, acc: 0.39666666666666667, loss:1.0720690488815308, lr:0.5297233666862861\n",
            "epoch: 800, acc: 0.4, loss:1.070396900177002, lr:0.500277932184547\n",
            "epoch: 900, acc: 0.41333333333333333, loss:1.068556547164917, lr:0.47393364928909953\n",
            "epoch: 1000, acc: 0.42333333333333334, loss:1.066581130027771, lr:0.45022511255627806\n",
            "epoch: 1100, acc: 0.44, loss:1.0645484924316406, lr:0.4287756074321105\n",
            "epoch: 1200, acc: 0.43333333333333335, loss:1.061824083328247, lr:0.4092769440654843\n",
            "epoch: 1300, acc: 0.43666666666666665, loss:1.0587058067321777, lr:0.39147455415397997\n",
            "epoch: 1400, acc: 0.44, loss:1.0556507110595703, lr:0.3751563151313047\n",
            "epoch: 1500, acc: 0.44, loss:1.0524868965148926, lr:0.3601440576230492\n",
            "epoch: 1600, acc: 0.42333333333333334, loss:1.0488972663879395, lr:0.3462870334744132\n",
            "epoch: 1700, acc: 0.4033333333333333, loss:1.0430479049682617, lr:0.33345683586513525\n",
            "epoch: 1800, acc: 0.42, loss:1.0370370149612427, lr:0.3215434083601286\n",
            "epoch: 1900, acc: 0.41333333333333333, loss:1.0306079387664795, lr:0.31045187995860646\n",
            "epoch: 2000, acc: 0.44333333333333336, loss:1.0244674682617188, lr:0.3001000333444481\n",
            "epoch: 2100, acc: 0.45666666666666667, loss:1.0180448293685913, lr:0.29041626331074544\n",
            "epoch: 2200, acc: 0.4666666666666667, loss:1.0111427307128906, lr:0.28133791809940606\n",
            "epoch: 2300, acc: 0.4766666666666667, loss:1.0035938024520874, lr:0.27280994240678996\n",
            "epoch: 2400, acc: 0.4866666666666667, loss:0.9961222410202026, lr:0.264783759929391\n",
            "epoch: 2500, acc: 0.5066666666666667, loss:0.9883489012718201, lr:0.2572163475278651\n",
            "epoch: 2600, acc: 0.52, loss:0.9803270697593689, lr:0.2500694637399277\n",
            "epoch: 2700, acc: 0.5333333333333333, loss:0.9721183180809021, lr:0.24330900243309003\n",
            "epoch: 2800, acc: 0.54, loss:0.9642433524131775, lr:0.23690444853908924\n",
            "epoch: 2900, acc: 0.5266666666666666, loss:0.9721681475639343, lr:0.2308284175429597\n",
            "epoch: 3000, acc: 0.5266666666666666, loss:0.9816446900367737, lr:0.22505626406601653\n",
            "epoch: 3100, acc: 0.5233333333333333, loss:0.982272207736969, lr:0.21956574774335202\n",
            "epoch: 3200, acc: 0.5133333333333333, loss:0.9802941679954529, lr:0.21433674684448678\n",
            "epoch: 3300, acc: 0.5133333333333333, loss:0.9753499627113342, lr:0.20935101186322402\n",
            "epoch: 3400, acc: 0.5133333333333333, loss:0.9709715843200684, lr:0.2045919527165265\n",
            "epoch: 3500, acc: 0.5166666666666667, loss:0.9691104292869568, lr:0.2000444543231829\n",
            "epoch: 3600, acc: 0.52, loss:0.9643534421920776, lr:0.19569471624266144\n",
            "epoch: 3700, acc: 0.5266666666666666, loss:0.9589905738830566, lr:0.1915301127899553\n",
            "epoch: 3800, acc: 0.5266666666666666, loss:0.9547461867332458, lr:0.18753907063971662\n",
            "epoch: 3900, acc: 0.5266666666666666, loss:0.9501391649246216, lr:0.18371096142069812\n",
            "epoch: 4000, acc: 0.5533333333333333, loss:0.944556474685669, lr:0.18003600720144028\n",
            "epoch: 4100, acc: 0.5566666666666666, loss:0.9408277273178101, lr:0.1765051970974701\n",
            "epoch: 4200, acc: 0.5566666666666666, loss:0.9361344575881958, lr:0.17311021350259667\n",
            "epoch: 4300, acc: 0.5533333333333333, loss:0.9305354952812195, lr:0.16984336667295713\n",
            "epoch: 4400, acc: 0.5566666666666666, loss:0.9244834184646606, lr:0.1666975365808483\n",
            "epoch: 4500, acc: 0.57, loss:0.9195552468299866, lr:0.16366612111292964\n",
            "epoch: 4600, acc: 0.5766666666666667, loss:0.9146866798400879, lr:0.16074298981961066\n",
            "epoch: 4700, acc: 0.58, loss:0.9090193510055542, lr:0.15792244253377785\n",
            "epoch: 4800, acc: 0.58, loss:0.9042315483093262, lr:0.1551991722710812\n",
            "epoch: 4900, acc: 0.59, loss:0.8984189033508301, lr:0.1525682319037125\n",
            "epoch: 5000, acc: 0.59, loss:0.8914826512336731, lr:0.15002500416736125\n",
            "epoch: 5100, acc: 0.6, loss:0.8875898122787476, lr:0.14756517461878996\n",
            "epoch: 5200, acc: 0.6, loss:0.8835523724555969, lr:0.14518470721084045\n",
            "epoch: 5300, acc: 0.61, loss:0.880218505859375, lr:0.14287982219399903\n",
            "epoch: 5400, acc: 0.6033333333333334, loss:0.8742620944976807, lr:0.14064697609001406\n",
            "epoch: 5500, acc: 0.62, loss:0.8705706596374512, lr:0.1384828435143868\n",
            "epoch: 5600, acc: 0.62, loss:0.8626813888549805, lr:0.1363843006516139\n",
            "epoch: 5700, acc: 0.62, loss:0.8595470190048218, lr:0.1343484102104792\n",
            "epoch: 5800, acc: 0.6233333333333333, loss:0.8568951487541199, lr:0.13237240770701575\n",
            "epoch: 5900, acc: 0.6233333333333333, loss:0.855272114276886, lr:0.13045368894042614\n",
            "epoch: 6000, acc: 0.6333333333333333, loss:0.852644145488739, lr:0.12858979854264896\n",
            "epoch: 6100, acc: 0.6366666666666667, loss:0.849540114402771, lr:0.12677841949570362\n",
            "epoch: 6200, acc: 0.6433333333333333, loss:0.8470592498779297, lr:0.1250173635227115\n",
            "epoch: 6300, acc: 0.64, loss:0.8446479439735413, lr:0.12330456226880393\n",
            "epoch: 6400, acc: 0.6466666666666666, loss:0.8407024145126343, lr:0.12163805919718881\n",
            "epoch: 6500, acc: 0.6466666666666666, loss:0.8371514081954956, lr:0.12001600213361781\n",
            "epoch: 6600, acc: 0.65, loss:0.8331452012062073, lr:0.11843663639952624\n",
            "epoch: 6700, acc: 0.6633333333333333, loss:0.8294439911842346, lr:0.11689829848032213\n",
            "epoch: 6800, acc: 0.67, loss:0.8256804347038269, lr:0.11539941018079242\n",
            "epoch: 6900, acc: 0.6666666666666666, loss:0.8220816254615784, lr:0.1139384732244588\n",
            "epoch: 7000, acc: 0.6666666666666666, loss:0.8195241093635559, lr:0.11251406425803225\n",
            "epoch: 7100, acc: 0.6666666666666666, loss:0.8168964385986328, lr:0.11112483022595382\n",
            "epoch: 7200, acc: 0.66, loss:0.8125894069671631, lr:0.10976948408342482\n",
            "epoch: 7300, acc: 0.66, loss:0.8100716471672058, lr:0.10844680081937584\n",
            "epoch: 7400, acc: 0.6666666666666666, loss:0.806832492351532, lr:0.10715561376354327\n",
            "epoch: 7500, acc: 0.66, loss:0.8043791651725769, lr:0.10589481115425343\n",
            "epoch: 7600, acc: 0.6633333333333333, loss:0.8022889494895935, lr:0.10466333294569136\n",
            "epoch: 7700, acc: 0.67, loss:0.7999650835990906, lr:0.10346016783538338\n",
            "epoch: 7800, acc: 0.67, loss:0.7967278957366943, lr:0.10228435049437437\n",
            "epoch: 7900, acc: 0.6666666666666666, loss:0.7949321269989014, lr:0.10113495898415552\n",
            "epoch: 8000, acc: 0.6666666666666666, loss:0.7936319708824158, lr:0.1000111123458162\n",
            "epoch: 8100, acc: 0.66, loss:0.7914961576461792, lr:0.09891196834817013\n",
            "epoch: 8200, acc: 0.6566666666666666, loss:0.7888838648796082, lr:0.09783672138275899\n",
            "epoch: 8300, acc: 0.6533333333333333, loss:0.7871407866477966, lr:0.09678460049467685\n",
            "epoch: 8400, acc: 0.6633333333333333, loss:0.7864149212837219, lr:0.0957548675390999\n",
            "epoch: 8500, acc: 0.66, loss:0.7837116718292236, lr:0.09474681545425834\n",
            "epoch: 8600, acc: 0.66, loss:0.7820512056350708, lr:0.09375976664235858\n",
            "epoch: 8700, acc: 0.65, loss:0.780517578125, lr:0.09279307145066501\n",
            "epoch: 8800, acc: 0.66, loss:0.7791102528572083, lr:0.0918461067455863\n",
            "epoch: 8900, acc: 0.6633333333333333, loss:0.7778030633926392, lr:0.09091827457318921\n",
            "epoch: 9000, acc: 0.6633333333333333, loss:0.7764581441879272, lr:0.09000900090009001\n",
            "epoch: 9100, acc: 0.6633333333333333, loss:0.7752015590667725, lr:0.0891177344291514\n",
            "epoch: 9200, acc: 0.6633333333333333, loss:0.7740125060081482, lr:0.08824394548485145\n",
            "epoch: 9300, acc: 0.6633333333333333, loss:0.7728772759437561, lr:0.0873871249635887\n",
            "epoch: 9400, acc: 0.66, loss:0.771757960319519, lr:0.08654678334455236\n",
            "epoch: 9500, acc: 0.6633333333333333, loss:0.7706199288368225, lr:0.08572244975711972\n",
            "epoch: 9600, acc: 0.6666666666666666, loss:0.7695419192314148, lr:0.08491367110104726\n",
            "epoch: 9700, acc: 0.6666666666666666, loss:0.7683978080749512, lr:0.08412001121600149\n",
            "epoch: 9800, acc: 0.6666666666666666, loss:0.7672532200813293, lr:0.08334105009723124\n",
            "epoch: 9900, acc: 0.6666666666666666, loss:0.7661957740783691, lr:0.08257638315441783\n",
            "epoch: 10000, acc: 0.6666666666666666, loss:0.7651330828666687, lr:0.08182562051095554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEx4hZ_l8XnG"
      },
      "source": [
        "# SGD optimizer\n",
        "class Optimizer_SGD:\n",
        "\n",
        "    # Initialize optimizer - set settings,\n",
        "    # learning rate of 1. is default for this optimizer\n",
        "    def __init__(self, learning_rate=1., decay=0., momentum=0.):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.momentum = momentum\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If we use momentum\n",
        "        if self.momentum:\n",
        "\n",
        "            # If layer does not contain momentum arrays, create them\n",
        "            # filled with zeros\n",
        "            if not hasattr(layer, 'weight_momentums'):\n",
        "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
        "                # If there is no momentum array for weights\n",
        "                # The array doesn't exist for biases yet either.\n",
        "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
        "\n",
        "            # Build weight updates with momentum - take previous\n",
        "            # updates multiplied by retain factor and update with\n",
        "            # current gradients\n",
        "            weight_updates = \\\n",
        "                self.momentum * layer.weight_momentums - \\\n",
        "                self.current_learning_rate * layer.dweights\n",
        "            layer.weight_momentums = weight_updates\n",
        "\n",
        "            # Build bias updates\n",
        "            bias_updates = \\\n",
        "                self.momentum * layer.bias_momentums - \\\n",
        "                self.current_learning_rate * layer.dbiases\n",
        "            layer.bias_momentums = bias_updates\n",
        "\n",
        "        # Vanilla SGD updates (as before momentum update)\n",
        "        else:\n",
        "            weight_updates = -self.current_learning_rate * \\\n",
        "                             layer.dweights\n",
        "            bias_updates = -self.current_learning_rate * \\\n",
        "                           layer.dbiases\n",
        "\n",
        "        # Update weights and biases using either\n",
        "        # vanilla or momentum updates\n",
        "        layer.weights += weight_updates\n",
        "        layer.biases += bias_updates\n",
        "\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "77Mn4VOiCdpP",
        "outputId": "3e225733-8247-42cc-9a3e-2257dce246e1"
      },
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "\n",
        "# Create dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n",
        "\n",
        "# Create Dense layer with 2 input features and 3 output values\n",
        "dense1 = Layer_Dense(2, 64)\n",
        "\n",
        "# Create ReLU activation (to be used with Dense layer):\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "# Create second Dense layer with 3 input features (as we take output\n",
        "# of previous layer here) and 3 output values (output values)\n",
        "dense2 = Layer_Dense(64, 3)\n",
        "\n",
        "# Create Softmax classifier's combined loss and activation\n",
        "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
        "\n",
        "optimizer = Optimizer_SGD(decay = 1e-3, momentum  =0.5)\n",
        "\n",
        "#train in loop \n",
        "losses = []\n",
        "for epoch in range(25000):\n",
        "\n",
        "  #forward passes \n",
        "  dense1.forward(X)\n",
        "  activation1.forward(dense1.output)\n",
        "  dense2.forward(activation1.output)\n",
        "  loss = loss_activation.forward(dense2.output, y)\n",
        "  losses.append(loss)\n",
        "  # calcualte accuracy \n",
        "  predictions = np.argmax(loss_activation.output, axis = 1)\n",
        "  if len(y.shape) == 2:\n",
        "    y = np.argmax(y, axis = 1)\n",
        "  \n",
        "  accuracy = np.mean(predictions == y)\n",
        "\n",
        "  if not epoch % 100:\n",
        "    print(f'epoch: {epoch}, acc: {accuracy}, loss:{loss}, lr:{optimizer.current_learning_rate}' )\n",
        "\n",
        "  # backward pass \n",
        "  loss_activation.backward(loss_activation.output, y)\n",
        "  dense2.backward(loss_activation.dinputs)\n",
        "  activation1.backward(dense2.dinputs)\n",
        "  dense1.backward(activation1.dinputs)\n",
        "\n",
        "  #update params \n",
        "  optimizer.pre_update_params()\n",
        "  optimizer.update_params(dense1)\n",
        "  optimizer.update_params(dense2)\n",
        "  optimizer.post_update_params()\n",
        "\n",
        "plt.plot(range(len(losses)), losses)\n",
        "plt.title('Loss vs steps')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, acc: 0.36, loss:1.098594307899475, lr:1.0\n",
            "epoch: 100, acc: 0.4266666666666667, loss:1.0776474475860596, lr:0.9099181073703367\n",
            "epoch: 200, acc: 0.42, loss:1.0752781629562378, lr:0.8340283569641367\n",
            "epoch: 300, acc: 0.4066666666666667, loss:1.0710084438323975, lr:0.7698229407236336\n",
            "epoch: 400, acc: 0.42, loss:1.0651527643203735, lr:0.7147962830593281\n",
            "epoch: 500, acc: 0.45, loss:1.0558302402496338, lr:0.66711140760507\n",
            "epoch: 600, acc: 0.44666666666666666, loss:1.0429142713546753, lr:0.6253908692933083\n",
            "epoch: 700, acc: 0.44333333333333336, loss:1.0206767320632935, lr:0.5885815185403178\n",
            "epoch: 800, acc: 0.44666666666666666, loss:1.0313973426818848, lr:0.5558643690939411\n",
            "epoch: 900, acc: 0.47333333333333333, loss:1.020171880722046, lr:0.526592943654555\n",
            "epoch: 1000, acc: 0.49333333333333335, loss:1.0180854797363281, lr:0.5002501250625312\n",
            "epoch: 1100, acc: 0.49333333333333335, loss:1.0113260746002197, lr:0.4764173415912339\n",
            "epoch: 1200, acc: 0.49666666666666665, loss:1.0063916444778442, lr:0.45475216007276037\n",
            "epoch: 1300, acc: 0.5033333333333333, loss:0.9850419163703918, lr:0.43497172683775553\n",
            "epoch: 1400, acc: 0.48, loss:0.9752609133720398, lr:0.4168403501458941\n",
            "epoch: 1500, acc: 0.5166666666666667, loss:1.0067600011825562, lr:0.4001600640256102\n",
            "epoch: 1600, acc: 0.53, loss:0.9979339838027954, lr:0.3847633705271258\n",
            "epoch: 1700, acc: 0.53, loss:0.9758486151695251, lr:0.3705075954057058\n",
            "epoch: 1800, acc: 0.5466666666666666, loss:0.9722157716751099, lr:0.35727045373347627\n",
            "epoch: 1900, acc: 0.5433333333333333, loss:0.96370929479599, lr:0.3449465332873405\n",
            "epoch: 2000, acc: 0.5466666666666666, loss:0.9794057011604309, lr:0.33344448149383127\n",
            "epoch: 2100, acc: 0.55, loss:0.9934732913970947, lr:0.32268473701193934\n",
            "epoch: 2200, acc: 0.5433333333333333, loss:0.933728039264679, lr:0.31259768677711786\n",
            "epoch: 2300, acc: 0.55, loss:0.9930039644241333, lr:0.3031221582297666\n",
            "epoch: 2400, acc: 0.54, loss:0.9242481589317322, lr:0.29420417769932333\n",
            "epoch: 2500, acc: 0.5633333333333334, loss:0.9551560282707214, lr:0.2857959416976279\n",
            "epoch: 2600, acc: 0.5633333333333334, loss:0.9338002800941467, lr:0.2778549597110308\n",
            "epoch: 2700, acc: 0.5766666666666667, loss:0.9225409030914307, lr:0.2703433360367667\n",
            "epoch: 2800, acc: 0.5766666666666667, loss:0.9188584685325623, lr:0.26322716504343247\n",
            "epoch: 2900, acc: 0.5733333333333334, loss:0.922747015953064, lr:0.25647601949217746\n",
            "epoch: 3000, acc: 0.5766666666666667, loss:0.8813536763191223, lr:0.25006251562890724\n",
            "epoch: 3100, acc: 0.5833333333333334, loss:0.8849719166755676, lr:0.2439619419370578\n",
            "epoch: 3200, acc: 0.62, loss:0.8566021919250488, lr:0.23815194093831865\n",
            "epoch: 3300, acc: 0.6033333333333334, loss:0.8684444427490234, lr:0.23261223540358225\n",
            "epoch: 3400, acc: 0.5833333333333334, loss:0.8812788724899292, lr:0.22732439190725165\n",
            "epoch: 3500, acc: 0.5966666666666667, loss:0.8631296753883362, lr:0.22227161591464767\n",
            "epoch: 3600, acc: 0.6133333333333333, loss:0.8459405303001404, lr:0.21743857360295715\n",
            "epoch: 3700, acc: 0.64, loss:0.8198301196098328, lr:0.21281123643328367\n",
            "epoch: 3800, acc: 0.6233333333333333, loss:0.8243356347084045, lr:0.20837674515524068\n",
            "epoch: 3900, acc: 0.6066666666666667, loss:0.8430351614952087, lr:0.20412329046744235\n",
            "epoch: 4000, acc: 0.6233333333333333, loss:0.8102720379829407, lr:0.2000400080016003\n",
            "epoch: 4100, acc: 0.6233333333333333, loss:0.834318995475769, lr:0.19611688566385566\n",
            "epoch: 4200, acc: 0.63, loss:0.8013365864753723, lr:0.19234468166955185\n",
            "epoch: 4300, acc: 0.6433333333333333, loss:0.7840418815612793, lr:0.18871485185884126\n",
            "epoch: 4400, acc: 0.6633333333333333, loss:0.7751749753952026, lr:0.18521948508983144\n",
            "epoch: 4500, acc: 0.6466666666666666, loss:0.7789967060089111, lr:0.18185124568103292\n",
            "epoch: 4600, acc: 0.6533333333333333, loss:0.7658028602600098, lr:0.1786033220217896\n",
            "epoch: 4700, acc: 0.6633333333333333, loss:0.7508143186569214, lr:0.1754693805930865\n",
            "epoch: 4800, acc: 0.6533333333333333, loss:0.7519492506980896, lr:0.17244352474564578\n",
            "epoch: 4900, acc: 0.6466666666666666, loss:0.7650014758110046, lr:0.16952025767079165\n",
            "epoch: 5000, acc: 0.66, loss:0.744621217250824, lr:0.16669444907484582\n",
            "epoch: 5100, acc: 0.6666666666666666, loss:0.7340646386146545, lr:0.16396130513198884\n",
            "epoch: 5200, acc: 0.6833333333333333, loss:0.7340014576911926, lr:0.16131634134537828\n",
            "epoch: 5300, acc: 0.7066666666666667, loss:0.7236548066139221, lr:0.15875535799333226\n",
            "epoch: 5400, acc: 0.6533333333333333, loss:0.730890154838562, lr:0.1562744178777934\n",
            "epoch: 5500, acc: 0.6666666666666666, loss:0.7310124039649963, lr:0.15386982612709646\n",
            "epoch: 5600, acc: 0.6666666666666666, loss:0.7136136889457703, lr:0.15153811183512653\n",
            "epoch: 5700, acc: 0.7, loss:0.6960659623146057, lr:0.14927601134497687\n",
            "epoch: 5800, acc: 0.67, loss:0.7163270115852356, lr:0.14708045300779526\n",
            "epoch: 5900, acc: 0.68, loss:0.6965180039405823, lr:0.14494854326714016\n",
            "epoch: 6000, acc: 0.7033333333333334, loss:0.6779309511184692, lr:0.1428775539362766\n",
            "epoch: 6100, acc: 0.6766666666666666, loss:0.6869231462478638, lr:0.1408649105507818\n",
            "epoch: 6200, acc: 0.6966666666666667, loss:0.6736894845962524, lr:0.13890818169190167\n",
            "epoch: 6300, acc: 0.69, loss:0.6747503280639648, lr:0.13700506918755992\n",
            "epoch: 6400, acc: 0.69, loss:0.6667998433113098, lr:0.13515339910798757\n",
            "epoch: 6500, acc: 0.6933333333333334, loss:0.6629419922828674, lr:0.13335111348179757\n",
            "epoch: 6600, acc: 0.68, loss:0.6725524663925171, lr:0.13159626266614027\n",
            "epoch: 6700, acc: 0.6933333333333334, loss:0.6562133431434631, lr:0.12988699831146902\n",
            "epoch: 6800, acc: 0.71, loss:0.6477257013320923, lr:0.12822156686754713\n",
            "epoch: 6900, acc: 0.72, loss:0.6404823064804077, lr:0.126598303582732\n",
            "epoch: 7000, acc: 0.7066666666666667, loss:0.6420261859893799, lr:0.12501562695336915\n",
            "epoch: 7100, acc: 0.7166666666666667, loss:0.6355139017105103, lr:0.12347203358439313\n",
            "epoch: 7200, acc: 0.7266666666666667, loss:0.6326407790184021, lr:0.12196609342602757\n",
            "epoch: 7300, acc: 0.73, loss:0.6264051198959351, lr:0.12049644535486204\n",
            "epoch: 7400, acc: 0.73, loss:0.6222986578941345, lr:0.11906179307060363\n",
            "epoch: 7500, acc: 0.7333333333333333, loss:0.619855523109436, lr:0.11766090128250381\n",
            "epoch: 7600, acc: 0.74, loss:0.6158869862556458, lr:0.11629259216187929\n",
            "epoch: 7700, acc: 0.7433333333333333, loss:0.6126937866210938, lr:0.11495574203931487\n",
            "epoch: 7800, acc: 0.7433333333333333, loss:0.609584391117096, lr:0.11364927832708263\n",
            "epoch: 7900, acc: 0.7433333333333333, loss:0.605916440486908, lr:0.11237217664906168\n",
            "epoch: 8000, acc: 0.7433333333333333, loss:0.6025527119636536, lr:0.11112345816201799\n",
            "epoch: 8100, acc: 0.7433333333333333, loss:0.6003170013427734, lr:0.10990218705352237\n",
            "epoch: 8200, acc: 0.7466666666666667, loss:0.596989095211029, lr:0.10870746820306555\n",
            "epoch: 8300, acc: 0.75, loss:0.5952409505844116, lr:0.1075384449940854\n",
            "epoch: 8400, acc: 0.7566666666666667, loss:0.5929646492004395, lr:0.10639429726566654\n",
            "epoch: 8500, acc: 0.7566666666666667, loss:0.5908587574958801, lr:0.10527423939362038\n",
            "epoch: 8600, acc: 0.76, loss:0.5888590216636658, lr:0.10417751849150952\n",
            "epoch: 8700, acc: 0.76, loss:0.5864834785461426, lr:0.10310341272296113\n",
            "epoch: 8800, acc: 0.7633333333333333, loss:0.5839033126831055, lr:0.1020512297173181\n",
            "epoch: 8900, acc: 0.7666666666666667, loss:0.581125795841217, lr:0.10102030508132134\n",
            "epoch: 9000, acc: 0.7633333333333333, loss:0.5779078006744385, lr:0.1000100010001\n",
            "epoch: 9100, acc: 0.7666666666666667, loss:0.5743922591209412, lr:0.09901970492127933\n",
            "epoch: 9200, acc: 0.77, loss:0.5725800395011902, lr:0.09804882831650162\n",
            "epoch: 9300, acc: 0.77, loss:0.5687853097915649, lr:0.09709680551509856\n",
            "epoch: 9400, acc: 0.7733333333333333, loss:0.5665604472160339, lr:0.09616309260505818\n",
            "epoch: 9500, acc: 0.7733333333333333, loss:0.5638228058815002, lr:0.09524716639679968\n",
            "epoch: 9600, acc: 0.7766666666666666, loss:0.5615196824073792, lr:0.09434852344560807\n",
            "epoch: 9700, acc: 0.7833333333333333, loss:0.558870255947113, lr:0.09346667912889055\n",
            "epoch: 9800, acc: 0.7833333333333333, loss:0.5572448968887329, lr:0.09260116677470137\n",
            "epoch: 9900, acc: 0.78, loss:0.5553344488143921, lr:0.09175153683824203\n",
            "epoch: 10000, acc: 0.78, loss:0.5530889630317688, lr:0.09091735612328393\n",
            "epoch: 10100, acc: 0.7866666666666666, loss:0.5505742430686951, lr:0.09009820704567979\n",
            "epoch: 10200, acc: 0.79, loss:0.5483107566833496, lr:0.0892936869363336\n",
            "epoch: 10300, acc: 0.79, loss:0.5464475750923157, lr:0.08850340738118417\n",
            "epoch: 10400, acc: 0.7933333333333333, loss:0.5442036390304565, lr:0.08772699359592946\n",
            "epoch: 10500, acc: 0.79, loss:0.5425392985343933, lr:0.08696408383337681\n",
            "epoch: 10600, acc: 0.7933333333333333, loss:0.5407847166061401, lr:0.08621432882145012\n",
            "epoch: 10700, acc: 0.7966666666666666, loss:0.5391027331352234, lr:0.08547739123001966\n",
            "epoch: 10800, acc: 0.7966666666666666, loss:0.5374584197998047, lr:0.08475294516484448\n",
            "epoch: 10900, acc: 0.8, loss:0.5360448956489563, lr:0.08404067568703252\n",
            "epoch: 11000, acc: 0.8066666666666666, loss:0.5340299606323242, lr:0.08334027835652971\n",
            "epoch: 11100, acc: 0.8066666666666666, loss:0.5326242446899414, lr:0.08265145879824778\n",
            "epoch: 11200, acc: 0.8066666666666666, loss:0.5312359929084778, lr:0.08197393228953193\n",
            "epoch: 11300, acc: 0.8066666666666666, loss:0.529880166053772, lr:0.08130742336775348\n",
            "epoch: 11400, acc: 0.8066666666666666, loss:0.5282825827598572, lr:0.08065166545689167\n",
            "epoch: 11500, acc: 0.81, loss:0.5270739793777466, lr:0.08000640051204096\n",
            "epoch: 11600, acc: 0.8066666666666666, loss:0.5255780220031738, lr:0.07937137868084769\n",
            "epoch: 11700, acc: 0.8066666666666666, loss:0.5242288112640381, lr:0.07874635798094339\n",
            "epoch: 11800, acc: 0.8066666666666666, loss:0.5228837132453918, lr:0.07813110399249942\n",
            "epoch: 11900, acc: 0.8066666666666666, loss:0.5216185450553894, lr:0.07752538956508256\n",
            "epoch: 12000, acc: 0.8066666666666666, loss:0.5203602910041809, lr:0.07692899453804139\n",
            "epoch: 12100, acc: 0.8066666666666666, loss:0.5193865299224854, lr:0.07634170547370028\n",
            "epoch: 12200, acc: 0.81, loss:0.5179125666618347, lr:0.07576331540268202\n",
            "epoch: 12300, acc: 0.81, loss:0.5167858600616455, lr:0.07519362358072036\n",
            "epoch: 12400, acc: 0.81, loss:0.515688955783844, lr:0.07463243525636241\n",
            "epoch: 12500, acc: 0.81, loss:0.5144290924072266, lr:0.07407956144899622\n",
            "epoch: 12600, acc: 0.8066666666666666, loss:0.5135239958763123, lr:0.07353481873667181\n",
            "epoch: 12700, acc: 0.8066666666666666, loss:0.5123708248138428, lr:0.07299802905321556\n",
            "epoch: 12800, acc: 0.8066666666666666, loss:0.5113204717636108, lr:0.07246901949416625\n",
            "epoch: 12900, acc: 0.8066666666666666, loss:0.5103026032447815, lr:0.07194762213108856\n",
            "epoch: 13000, acc: 0.8066666666666666, loss:0.5092885494232178, lr:0.07143367383384527\n",
            "epoch: 13100, acc: 0.8066666666666666, loss:0.5083392262458801, lr:0.07092701610043266\n",
            "epoch: 13200, acc: 0.8066666666666666, loss:0.5073763132095337, lr:0.07042749489400663\n",
            "epoch: 13300, acc: 0.8066666666666666, loss:0.5064617395401001, lr:0.06993496048674733\n",
            "epoch: 13400, acc: 0.8033333333333333, loss:0.5055527687072754, lr:0.06944926731022988\n",
            "epoch: 13500, acc: 0.8066666666666666, loss:0.5045073628425598, lr:0.06897027381198703\n",
            "epoch: 13600, acc: 0.8066666666666666, loss:0.5036851763725281, lr:0.06849784231796699\n",
            "epoch: 13700, acc: 0.8033333333333333, loss:0.5028202533721924, lr:0.06803183890060549\n",
            "epoch: 13800, acc: 0.81, loss:0.5018883943557739, lr:0.06757213325224677\n",
            "epoch: 13900, acc: 0.81, loss:0.5010611414909363, lr:0.06711859856366198\n",
            "epoch: 14000, acc: 0.8133333333333334, loss:0.500216543674469, lr:0.06667111140742715\n",
            "epoch: 14100, acc: 0.8133333333333334, loss:0.49932733178138733, lr:0.0662295516259355\n",
            "epoch: 14200, acc: 0.8133333333333334, loss:0.4985383152961731, lr:0.06579380222383052\n",
            "epoch: 14300, acc: 0.81, loss:0.49772775173187256, lr:0.06536374926465782\n",
            "epoch: 14400, acc: 0.81, loss:0.497005820274353, lr:0.06493928177154361\n",
            "epoch: 14500, acc: 0.81, loss:0.49621835350990295, lr:0.06452029163171817\n",
            "epoch: 14600, acc: 0.8133333333333334, loss:0.49538204073905945, lr:0.06410667350471184\n",
            "epoch: 14700, acc: 0.81, loss:0.49464112520217896, lr:0.0636983247340595\n",
            "epoch: 14800, acc: 0.8133333333333334, loss:0.49393823742866516, lr:0.06329514526235838\n",
            "epoch: 14900, acc: 0.8133333333333334, loss:0.4932352602481842, lr:0.06289703754953141\n",
            "epoch: 15000, acc: 0.8133333333333334, loss:0.49249425530433655, lr:0.06250390649415588\n",
            "epoch: 15100, acc: 0.8133333333333334, loss:0.49172282218933105, lr:0.06211565935772408\n",
            "epoch: 15200, acc: 0.8166666666666667, loss:0.49087849259376526, lr:0.061732205691709376\n",
            "epoch: 15300, acc: 0.8166666666666667, loss:0.49020150303840637, lr:0.061353457267317016\n",
            "epoch: 15400, acc: 0.8166666666666667, loss:0.489587664604187, lr:0.06097932800780535\n",
            "epoch: 15500, acc: 0.8233333333333334, loss:0.48888543248176575, lr:0.060609733923268065\n",
            "epoch: 15600, acc: 0.8233333333333334, loss:0.48823028802871704, lr:0.060244593047773964\n",
            "epoch: 15700, acc: 0.82, loss:0.4876672327518463, lr:0.0598838253787652\n",
            "epoch: 15800, acc: 0.82, loss:0.4870346486568451, lr:0.059527352818620156\n",
            "epoch: 15900, acc: 0.82, loss:0.48630544543266296, lr:0.05917509911829102\n",
            "epoch: 16000, acc: 0.82, loss:0.4856448471546173, lr:0.058826989822930754\n",
            "epoch: 16100, acc: 0.8166666666666667, loss:0.48504170775413513, lr:0.058482952219428036\n",
            "epoch: 16200, acc: 0.8233333333333334, loss:0.4843100905418396, lr:0.05814291528577242\n",
            "epoch: 16300, acc: 0.82, loss:0.4835953414440155, lr:0.05780680964217585\n",
            "epoch: 16400, acc: 0.8166666666666667, loss:0.4830057919025421, lr:0.05747456750387953\n",
            "epoch: 16500, acc: 0.8166666666666667, loss:0.482317715883255, lr:0.05714612263557918\n",
            "epoch: 16600, acc: 0.8233333333333334, loss:0.4817359447479248, lr:0.05682141030740383\n",
            "epoch: 16700, acc: 0.8166666666666667, loss:0.4812141954898834, lr:0.056500367252387135\n",
            "epoch: 16800, acc: 0.8166666666666667, loss:0.4805411696434021, lr:0.05618293162537221\n",
            "epoch: 16900, acc: 0.8133333333333334, loss:0.48002615571022034, lr:0.055869042963294036\n",
            "epoch: 17000, acc: 0.8266666666666667, loss:0.47940683364868164, lr:0.055558642146785936\n",
            "epoch: 17100, acc: 0.82, loss:0.47889211773872375, lr:0.05525167136305873\n",
            "epoch: 17200, acc: 0.8166666666666667, loss:0.47827890515327454, lr:0.05494807407000384\n",
            "epoch: 17300, acc: 0.8133333333333334, loss:0.4772934913635254, lr:0.0546477949614733\n",
            "epoch: 17400, acc: 0.8166666666666667, loss:0.47653746604919434, lr:0.05435077993369205\n",
            "epoch: 17500, acc: 0.8166666666666667, loss:0.47597062587738037, lr:0.05405697605275961\n",
            "epoch: 17600, acc: 0.8133333333333334, loss:0.47539830207824707, lr:0.05376633152320017\n",
            "epoch: 17700, acc: 0.8166666666666667, loss:0.47485047578811646, lr:0.05347879565752179\n",
            "epoch: 17800, acc: 0.8166666666666667, loss:0.4743026793003082, lr:0.05319431884674717\n",
            "epoch: 17900, acc: 0.8133333333333334, loss:0.47369903326034546, lr:0.05291285253187999\n",
            "epoch: 18000, acc: 0.8166666666666667, loss:0.47314900159835815, lr:0.05263434917627244\n",
            "epoch: 18100, acc: 0.8133333333333334, loss:0.4726179540157318, lr:0.05235876223886067\n",
            "epoch: 18200, acc: 0.8166666666666667, loss:0.4721454977989197, lr:0.052086046148236885\n",
            "epoch: 18300, acc: 0.8133333333333334, loss:0.47158971428871155, lr:0.05181615627752734\n",
            "epoch: 18400, acc: 0.8133333333333334, loss:0.4711062014102936, lr:0.05154904892004742\n",
            "epoch: 18500, acc: 0.8133333333333334, loss:0.47067707777023315, lr:0.051284681265705935\n",
            "epoch: 18600, acc: 0.8166666666666667, loss:0.470154732465744, lr:0.05102301137813154\n",
            "epoch: 18700, acc: 0.8133333333333334, loss:0.4696849584579468, lr:0.050763998172496064\n",
            "epoch: 18800, acc: 0.8166666666666667, loss:0.4692173898220062, lr:0.0505076013940098\n",
            "epoch: 18900, acc: 0.8166666666666667, loss:0.46876201033592224, lr:0.05025378159706518\n",
            "epoch: 19000, acc: 0.8166666666666667, loss:0.4683304727077484, lr:0.050002500125006254\n",
            "epoch: 19100, acc: 0.8166666666666667, loss:0.46786630153656006, lr:0.04975371909050202\n",
            "epoch: 19200, acc: 0.82, loss:0.46744823455810547, lr:0.04950740135650279\n",
            "epoch: 19300, acc: 0.82, loss:0.4670180380344391, lr:0.0492635105177595\n",
            "epoch: 19400, acc: 0.8166666666666667, loss:0.4666067361831665, lr:0.049022010882886415\n",
            "epoch: 19500, acc: 0.8166666666666667, loss:0.4661858081817627, lr:0.048782867456949125\n",
            "epoch: 19600, acc: 0.8166666666666667, loss:0.4657536745071411, lr:0.048546045924559446\n",
            "epoch: 19700, acc: 0.8166666666666667, loss:0.46535205841064453, lr:0.04831151263346055\n",
            "epoch: 19800, acc: 0.8166666666666667, loss:0.4649381637573242, lr:0.04807923457858551\n",
            "epoch: 19900, acc: 0.8166666666666667, loss:0.4645389914512634, lr:0.047849179386573515\n",
            "epoch: 20000, acc: 0.8166666666666667, loss:0.4641396999359131, lr:0.047621315300728606\n",
            "epoch: 20100, acc: 0.8166666666666667, loss:0.46376341581344604, lr:0.04739561116640599\n",
            "epoch: 20200, acc: 0.8166666666666667, loss:0.4633561074733734, lr:0.04717203641681211\n",
            "epoch: 20300, acc: 0.8166666666666667, loss:0.46285542845726013, lr:0.04695056105920466\n",
            "epoch: 20400, acc: 0.8166666666666667, loss:0.4621078073978424, lr:0.046731155661479507\n",
            "epoch: 20500, acc: 0.8166666666666667, loss:0.46155455708503723, lr:0.046513791339132055\n",
            "epoch: 20600, acc: 0.8166666666666667, loss:0.46106618642807007, lr:0.046298439742580674\n",
            "epoch: 20700, acc: 0.8166666666666667, loss:0.4606238901615143, lr:0.046085073044840774\n",
            "epoch: 20800, acc: 0.8166666666666667, loss:0.4602004885673523, lr:0.04587366392953805\n",
            "epoch: 20900, acc: 0.82, loss:0.459590345621109, lr:0.04566418557925019\n",
            "epoch: 21000, acc: 0.8166666666666667, loss:0.4588249623775482, lr:0.045456611664166556\n",
            "epoch: 21100, acc: 0.8233333333333334, loss:0.4582810401916504, lr:0.045250916331055706\n",
            "epoch: 21200, acc: 0.8233333333333334, loss:0.45777907967567444, lr:0.04504707419253119\n",
            "epoch: 21300, acc: 0.8233333333333334, loss:0.45733749866485596, lr:0.04484506031660613\n",
            "epoch: 21400, acc: 0.8233333333333334, loss:0.4568959176540375, lr:0.044644850216527525\n",
            "epoch: 21500, acc: 0.8266666666666667, loss:0.4564628601074219, lr:0.044446419840881816\n",
            "epoch: 21600, acc: 0.8266666666666667, loss:0.45605164766311646, lr:0.04424974556396301\n",
            "epoch: 21700, acc: 0.8233333333333334, loss:0.45564004778862, lr:0.044054804176395436\n",
            "epoch: 21800, acc: 0.8233333333333334, loss:0.45522522926330566, lr:0.043861572876003334\n",
            "epoch: 21900, acc: 0.8233333333333334, loss:0.4547414779663086, lr:0.0436700292589196\n",
            "epoch: 22000, acc: 0.8266666666666667, loss:0.45428401231765747, lr:0.043480151310926564\n",
            "epoch: 22100, acc: 0.8266666666666667, loss:0.4538702368736267, lr:0.0432919173990216\n",
            "epoch: 22200, acc: 0.8266666666666667, loss:0.45340830087661743, lr:0.043105306263201\n",
            "epoch: 22300, acc: 0.8266666666666667, loss:0.4529963731765747, lr:0.0429202970084553\n",
            "epoch: 22400, acc: 0.8233333333333334, loss:0.45220592617988586, lr:0.04273686909696996\n",
            "epoch: 22500, acc: 0.8266666666666667, loss:0.4516071677207947, lr:0.04255500234052513\n",
            "epoch: 22600, acc: 0.8266666666666667, loss:0.4510638415813446, lr:0.04237467689308869\n",
            "epoch: 22700, acc: 0.83, loss:0.45055288076400757, lr:0.042195873243596776\n",
            "epoch: 22800, acc: 0.83, loss:0.4500698745250702, lr:0.04201857220891634\n",
            "epoch: 22900, acc: 0.83, loss:0.44961023330688477, lr:0.04184275492698439\n",
            "epoch: 23000, acc: 0.83, loss:0.4491700828075409, lr:0.04166840285011876\n",
            "epoch: 23100, acc: 0.83, loss:0.44872233271598816, lr:0.041495497738495375\n",
            "epoch: 23200, acc: 0.83, loss:0.44830235838890076, lr:0.041324021653787346\n",
            "epoch: 23300, acc: 0.83, loss:0.44788065552711487, lr:0.04115395695296103\n",
            "epoch: 23400, acc: 0.83, loss:0.4474928379058838, lr:0.04098528628222468\n",
            "epoch: 23500, acc: 0.8333333333333334, loss:0.4470718801021576, lr:0.04081799257112535\n",
            "epoch: 23600, acc: 0.8333333333333334, loss:0.4466908872127533, lr:0.04065205902678971\n",
            "epoch: 23700, acc: 0.8366666666666667, loss:0.4463100731372833, lr:0.04048746912830479\n",
            "epoch: 23800, acc: 0.8366666666666667, loss:0.445926308631897, lr:0.040324206621234725\n",
            "epoch: 23900, acc: 0.8366666666666667, loss:0.44556763768196106, lr:0.04016225551226957\n",
            "epoch: 24000, acc: 0.8366666666666667, loss:0.4451870620250702, lr:0.040001600064002565\n",
            "epoch: 24100, acc: 0.8366666666666667, loss:0.44482192397117615, lr:0.039842224789832265\n",
            "epoch: 24200, acc: 0.8366666666666667, loss:0.4444732666015625, lr:0.03968411444898607\n",
            "epoch: 24300, acc: 0.8366666666666667, loss:0.4441194534301758, lr:0.03952725404166173\n",
            "epoch: 24400, acc: 0.8366666666666667, loss:0.44379526376724243, lr:0.03937162880428363\n",
            "epoch: 24500, acc: 0.8366666666666667, loss:0.4434451162815094, lr:0.03921722420487078\n",
            "epoch: 24600, acc: 0.8366666666666667, loss:0.4431068003177643, lr:0.03906402593851322\n",
            "epoch: 24700, acc: 0.8366666666666667, loss:0.4427723288536072, lr:0.0389120199229542\n",
            "epoch: 24800, acc: 0.8366666666666667, loss:0.4424488842487335, lr:0.03876119229427497\n",
            "epoch: 24900, acc: 0.8366666666666667, loss:0.4421465992927551, lr:0.03861152940267964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gpGygrucG0J"
      },
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "\n",
        "\n",
        "# Dense layer\n",
        "class Layer_Dense:\n",
        "\n",
        "    # Layer initialization\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "        # Initialize weights and biases\n",
        "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "        self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Calculate output values from inputs, weights and biases\n",
        "        self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Gradients on parameters\n",
        "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
        "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
        "        # Gradient on values\n",
        "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
        "\n",
        "\n",
        "# ReLU activation\n",
        "class Activation_ReLU:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Calculate output values from inputs\n",
        "        self.output = np.maximum(0, inputs)\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Since we need to modify original variable,\n",
        "        # let's make a copy of values first\n",
        "        self.dinputs = dvalues.copy()\n",
        "\n",
        "        # Zero gradient where input values were negative\n",
        "        self.dinputs[self.inputs <= 0] = 0\n",
        "\n",
        "\n",
        "\n",
        "# Softmax activation\n",
        "class Activation_Softmax:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "\n",
        "        # Get unnormalized probabilities\n",
        "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
        "                                            keepdims=True))\n",
        "        # Normalize them for each sample\n",
        "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
        "                                            keepdims=True)\n",
        "\n",
        "        self.output = probabilities\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "\n",
        "        # Create uninitialized array\n",
        "        self.dinputs = np.empty_like(dvalues)\n",
        "\n",
        "        # Enumerate outputs and gradients\n",
        "        for index, (single_output, single_dvalues) in \\\n",
        "                enumerate(zip(self.output, dvalues)):\n",
        "            # Flatten output array\n",
        "            single_output = single_output.reshape(-1, 1)\n",
        "            # Calculate Jacobian matrix of the output\n",
        "            jacobian_matrix = np.diagflat(single_output) - \\\n",
        "                              np.dot(single_output, single_output.T)\n",
        "            # Calculate sample-wise gradient\n",
        "            # and add it to the array of sample gradients\n",
        "            self.dinputs[index] = np.dot(jacobian_matrix,\n",
        "                                         single_dvalues)\n",
        "\n",
        "\n",
        "# SGD optimizer\n",
        "class Optimizer_SGD:\n",
        "\n",
        "    # Initialize optimizer - set settings,\n",
        "    # learning rate of 1. is default for this optimizer\n",
        "    def __init__(self, learning_rate=1., decay=0., momentum=0.):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.momentum = momentum\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If we use momentum\n",
        "        if self.momentum:\n",
        "\n",
        "            # If layer does not contain momentum arrays, create them\n",
        "            # filled with zeros\n",
        "            if not hasattr(layer, 'weight_momentums'):\n",
        "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
        "                # If there is no momentum array for weights\n",
        "                # The array doesn't exist for biases yet either.\n",
        "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
        "\n",
        "            # Build weight updates with momentum - take previous\n",
        "            # updates multiplied by retain factor and update with\n",
        "            # current gradients\n",
        "            weight_updates = \\\n",
        "                self.momentum * layer.weight_momentums - \\\n",
        "                self.current_learning_rate * layer.dweights\n",
        "            layer.weight_momentums = weight_updates\n",
        "\n",
        "            # Build bias updates\n",
        "            bias_updates = \\\n",
        "                self.momentum * layer.bias_momentums - \\\n",
        "                self.current_learning_rate * layer.dbiases\n",
        "            layer.bias_momentums = bias_updates\n",
        "\n",
        "        # Vanilla SGD updates (as before momentum update)\n",
        "        else:\n",
        "            weight_updates = -self.current_learning_rate * \\\n",
        "                             layer.dweights\n",
        "            bias_updates = -self.current_learning_rate * \\\n",
        "                           layer.dbiases\n",
        "\n",
        "        # Update weights and biases using either\n",
        "        # vanilla or momentum updates\n",
        "        layer.weights += weight_updates\n",
        "        layer.biases += bias_updates\n",
        "\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "# Adagrad optimizer\n",
        "class Optimizer_Adagrad:\n",
        "\n",
        "    # Initialize optimizer - set settings\n",
        "    def __init__(self, learning_rate=1., decay=0., epsilon=1e-7):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If layer does not contain cache arrays,\n",
        "        # create them filled with zeros\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        # Update cache with squared current gradients\n",
        "        layer.weight_cache += layer.dweights**2\n",
        "        layer.bias_cache += layer.dbiases**2\n",
        "\n",
        "        # Vanilla SGD parameter update + normalization\n",
        "        # with square rooted cache\n",
        "        layer.weights += -self.current_learning_rate * \\\n",
        "                         layer.dweights / \\\n",
        "                         (np.sqrt(layer.weight_cache) + self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * \\\n",
        "                        layer.dbiases / \\\n",
        "                        (np.sqrt(layer.bias_cache) + self.epsilon)\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "# RMSprop optimizer\n",
        "class Optimizer_RMSprop:\n",
        "\n",
        "    # Initialize optimizer - set settings\n",
        "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7,\n",
        "                 rho=0.9):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "        self.rho = rho\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If layer does not contain cache arrays,\n",
        "        # create them filled with zeros\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        # Update cache with squared current gradients\n",
        "        layer.weight_cache = self.rho * layer.weight_cache + \\\n",
        "            (1 - self.rho) * layer.dweights**2\n",
        "        layer.bias_cache = self.rho * layer.bias_cache + \\\n",
        "            (1 - self.rho) * layer.dbiases**2\n",
        "\n",
        "        # Vanilla SGD parameter update + normalization\n",
        "        # with square rooted cache\n",
        "        layer.weights += -self.current_learning_rate * \\\n",
        "                         layer.dweights / \\\n",
        "                         (np.sqrt(layer.weight_cache) + self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * \\\n",
        "                        layer.dbiases / \\\n",
        "                        (np.sqrt(layer.bias_cache) + self.epsilon)\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "\n",
        "# Adam optimizer\n",
        "class Optimizer_Adam:\n",
        "\n",
        "    # Initialize optimizer - set settings\n",
        "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7,\n",
        "                 beta_1=0.9, beta_2=0.999):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "        self.beta_1 = beta_1\n",
        "        self.beta_2 = beta_2\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If layer does not contain cache arrays,\n",
        "        # create them filled with zeros\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        # Update momentum  with current gradients\n",
        "        layer.weight_momentums = self.beta_1 * \\\n",
        "                                 layer.weight_momentums + \\\n",
        "                                 (1 - self.beta_1) * layer.dweights\n",
        "        layer.bias_momentums = self.beta_1 * \\\n",
        "                               layer.bias_momentums + \\\n",
        "                               (1 - self.beta_1) * layer.dbiases\n",
        "        # Get corrected momentum\n",
        "        # self.iteration is 0 at first pass\n",
        "        # and we need to start with 1 here\n",
        "        weight_momentums_corrected = layer.weight_momentums / \\\n",
        "            (1 - self.beta_1 ** (self.iterations + 1))\n",
        "        bias_momentums_corrected = layer.bias_momentums / \\\n",
        "            (1 - self.beta_1 ** (self.iterations + 1))\n",
        "        # Update cache with squared current gradients\n",
        "        layer.weight_cache = self.beta_2 * layer.weight_cache + \\\n",
        "            (1 - self.beta_2) * layer.dweights**2\n",
        "\n",
        "        layer.bias_cache = self.beta_2 * layer.bias_cache + \\\n",
        "            (1 - self.beta_2) * layer.dbiases**2\n",
        "        # Get corrected cache\n",
        "        weight_cache_corrected = layer.weight_cache / \\\n",
        "            (1 - self.beta_2 ** (self.iterations + 1))\n",
        "        bias_cache_corrected = layer.bias_cache / \\\n",
        "            (1 - self.beta_2 ** (self.iterations + 1))\n",
        "\n",
        "        # Vanilla SGD parameter update + normalization\n",
        "        # with square rooted cache\n",
        "        layer.weights += -self.current_learning_rate * \\\n",
        "                         weight_momentums_corrected / \\\n",
        "                         (np.sqrt(weight_cache_corrected) +\n",
        "                             self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * \\\n",
        "                         bias_momentums_corrected / \\\n",
        "                         (np.sqrt(bias_cache_corrected) +\n",
        "                             self.epsilon)\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "# Common loss class\n",
        "class Loss:\n",
        "\n",
        "    # Calculates the data and regularization losses\n",
        "    # given model output and ground truth values\n",
        "    def calculate(self, output, y):\n",
        "\n",
        "        # Calculate sample losses\n",
        "        sample_losses = self.forward(output, y)\n",
        "\n",
        "        # Calculate mean loss\n",
        "        data_loss = np.mean(sample_losses)\n",
        "\n",
        "        # Return loss\n",
        "        return data_loss\n",
        "\n",
        "\n",
        "# Cross-entropy loss\n",
        "class Loss_CategoricalCrossentropy(Loss):\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, y_pred, y_true):\n",
        "\n",
        "        # Number of samples in a batch\n",
        "        samples = len(y_pred)\n",
        "        # Clip data to prevent division by 0\n",
        "        # Clip both sides to not drag mean towards any value\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        # Probabilities for target values -\n",
        "        # only if categorical labels\n",
        "        if len(y_true.shape) == 1:\n",
        "            correct_confidences = y_pred_clipped[\n",
        "                range(samples),\n",
        "                y_true\n",
        "            ]\n",
        "\n",
        "        # Mask values - only for one-hot encoded labels\n",
        "        elif len(y_true.shape) == 2:\n",
        "            correct_confidences = np.sum(\n",
        "                y_pred_clipped * y_true,\n",
        "                axis=1\n",
        "            )\n",
        "\n",
        "        # Losses\n",
        "        negative_log_likelihoods = -np.log(correct_confidences)\n",
        "        return negative_log_likelihoods\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "        # Number of labels in every sample\n",
        "        # We'll use the first sample to count them\n",
        "        labels = len(dvalues[0])\n",
        "\n",
        "        # If labels are sparse, turn them into one-hot vector\n",
        "        if len(y_true.shape) == 1:\n",
        "            y_true = np.eye(labels)[y_true]\n",
        "\n",
        "        # Calculate gradient\n",
        "        self.dinputs = -y_true / dvalues\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "\n",
        "\n",
        "# Softmax classifier - combined Softmax activation\n",
        "# and cross-entropy loss for faster backward step\n",
        "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
        "\n",
        "    # Creates activation and loss function objects\n",
        "    def __init__(self):\n",
        "        self.activation = Activation_Softmax()\n",
        "        self.loss = Loss_CategoricalCrossentropy()\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs, y_true):\n",
        "        # Output layer's activation function\n",
        "        self.activation.forward(inputs)\n",
        "        # Set the output\n",
        "        self.output = self.activation.output\n",
        "        # Calculate and return loss value\n",
        "        return self.loss.calculate(self.output, y_true)\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "\n",
        "        # If labels are one-hot encoded,\n",
        "        # turn them into discrete values\n",
        "        if len(y_true.shape) == 2:\n",
        "            y_true = np.argmax(y_true, axis=1)\n",
        "\n",
        "        # Copy so we can safely modify\n",
        "        self.dinputs = dvalues.copy()\n",
        "        # Calculate gradient\n",
        "        self.dinputs[range(samples), y_true] -= 1\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "\n",
        "# Create dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n",
        "\n",
        "# Create Dense layer with 2 input features and 64 output values\n",
        "dense1 = Layer_Dense(2, 64)\n",
        "\n",
        "# Create ReLU activation (to be used with Dense layer):\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "# Create second Dense layer with 64 input features (as we take output\n",
        "# of previous layer here) and 3 output values (output values)\n",
        "dense2 = Layer_Dense(64, 3)\n",
        "# Create Softmax classifier's combined loss and activation\n",
        "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = Optimizer_Adam(learning_rate=0.05, decay=5e-7)\n",
        "\n",
        "# Train in loop\n",
        "for epoch in range(10001):\n",
        "\n",
        "    # Perform a forward pass of our training data through this layer\n",
        "    dense1.forward(X)\n",
        "\n",
        "    # Perform a forward pass through activation function\n",
        "    # takes the output of first dense layer here\n",
        "    activation1.forward(dense1.output)\n",
        "\n",
        "    # Perform a forward pass through second Dense layer\n",
        "    # takes outputs of activation function of first layer as inputs\n",
        "    dense2.forward(activation1.output)\n",
        "\n",
        "    # Perform a forward pass through the activation/loss function\n",
        "    # takes the output of second dense layer here and returns loss\n",
        "    loss = loss_activation.forward(dense2.output, y)\n",
        "\n",
        "    # Calculate accuracy from output of activation2 and targets\n",
        "    # calculate values along first axis\n",
        "    predictions = np.argmax(loss_activation.output, axis=1)\n",
        "    if len(y.shape) == 2:\n",
        "        y = np.argmax(y, axis=1)\n",
        "    accuracy = np.mean(predictions==y)\n",
        "\n",
        "    if not epoch % 100:\n",
        "        print(f'epoch: {epoch}, ' +\n",
        "              f'acc: {accuracy:.3f}, ' +\n",
        "              f'loss: {loss:.3f}, ' +\n",
        "              f'lr: {optimizer.current_learning_rate}')\n",
        "\n",
        "    # Backward pass\n",
        "    loss_activation.backward(loss_activation.output, y)\n",
        "    dense2.backward(loss_activation.dinputs)\n",
        "    activation1.backward(dense2.dinputs)\n",
        "    dense1.backward(activation1.dinputs)\n",
        "\n",
        "    # Update weights and biases\n",
        "    optimizer.pre_update_params()\n",
        "    optimizer.update_params(dense1)\n",
        "    optimizer.update_params(dense2)\n",
        "    optimizer.post_update_params()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}